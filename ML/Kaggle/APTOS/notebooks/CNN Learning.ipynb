{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "absProjectDir = Path(os.getcwd()).resolve().parents[0]\n",
    "projectDir = os.path.relpath(absProjectDir,os.curdir)\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "trainDfPath = os.path.join(projectDir, os.environ.get(\"REF_PROC_TRAIN_DF\"))\n",
    "testDfPath = os.path.join(projectDir, os.environ.get(\"REF_PROC_TEST_DF\"))\n",
    "testOrigDir = os.path.join(projectDir, os.environ.get(\"PROC_TEST_ORIG_DIR\"))\n",
    "testAugmDir = os.path.join(projectDir, os.environ.get(\"PROC_TEST_AUG_DIR\"))\n",
    "trainOrigDir = os.path.join(projectDir, os.environ.get(\"PROC_TRAIN_ORIG_DIR\"))\n",
    "trainAugmDir = os.path.join(projectDir, os.environ.get(\"PROC_TRAIN_AUG_DIR\"))\n",
    "testRootDir = os.path.commonpath([testOrigDir, testAugmDir])\n",
    "trainRootDir = os.path.commonpath([trainOrigDir, trainAugmDir])\n",
    "\n",
    "sys.path.append(os.path.join(projectDir,'src/data'))\n",
    "import imggen as imgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.layers import SeparableConv2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "class ConvBatchNorm(layers.Layer):\n",
    "    def __init__(self,filters, kernel_size = (3,3), strides=(1, 1)) :\n",
    "        super(ConvBatchNorm,self).__init__()\n",
    "        self.Layer1 = Conv2D(filters,kernel_size,strides,padding = \"same\")\n",
    "        self.Layer2 = BatchNormalization()\n",
    "    def call(self,inputs,training = None):\n",
    "        x = self.Layer1(inputs)\n",
    "        x = self.Layer2(x,training = training)\n",
    "        return tf.nn.relu(x)\n",
    "    \n",
    "class InceptionV1(layers.Layer):\n",
    "    def __init__(self, filters1, filters31, filters33, filters51, filters55, filtersPool):\n",
    "        super(InceptionV1, self).__init__()\n",
    "        self.Layer11 = ConvBatchNorm(filters1, (1,1), (1,1))\n",
    "        self.Layer12 = ConvBatchNorm(filters31, (1,1), (1,1))\n",
    "        self.Layer13 = ConvBatchNorm(filters51, (1,1), (1,1))\n",
    "        self.Layer14 = MaxPool2D(pool_size=(3, 3), strides=(1,1), padding = \"same\")\n",
    "        self.Layer22 = ConvBatchNorm(filters33, (3,3), (1,1))\n",
    "        self.Layer23 = ConvBatchNorm(filters55,(5,5),(1,1))\n",
    "        self.Layer24 = ConvBatchNorm(filtersPool, (1,1), (1,1))\n",
    "        self.Layer3 = Concatenate()\n",
    "        self.Layer4 = ReLU()\n",
    "        \n",
    "    def call(self, inputs, training = None):\n",
    "        x1 = self.Layer11(inputs,training)\n",
    "        x2 = self.Layer12(inputs,training)\n",
    "        x2 = self.Layer22(x2,training)\n",
    "        x3 = self.Layer13(inputs,training)\n",
    "        x3 = self.Layer23(x3, training)\n",
    "        x4 = self.Layer14(inputs)\n",
    "        x4 = self.Layer24(x4, training)\n",
    "        x5 = self.Layer3([x1,x2,x3,x4])\n",
    "        x5 = self.Layer4(x5)\n",
    "        return x5\n",
    "\n",
    "class CustomInceptionV1(layers.Layer):\n",
    "    def __init__(self, filters, r0):\n",
    "        super(CustomInceptionV1,self).__init__()\n",
    "        f1 = int(r0 * filters  * 0.25)\n",
    "        f31 = int(r0 * filters)\n",
    "        f33 = f31\n",
    "        f51 = int(r0 * filters * 0.15)\n",
    "        f55 = f51\n",
    "        fPool = filters - (f1 + f33 + f55)\n",
    "        self.InceptionLayer = InceptionV1(f1, f31, f33, f51, f55, fPool)\n",
    "    \n",
    "    def call(self,inputs,training = None):\n",
    "        return self.InceptionLayer.call(inputs,training)\n",
    "    \n",
    "def CustomInceptionModel1(r = 0.5, kernel = (3,3), filters = 32, units = 512, input_shape = (224,224,3)):\n",
    "    model = Sequential(name = \"CustomInceptionV1_R{}_Kern{}_Filters{}_Units{}\".format(int(r*10),kernel[0],filters,units))\n",
    "    model.add(InputLayer(input_shape))\n",
    "    layers = []\n",
    "    layers.append(ConvBatchNorm(filters, kernel, (1,1)))\n",
    "    layers.append(ConvBatchNorm(filters * 2, kernel, (1,1)))\n",
    "    layers.append(CustomInceptionV1(filters * 4,r))\n",
    "    layers.append(CustomInceptionV1(filters * 8, r))\n",
    "    layers.append(CustomInceptionV1(filters * 16, r))\n",
    "    for layer in layers:\n",
    "        model.add(layer)\n",
    "        model.add(MaxPool2D(pool_size=(2, 2), strides = (2,2)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(units, activation = 'relu'))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    model.compile(optimizer=Adam(lr=0.0001),loss=BinaryCrossentropy(),metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgen = imgen.Generator(trainDfPath, trainRootDir, (224,224))\n",
    "trgen.SetDataFrameForGeneration([[2],[3]],[[2048],[2048]])\n",
    "\n",
    "tsgen = imgen.Generator(testDfPath,testRootDir, (224,224))\n",
    "tsgen.SetDataFrameForGeneration([[2],[3]], [[1024],[1024]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4096 validated image filenames belonging to 2 classes.\n",
      "Found 2048 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = trgen.GetGenerator(bs = 16)\n",
    "test_set = tsgen.GetGenerator(bs = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomInceptionModel1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 256.0 steps, validate for 128.0 steps\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 449s 2s/step - loss: 0.6163 - accuracy: 0.6736 - val_loss: 1.7138 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 410s 2s/step - loss: 0.5817 - accuracy: 0.6963 - val_loss: 0.6533 - val_accuracy: 0.6313\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 410s 2s/step - loss: 0.5653 - accuracy: 0.7129 - val_loss: 0.6635 - val_accuracy: 0.6118\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 409s 2s/step - loss: 0.5455 - accuracy: 0.7246 - val_loss: 1.0366 - val_accuracy: 0.5288\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 458s 2s/step - loss: 0.5223 - accuracy: 0.7424 - val_loss: 1.1638 - val_accuracy: 0.5093\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 412s 2s/step - loss: 0.4940 - accuracy: 0.7593 - val_loss: 0.6578 - val_accuracy: 0.6382\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 566s 2s/step - loss: 0.4586 - accuracy: 0.7949 - val_loss: 0.9054 - val_accuracy: 0.5571\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 23323s 91s/step - loss: 0.4267 - accuracy: 0.8098 - val_loss: 0.7468 - val_accuracy: 0.5923\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 432s 2s/step - loss: 0.3723 - accuracy: 0.8440 - val_loss: 0.6827 - val_accuracy: 0.6094\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 401s 2s/step - loss: 0.2993 - accuracy: 0.8860 - val_loss: 0.8196 - val_accuracy: 0.5991\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 405s 2s/step - loss: 0.2184 - accuracy: 0.9260 - val_loss: 1.7334 - val_accuracy: 0.5220\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 401s 2s/step - loss: 0.1498 - accuracy: 0.9587 - val_loss: 1.9449 - val_accuracy: 0.5361\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 396s 2s/step - loss: 0.1181 - accuracy: 0.9658 - val_loss: 1.2343 - val_accuracy: 0.5737\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 377s 1s/step - loss: 0.0791 - accuracy: 0.9792 - val_loss: 0.8571 - val_accuracy: 0.6406\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 376s 1s/step - loss: 0.0591 - accuracy: 0.9841 - val_loss: 1.6023 - val_accuracy: 0.5781\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 376s 1s/step - loss: 0.0465 - accuracy: 0.9893 - val_loss: 0.9959 - val_accuracy: 0.6211\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 621s 2s/step - loss: 0.0399 - accuracy: 0.9907 - val_loss: 1.1225 - val_accuracy: 0.6128\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 542s 2s/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 1.5084 - val_accuracy: 0.5845\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 641s 3s/step - loss: 0.0376 - accuracy: 0.9890 - val_loss: 1.2769 - val_accuracy: 0.6587\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 644s 3s/step - loss: 0.0143 - accuracy: 0.9983 - val_loss: 1.7125 - val_accuracy: 0.5933\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_set,\n",
    "                 steps_per_epoch = 2048 / 8,\n",
    "                 epochs = 20, validation_data = test_set,validation_steps = 1024 / 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256 * 3 /8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FooModel(Model):\n",
    "    def __init__(self,name = \"FooModel\", **kwargs):\n",
    "        super(FooModel, self).__init__(name = name, **kwargs)\n",
    "        self.layer1 = InputLayer((224,224,3))\n",
    "        self.layer2 = ConvBatchNorm(32, (3,3), (1,1))\n",
    "        self.layer3 = CustomInceptionV1(128, 0.5)\n",
    "        self.layer33 = MaxPool2D(pool_size=(2, 2), strides = (2,2))\n",
    "        self.layer4 = GlobalAveragePooling2D()\n",
    "        self.layer5 = Dense(256, activation = 'relu')\n",
    "        self.layer6 = Dense(1,activation = 'sigmoid')\n",
    "        \n",
    "    def call(self, inputs, training = None):\n",
    "        x = self.layer1(inputs)\n",
    "        x = self.layer2(x,training)\n",
    "        x = self.layer3(x,training)\n",
    "        x = self.layer33(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FooModel(Sequential):\n",
    "    def __init__(self,name = \"FooModel\", **kwargs):\n",
    "        super(FooModel, self).__init__(name = name, **kwargs)\n",
    "        self.layers = []\n",
    "        self.layers.append(InputLayer((224,224,3)))\n",
    "        self.layers.append(ConvBatchNorm(32, (3,3), (1,1)))\n",
    "        self.layers.append(CustomInceptionV1(128, 0.5))\n",
    "        self.layers.append(GlobalAveragePooling2D())\n",
    "        self.layers.append(Dense(256, activation = 'relu'))\n",
    "        self.layers.append(Dense(1,activation = 'sigmoid'))\n",
    "        \n",
    "    def call(self, inputs, training = None):\n",
    "        x = self.layers[0](inputs)\n",
    "        for i in range(1,7):\n",
    "            x = self.layers[i](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((224,224,3)))\n",
    "model.add(ConvBatchNorm(32, (3,3), (1,1)))\n",
    "model.add(CustomInceptionV1(128, 0.5))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = FooModel()\n",
    "model.compile(optimizer=Adam(lr=0.0001),loss=BinaryCrossentropy(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_batch_norm_42 (ConvBatc (None, 224, 224, 32)      1024      \n",
      "_________________________________________________________________\n",
      "custom_inception_v1_6 (Custo (None, 224, 224, 128)     43990     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 78,295\n",
      "Trainable params: 77,829\n",
      "Non-trainable params: 466\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train_set,\n",
    "                 steps_per_epoch = 128 / 4,\n",
    "                 epochs = 20, validation_data = test_set,validation_steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 0.5\n",
    "filters = 32\n",
    "kernel = (3,3)\n",
    "units = 512\n",
    "model = Sequential()#name = \"CustomInceptionV1_R{}_Kern{}_Filters{}_Units{}\".format(int(r*10),kernel[0],filters,units))\n",
    "model.add(InputLayer((224,224,3)))\n",
    "model.add(ConvBatchNorm(filters, kernel, (1,1)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides = (2,2)))\n",
    "model.add(ConvBatchNorm(filters * 2, kernel, (1,1)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides = (2,2)))\n",
    "model.add(CustomInceptionV1(filters * 4,r))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides = (2,2), padding='same'))\n",
    "model.add(CustomInceptionV1(filters * 8, r))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides = (2,2)))\n",
    "model.add(CustomInceptionV1(filters * 16, r))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides = (2,2)))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(units, activation = 'relu'))\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "model.compile(optimizer=Adam(lr=0.0001),loss=BinaryCrossentropy(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 32.0 steps, validate for 1 steps\n",
      "32/32 [==============================] - 56s 2s/step - loss: 0.6080 - accuracy: 0.6836 - val_loss: 0.7218 - val_accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_set,\n",
    "                 steps_per_epoch = 128 / 4,\n",
    "                 epochs = 1, validation_data = test_set,validation_steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_batch_norm_315 (ConvBat (None, 224, 224, 32)      1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_139 (MaxPoolin (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_batch_norm_316 (ConvBat (None, 112, 112, 64)      18752     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_140 (MaxPoolin (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "custom_inception_v1_44 (Cust (None, 56, 56, 128)       48086     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_141 (MaxPoolin (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "custom_inception_v1_45 (Cust (None, 28, 28, 256)       191264    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_142 (MaxPoolin (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "custom_inception_v1_46 (Cust (None, 14, 14, 512)       761026    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_143 (MaxPoolin (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_24  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,283,321\n",
      "Trainable params: 1,280,309\n",
      "Non-trainable params: 3,012\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
