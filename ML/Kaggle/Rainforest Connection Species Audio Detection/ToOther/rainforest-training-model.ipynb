{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n!pip install iterative-stratification\n\nimport numpy as np \nimport scipy as sp\nimport sklearn as sl\nimport pandas as pd\nimport librosa\nfrom librosa import display\nimport IPython\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom dataclasses import dataclass\nfrom functools import partial\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nfrom tqdm import tqdm\n\nimport tensorflow as tf\nimport tensorflow.keras as tfk\nimport tensorflow.keras.layers as tfkl\nimport tensorflow.data as tfd\nimport tensorflow_addons as tfa\nimport tensorflow_hub as hub\n\nimport os\nfrom kaggle_datasets import KaggleDatasets\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"VALIDATION = False\n\ncfg = { \n    'Version' : 7,\n    'Mode' : 'tpu', #'gpu','cpu'\n    'Training' : True,\n    'parse_params': {\n        'sample_rate' : 48000,\n        'cut' : 12.0\n    },\n    'data_params': {\n        'frame_length' : 2048,\n        'frame_step' : 512,\n        'mel_highest_freq' : 16000.0,#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n        'mel_lowest_freq' : 100.0,\n        'mel_num_bins' : 256,\n        'img_shape' : (256, 512),\n        'patch_cut' : 5.5,\n        'std' : 0.5,\n        'hcrop' : 20,\n        'wcrop' : 40,\n        'min_seg' : 0.50, \n        'min_fp_seg': 2.0,\n        'freqv' : [15000.0, 16000.0, 17000.0, 18000.0,19000.0, 20000.0, 22000.0, 24000.0],    \n        'pfp' : 0.2,\n        'shuffle_size' : 2048,\n    },\n    'model_params': {\n        'batchsize_per_tpu': 16,\n        'iteration_per_epoch': 128,\n        'epoch' : 72,\n        'ml_model': {\n            'fn' : tf.keras.applications.ResNet50,\n            'params' : {'include_top': False, 'weights' : 'imagenet', 'pooling' : 'avg' },\n            'top_drops' : 0.4,\n            'top_size' : 256,\n            'name' : 'JustSecondModel'  \n        },\n        'loss': {\n            'fn': tfa.losses.SigmoidFocalCrossEntropy,\n            'params': {'reduction' : tf.keras.losses.Reduction.NONE,  'from_logits' : False,},\n        },\n        'optim': {\n            'fn': tfa.optimizers.RectifiedAdam,\n            'params': {'lr': 1e-3, 'total_steps': 15*64, 'warmup_proportion': 0.3, 'min_lr': 1e-6},\n        },\n        'is_tp' : False\n    }\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path()\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nSCOPE = tf.name_scope('Not TPU')\nNUMBER_OF_REPLICAS = 1\nSTRATEGY = None\nMODE = cfg['Mode']\n\nif MODE == 'tpu':\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    STRATEGY = tf.distribute.experimental.TPUStrategy(tpu)\n    SCOPE = STRATEGY.scope()\n    NUMBER_OF_REPLICAS = STRATEGY.num_replicas_in_sync\n    print(\"All devices: \", tf.config.list_logical_devices('TPU'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@dataclass(frozen=True)  # Instances of this class are immutable.\nclass Params:\n    class_n: int = 24\n    sr: float = cfg['parse_params']['sample_rate'] # all wave's sample rate may be 48k   \n    cut: float = cfg['parse_params']['cut']\n    mcut: float = cfg['data_params']['min_seg']\n    fpmcut: float = cfg['data_params']['min_fp_seg']\n    frm_len: int = cfg['data_params']['frame_length']\n    frm_step: int = cfg['data_params']['frame_step']\n    mel_frq_h: float = cfg['data_params']['mel_highest_freq']\n    mel_frq_l: float = cfg['data_params']['mel_lowest_freq']\n    mel_bins: int = cfg['data_params']['img_shape'][0]\n    img_size_h: int = cfg['data_params']['img_shape'][0]\n    img_size_w: int = cfg['data_params']['img_shape'][1]\n    patch_cut: float = cfg['data_params']['patch_cut']\n    std: float = cfg['data_params']['std']\n    hcrop: int = cfg['data_params']['hcrop']\n    wcrop: int = cfg['data_params']['wcrop']\n    h: int = cfg['data_params']['img_shape'][0]\n    w: int = cfg['data_params']['img_shape'][1]\n    frqv = cfg['data_params']['freqv']\n    pfp: float = cfg['data_params']['pfp']\n    loss_fn = cfg['model_params']['loss']\n    optimize_fn = cfg['model_params']['optim']\n    training: bool = cfg['Training']\n    shuffle: int = cfg['data_params']['shuffle_size']\n    version: int = cfg['Version']\n    \n    @property\n    def model_fn(self):\n        model_fn = cfg['model_params']['ml_model']\n        model_fn['params']['input_shape'] = (self.img_size_h, self.img_size_w, 3)\n        return model_fn\n        \n    @property\n    def input_seq_size(self):\n        return self.frm_len + (self.img_size_w - 1) * self.frm_step\n    @property\n    def batch_size(self):\n        return cfg['model_params']['batchsize_per_tpu'] * NUMBER_OF_REPLICAS\n    @property\n    def iter_per_epoch(self):\n        return int((cfg['model_params']['iteration_per_epoch'] * self.batch_size) // 128)\n    @property\n    def batch_val_size(self):\n        return NUMBER_OF_REPLICAS * 8\n\n    epoch: int = cfg['model_params']['epoch']\n    train_tfrec: str = GCS_DS_PATH + \"/tfrecords/train\"\n    test_tfrec: str = GCS_DS_PATH + \"/tfrecords/test\"\n        \n    @property\n    def all_train_tfrec(self):\n        return [os.path.join(self.train_tfrec,filename) for filename in tf.io.gfile.listdir(self.train_tfrec)]\n    \n    @property\n    def all_test_tfrec(self):\n        return [os.path.join(self.test_tfrec,filename) for filename in tf.io.gfile.listdir(self.test_tfrec)]\n\n    path_tp_model: str = ''\n    path_fp_model: str = ''\n    \n    @property\n    def path_to_csv_table(self):        \n        if cfg['model_params']['is_tp'] == True:\n           return '/kaggle/input/rfcx-species-audio-detection/train_tp.csv'\n        return '/kaggle/input/rfcx-species-audio-detection/train_fp.csv'\n    @property \n    def tp(self):\n        if cfg['model_params']['is_tp'] == True:\n            return 1\n        return 0\n    \nGPARAMS = Params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#[Xmin, Xmax)\nclass Cropping:\n    def __init__(self, params):\n        self.in_seq_size = tf.cast(params.cut * params.sr, tf.int32)\n        self.min_tp_seq_size = tf.cast(params.mcut * params.sr, tf.int32)\n        self.min_fp_seq_size = tf.cast(params.fpmcut * params.sr, tf.int32)\n        self.out_seq_size = tf.cast(params.patch_cut * params.sr, tf.int32)\n        self.sr = tf.cast(params.sr, tf.float32)\n        \n    def _find_inertia_position(self, left, right):\n        s_diff = tf.cast((self.out_seq_size - (right - left))/2,tf.int32)\n        cleft = tf.cast(tf.maximum(0, tf.minimum(left - s_diff,tf.minimum(right + s_diff,self.in_seq_size) - self.out_seq_size)), tf.int32)\n        return cleft\n    \n    def _find_max_left_shift(self, left, right, istp):\n        min_seq_size = istp * self.min_tp_seq_size + (1 - istp) * self.min_fp_seq_size\n        p = tf.maximum(0, tf.minimum(self.in_seq_size, left + min_seq_size) - self.out_seq_size)\n        return p\n        \n    def _find_max_right_shift(self, left, right, istp):\n        min_seq_size = istp * self.min_tp_seq_size + (1 - istp) * self.min_fp_seq_size\n        p = tf.maximum(0, tf.minimum(self.in_seq_size, right - min_seq_size + self.out_seq_size) - self.out_seq_size)\n        return p\n           \n    def findRandomPossition(self, t_min, t_max, istp):\n        left = tf.cast(t_min * self.sr, tf.int32)\n        right = tf.cast(t_max * self.sr, tf.int32)\n        p0 = self._find_inertia_position(left, right)\n        pleft = self._find_max_left_shift(left, right, istp)\n        pright = self._find_max_right_shift(left, right, istp)\n        shift = tf.random.uniform([], minval = 0, maxval = 2, dtype = tf.int32)\n        p = shift * pleft + (1 - shift) * pright\n        pmin = tf.minimum(p0, p)\n        pmax = tf.maximum(p0, p)      \n        cleft = tf.random.uniform( [], minval = pmin, maxval = pmax + 1, dtype=tf.int32)\n        cright = cleft + self.out_seq_size\n        return (cleft, cright)\n    \n    @tf.function\n    def __call__(self, sample):\n        cleft, cright = self.findRandomPossition(sample['t_min'], sample['t_max'], tf.cast(sample['is_tp'], tf.int32))\n        length = cright - cleft\n        padding_space = tf.maximum(0, self.out_seq_size - length)\n        padding = tf.convert_to_tensor([[0, padding_space]])\n        return tf.pad(tf.slice(sample['audio_wav'],[cleft],[length]),padding, \"CONSTANT\")\n#########################################################################################################################################################################\n#########################################################################################################################################################################\n#########################################################################################################################################################################\n\nclass MalSpectrogram:\n    def __init__(self, params):\n        self.params = params\n        self.fft_length = 2 ** int(np.ceil(np.log(params.frm_len) / np.log(2.0)))\n        self.num_spectrogram_bins = self.fft_length // 2 + 1\n        llmelwm = []\n        for frq in params.frqv:\n            lmelwm = tf.signal.linear_to_mel_weight_matrix(num_mel_bins = self.params.mel_bins, num_spectrogram_bins = self.num_spectrogram_bins,\n                                                           sample_rate = self.params.sr, lower_edge_hertz = self.params.mel_frq_l,upper_edge_hertz = frq)\n            llmelwm.append(tf.expand_dims(lmelwm,0))\n        self.llmelwm = tf.concat(llmelwm,0)\n        \n    @tf.function\n    def __call__(self, waveform):\n        with tf.name_scope('log_mel_features'):\n            magnitude_spectrogram = tf.abs(tf.signal.stft(signals = waveform, frame_length = self.params.frm_len,\n                                                          frame_step = self.params.frm_step, fft_length=self.fft_length))\n            idx = tf.random.uniform([], minval = 0, maxval = len(self.params.frqv), dtype = tf.int32)\n            mel_spectrogram = tf.matmul(magnitude_spectrogram, self.llmelwm[idx,...])\n            log_mel_spectrogram = tf.math.log(mel_spectrogram + 0.001)\n            return tf.transpose(log_mel_spectrogram,[0,2,1])         \n#########################################################################################################################################################################\n#########################################################################################################################################################################\n#########################################################################################################################################################################\n\nclass FilterFun:\n    def __init__(self, params):\n        self.params = params\n    \n    def __call__(self, recids = None, pfp = 0.0):\n        @tf.function\n        def _filt_wo_recids(sample):\n            flag1 = tf.convert_to_tensor(sample['is_tp'] == 1)\n            flag2 = tf.random.uniform([]) < pfp\n            return flag1 | flag2      \n        @tf.function\n        def _filt_with_recids(sample):\n            return _filt_wo_recids(sample) & tf.reduce_any(recids == sample['recording_id'])\n        if recids is None:\n            return _filt_wo_recids\n        return _filt_with_recids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_description = {\n    'recording_id': tf.io.FixedLenFeature([], tf.string, default_value=''),\n    'audio_wav': tf.io.FixedLenFeature([], tf.string, default_value=''),\n    'label_info': tf.io.FixedLenFeature([], tf.string, default_value=''),\n}\n\nparse_dtype = {\n    'audio_wav': tf.float32,\n    'recording_id': tf.string,\n    'species_id': tf.int32,\n    'songtype_id': tf.int32,\n    't_min': tf.float32,\n    'f_min': tf.float32,\n    't_max': tf.float32,\n    'f_max':tf.float32,\n    'is_tp': tf.int32\n}\n\n@tf.function\ndef parse_step_fun(example_proto, params):\n    sample = tf.io.parse_single_example(example_proto, feature_description)\n    wav, _ = tf.audio.decode_wav(sample['audio_wav'], desired_channels=1) # mono\n    label_info = tf.strings.split(sample['label_info'], sep='\"')[1]\n    labels = tf.strings.split(label_info, sep=';')\n    \n    @tf.function\n    def _cut_audio(label):\n        items = tf.strings.split(label, sep=',')\n        spid = tf.squeeze(tf.strings.to_number(items[0], tf.int32))\n        soid = tf.squeeze(tf.strings.to_number(items[1], tf.int32))\n        tmin = tf.squeeze(tf.strings.to_number(items[2]))\n        fmin = tf.squeeze(tf.strings.to_number(items[3]))\n        tmax = tf.squeeze(tf.strings.to_number(items[4]))\n        fmax = tf.squeeze(tf.strings.to_number(items[5]))\n        tp = tf.squeeze(tf.strings.to_number(items[6], tf.int32))\n\n        seq_len = tf.cast(params.cut * params.sr,tf.int32)\n        tmax_s = tmax * tf.cast(params.sr, tf.float32)\n        tmin_s = tmin * tf.cast(params.sr, tf.float32)\n        cut_s = tf.cast(seq_len, tf.float32)\n        all_s = tf.cast(60 * params.sr, tf.float32)\n        tsize_s = tmax_s - tmin_s\n        cut_min = tf.cast(\n            tf.maximum(0.0, \n                tf.minimum(tmin_s - (cut_s - tsize_s) / 2,\n                           tf.minimum(tmax_s + (cut_s - tsize_s) / 2, all_s) - cut_s)\n            ), tf.int32\n        )\n        \n        cut_max = cut_min + seq_len\n        \n        _sample = {\n            'audio_wav': tf.reshape(wav[cut_min:cut_max], [seq_len]),\n            'recording_id': sample['recording_id'],\n            'species_id': spid,\n            'songtype_id': soid,\n            't_min': tmin - tf.cast(cut_min, tf.float32)/tf.cast(params.sr, tf.float32),\n            'f_min': fmin,\n            't_max': tmax - tf.cast(cut_min, tf.float32)/tf.cast(params.sr, tf.float32),\n            'f_max': fmax,\n            'is_tp': tp\n        }\n        return _sample\n    samples = tf.map_fn(_cut_audio, labels, dtype=parse_dtype)\n    return samples\n\n\nclass PipelineComponents:\n    def __init__(self, params):\n        self.params = params\n        self.Crop = Cropping(params)\n        self.Spectrogram = MalSpectrogram(params)\n        self.FP = FilterFun(params) \n        \n    def _striping(self, image):\n        h = self.params.img_size_h\n        w = self.params.img_size_w \n        hcrop = self.params.hcrop\n        wcrop = self.params.wcrop\n        offset_x = tf.random.uniform(shape = (), minval = 0, maxval = w - wcrop - 3, dtype = tf.int32)\n        width = tf.random.uniform(shape = (), minval = wcrop // 2, maxval = wcrop, dtype = tf.int32 )\n        offset_y = tf.random.uniform(shape = (), minval = 0, maxval = h - hcrop - 3, dtype = tf.int32)\n        height = tf.random.uniform(shape = (), minval = hcrop // 2, maxval = hcrop, dtype = tf.int32 )\n        hor = tf.pad(tensor = tf.zeros([height, w], tf.int32), paddings = [[offset_y, h - offset_y - height],[0,0]], mode='CONSTANT', constant_values=1)\n        ver = tf.pad(tensor = tf.zeros([h, width], tf.int32), paddings = [[0,0],[offset_x, w - offset_x - width]], mode='CONSTANT', constant_values=1)\n        flag = tf.random.uniform(shape = (), minval = 0, maxval = 2, dtype = tf.int32)\n        mask = flag * hor + (1 - flag) * ver\n        flag = tf.random.uniform(shape = (), minval = 0, maxval = 2, dtype = tf.int32)\n        mask = tf.expand_dims(tf.expand_dims(tf.cast(flag * mask + (1 - flag) * hor * ver, tf.float32),0),-1)\n        return image * mask  \n        \n    def _target_representation(self, sample):       \n        return tf.convert_to_tensor([sample['species_id'], sample['is_tp']], dtype = tf.int32)\n    \n    def CropFn(self):\n        @tf.function\n        def _crop(sample):\n            x = self.Crop(sample)\n            y = self._target_representation(sample)\n            return { 'x' : x, 'y' : y}\n        return _crop\n    \n    def Output(self):\n        @tf.function\n        def _output(sample):\n            return (sample['x'], sample['y'])\n        return _output\n\n    def MapToSpectrogramFn(self):\n        out_seq_size = tf.cast(self.params.patch_cut * self.params.sr, tf.int32)\n        @tf.function\n        def _mapToSpectrogram(sample):\n            x = tf.expand_dims(sample['x'], axis = 0)\n            x = tf.squeeze(self.Spectrogram(x))\n            padding_space =tf.math.maximum(0, self.params.img_size_w - 1 - (out_seq_size - self.params.frm_len)//self.params.frm_step)\n            paddings = tf.convert_to_tensor([[0, 0], [0, padding_space]])    \n            x = tf.expand_dims(tf.pad(x,paddings)[...,:self.params.img_size_w], 0)\n            return {'x' : x, 'y' : sample['y']}\n        return _mapToSpectrogram\n    \n    def AugmentFn(self, training):\n        @tf.function\n        def _augment(sample):\n            img = tf.image.per_image_standardization(tf.expand_dims(sample['x'],-1)) \n            #noskip = tf.cast(1 == tf.cast(training, tf.int32) * sample['y'][-1], tf.bool)\n            if training:\n                gau = tfkl.GaussianNoise(self.params.std)\n                flag = tf.cast(tf.random.uniform(shape = (), minval = 0, maxval = 2, dtype = tf.int32), tf.float32) * tf.cast(sample['y'][-1],tf.float32)\n                img = flag * gau(img, training=True) + (1.0 - flag) * img\n                flag = tf.cast(tf.random.uniform(shape = (), minval = 0, maxval = 2, dtype = tf.int32), tf.float32) * tf.cast(sample['y'][-1],tf.float32)\n                img = flag * self._striping(img) + (1.0 - flag) * img\n            img = tf.squeeze(img)\n            img = (img - tf.math.reduce_min(img)) / (tf.math.reduce_max(img) - tf.math.reduce_min(img))\n            return (tf.reshape(img,[self.params.h, self.params.w]), sample[\"y\"])\n        return _augment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DatasetSrc:\n    def __init__(self, params):\n        self.Params = params\n        self.Filters = PipelineComponents(params)\n        self.BaseDataSet = (tfd.TFRecordDataset(params.all_train_tfrec)\n                            .map(partial(parse_step_fun, params = self.Params), num_parallel_calls=AUTOTUNE)\n                            .unbatch())\n        \n    def CreateDataset(self):\n        tr_dataset = (self.BaseDataSet.filter(self.Filters.FP(None, self.Params.pfp))\n                      .cache()\n                      .map(self.Filters.CropFn(),num_parallel_calls=AUTOTUNE)\n                      .map(self.Filters.MapToSpectrogramFn(),num_parallel_calls=AUTOTUNE)\n                      #.map(self.Filters.Output(),num_parallel_calls=AUTOTUNE)\n                      .map(self.Filters.AugmentFn(True),num_parallel_calls=AUTOTUNE)\n                      .batch(self.Params.batch_size).prefetch(AUTOTUNE))\n        return tr_dataset\n    \n    def CreateTrainDataset(self, shufflelen = None, recordIdv = None):\n        tr_dataset = (self.BaseDataSet.filter(self.Filters.FP(recordIdv, self.Params.pfp))\n                      .cache()\n                      .map(self.Filters.CropFn()))\n        if shufflelen is not None:\n            tr_dataset = tr_dataset.shuffle(shufflelen)\n        tr_dataset = (tr_dataset.repeat()\n                      .map(self.Filters.MapToSpectrogramFn(),num_parallel_calls=AUTOTUNE)\n                      .map(self.Filters.AugmentFn(True),num_parallel_calls=AUTOTUNE) \n                      .batch(self.Params.batch_size).prefetch(AUTOTUNE))\n        return tr_dataset\n \n    def CreateValDataset(self, recordIdv = None):\n        val_dataset = (self.BaseDataSet.filter(self.FP(recordIdv))\n                      .map(self.Filters.CropFn())\n                      .map(self.Filters.MapToSpectrogramFn(),num_parallel_calls=AUTOTUNE)\n                      .map(self.Filters.AugmentFn(False),num_parallel_calls=AUTOTUNE)\n                      .batch(self.Params.batch_val_size).cache())\n        return val_dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Metric"},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef _one_sample_positive_class_precisions(example):\n    y_true, y_pred = example\n    y_true = tf.cast(y_true > 0, tf.float32)\n\n    retrieved_classes = tf.argsort(y_pred, direction='DESCENDING')\n    class_rankings = tf.argsort(retrieved_classes)\n    retrieved_class_true = tf.gather(y_true, retrieved_classes)\n    retrieved_cumulative_hits = tf.math.cumsum(tf.cast(retrieved_class_true, tf.float32))\n\n    idx = tf.where(y_true)[:, 0]\n    i = tf.boolean_mask(class_rankings, y_true)\n    r = tf.gather(retrieved_cumulative_hits, i)\n    c = 1 + tf.cast(i, tf.float32)\n    precisions = r / c\n\n    dense = tf.scatter_nd(idx[:, None], precisions, [y_pred.shape[0]])\n    return dense\n\nclass LWLRAP(tf.keras.metrics.Metric):\n    def __init__(self, num_classes, name='lwlrap'):\n        super().__init__(name=name)\n\n        self._precisions = self.add_weight(\n            name='per_class_cumulative_precision',\n            shape=[num_classes],\n            initializer='zeros',\n        )\n\n        self._counts = self.add_weight(\n            name='per_class_cumulative_count',\n            shape=[num_classes],\n            initializer='zeros',\n        )\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        precisions = tf.map_fn(\n            fn=_one_sample_positive_class_precisions,\n            elems=(y_true, y_pred),\n            dtype=(tf.float32),\n        )\n\n        increments = tf.cast(precisions > 0, tf.float32)\n        total_increments = tf.reduce_sum(increments, axis=0)\n        total_precisions = tf.reduce_sum(precisions, axis=0)\n\n        self._precisions.assign_add(total_precisions)\n        self._counts.assign_add(total_increments)        \n\n    def result(self):\n        per_class_lwlrap = self._precisions / tf.maximum(self._counts, 1.0)\n        per_class_weight = self._counts / tf.reduce_sum(self._counts)\n        overall_lwlrap = tf.reduce_sum(per_class_lwlrap * per_class_weight)\n        return overall_lwlrap\n\n    def reset_states(self):\n        self._precisions.assign(self._precisions * 0)\n        self._counts.assign(self._counts * 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utils"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_history(history, name):\n    plt.figure(figsize=(8,3))\n    plt.subplot(1,2,1)\n    plt.plot(history.history[\"loss\"])\n    plt.plot(history.history[\"val_loss\"])\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.title(\"loss\")\n    # plt.yscale('log')\n\n    plt.subplot(1,2,2)\n    plt.plot(history.history[\"lwlrap\"])\n    plt.plot(history.history[\"val_lwlrap\"])\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.title(\"metric\")\n\n    plt.savefig(name)\n    \ndef plot_train_history(history, name):\n    plt.figure(figsize=(8,3))\n    plt.subplot(1,2,1)\n    plt.plot(history.history[\"loss\"])\n    plt.title(\"loss\")\n    # plt.yscale('log')\n\n    plt.subplot(1,2,2)\n    plt.plot(history.history[\"lwlrap\"])\n    plt.title(\"metric\")\n\n    plt.savefig(name)\n    \ndef template_save_weights(curepoch, epochs, model_step, pfp = '05',min_seg = '05', min_seg_fp = '2', units = 256,\n                          shuffle = GPARAMS.shuffle, version = GPARAMS.version, tp = GPARAMS.tp):\n    if curepoch in epochs:\n        filename = f'model_v{version}_e{curepoch}_s{shuffle}_ms{min_seg}_msfp{min_seg_fp}_u{units}_tp{tp}_pfp{pfp}.h5'\n        model_step.model.save_weights(filename)\n        print(filename)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ComponentFactory:\n    def __init__(self, params):\n        self.params = params\n        self.loss = None\n        self.optimize = None\n        self.model = None\n        self.train_acc = None\n        self.test_acc = None\n        \n    def _create_model(self):\n        params = self.params\n        cnn_model = params.model_fn['fn'](**params.model_fn['params'])\n        for layer in cnn_model.layers:\n            layer.trainable = True\n        inputs = tfkl.Input(shape = (params.img_size_h, params.img_size_w))\n        x = tfkl.Reshape((params.img_size_h, params.img_size_w,1))(inputs)\n        x = tfkl.Conv2D(filters = 3, kernel_size = 7, padding='same', activation = 'sigmoid')(x)\n        x = cnn_model(x)\n        outputs = []\n        for _ in range(params.class_n):\n            t = tfkl.Dropout(0.4)(x, training = params.training)\n            t = tfkl.Dense(params.model_fn['top_size'], activation='relu')(t)\n            t = tfkl.Dropout(params.model_fn['top_drops'])(t, training = params.training)\n            t = tfkl.Dense(1, activation = 'sigmoid')(t)\n            outputs.append(t)\n        model = tfk.Model(name=params.model_fn['name'], inputs=inputs,outputs=outputs)\n        return model\n    \n    def CreateModelIngradients(self):\n        self.model = self._create_model()\n        loss_obj = self.params.loss_fn['fn'](**self.params.loss_fn['params'])\n        def _loss_fn(y_true, y_pred):\n            return tf.nn.compute_average_loss(loss_obj(y_true = y_true,y_pred = y_pred),global_batch_size = self.params.batch_size)\n        self.loss = _loss_fn\n        optimizer = self.params.optimize_fn['fn'](**self.params.optimize_fn['params'])\n        def _opt_fn(gradients):\n            return optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n        self.optimize = _opt_fn\n        self.train_acc = LWLRAP(self.params.class_n, name = 'train_lwlrap')\n        self.test_acc = LWLRAP(self.params.class_n, name = 'test_lwlrap')\n        return self\n        \n    def CreateModelIngradientsInScope(self):\n        with SCOPE:\n            self.CreateModelIngradients()\n        return self \n    \nclass CreateStepFns:\n    def __init__(self, ingradients):\n        self.model = ingradients.model\n        self.loss = ingradients.loss\n        self.optimize = ingradients.optimize\n        self.train_acc = ingradients.train_acc\n        self.test_acc = ingradients.test_acc\n        self.class_n = ingradients.params.class_n\n        self.tp = ingradients.params.tp == 1\n        \n    def _train_step_tp(self, inputs):\n        images, y = inputs\n        y_true = tf.one_hot(y[:,0],self.class_n, on_value = 1.0, off_value = 0.0)\n        with tf.GradientTape() as tape:\n            y_pred = self.model(images, training=True)\n            y_pred = tf.concat(y_pred, axis = -1)\n            loss = self.loss(y_true, y_pred)\n\n        gradients = tape.gradient(loss, self.model.trainable_variables)\n        self.optimize(gradients)\n        self.train_acc.update_state(y_true, y_pred)\n        return loss\n    \n    def _train_step_tp_fp(self,inputs):\n        images, y = inputs\n        y_true = tf.one_hot(y[:,0] + self.class_n * (y[:,1] - 1),self.class_n, on_value = 1.0, off_value = 0.0)\n        ix1 = tf.cast(tf.where(y[:,1] == 1), tf.int32)\n        y_true1 = tf.squeeze(tf.one_hot(tf.gather_nd(y[:,0], tf.expand_dims(ix1, -1)), self.class_n, on_value = 1.0, off_value = 0.0))\n\n        ix2 = tf.cast(tf.where(y[:,1] == 0),tf.int32)\n        ys = tf.gather_nd(y[:,0], tf.expand_dims(ix2, -1))\n        y_true2 = tf.zeros_like(ys,dtype = tf.float32)\n        idxx = tf.stack([ix2, ys], axis = -1)\n        with tf.GradientTape() as tape:\n            y_pred = tf.concat(self.model(images,training = True),axis = -1)\n            y_pred1 = tf.squeeze(tf.gather_nd(y_pred, tf.expand_dims(ix1, -1)))\n            y_pred2 = tf.gather_nd(y_pred, idxx)\n            loss1 = self.loss(y_true1, y_pred1)\n            loss2 = self.loss(y_true2, y_pred2)\n            loss = loss1 + loss2\n        gradients = tape.gradient(loss, self.model.trainable_variables)\n        self.optimize(gradients)\n        self.train_acc.update_state(y_true, y_pred)\n        return loss\n           \n    def CreateTrainStepFn(self):\n        if self.tp == True:\n            return lambda inputs : self._train_step_tp(inputs)\n        if self.tp == False:\n            return lambda inputs : self._train_step_tp_fp(inputs)\n        \n    def CreateTestStepFn(self):\n        def _test_step(inputs):\n            images, y_true = inputs\n            y_pred = self.model(images, training = False)\n            y_pred = tf.concat(y_pred, axis = -1)\n            self.test_acc.update_state(y_true, y_pred)\n        return _test_step   \n#&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&    \n#ml_ingradients = ComponentFactory(GPARAMS).CreateModelIngradientsInScope()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Data preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = DatasetSrc(GPARAMS)\ndf = pd.read_csv(GPARAMS.path_to_csv_table)\ntable = df.groupby('recording_id')['species_id'].apply(lambda x: tf.scatter_nd(tf.expand_dims(x, 1),\n                                                                               np.ones_like(x),\n                                                                               shape=[GPARAMS.class_n]).numpy()).reset_index()\n\nskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=0)\nidx_splits = list(skf.split(table.recording_id, np.stack(table.species_id.to_numpy())))\nsplits = list(map(lambda xs: (table.recording_id[xs[0]].to_numpy(), table.recording_id[xs[1]].to_numpy()), idx_splits))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = None\ntest_dataset = None\ntr_datasets = []\nval_datasets = []\n\nif VALIDATION:\n    for i in range(5):\n        tr_dataset = dataset.CreateTrainDataset(splits[i][0], shufflelen = GPARAMS.shuffle // 2)\n        tr_datasets.append(tr_dataset)\n    \n    for i in range(5):\n        val_dataset = dataset.CreateValDataset(splits[i][1])\n        val_datasets.append(val_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = 1\n\nif VALIDATION:\n    train_dataset = tr_datasets[idx]\n    test_dataset = val_datasets[idx]\nelse:\n    train_dataset = dataset.CreateTrainDataset(shufflelen = GPARAMS.shuffle)\n    \nif MODE == 'tpu':\n    train_dataset = STRATEGY.experimental_distribute_dataset(train_dataset)\n    if VALIDATION:\n        test_dataset = STRATEGY.experimental_distribute_dataset(test_dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training ML Model Creation and Initialization"},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_ingradients = ComponentFactory(GPARAMS).CreateModelIngradientsInScope()\nml_steps = CreateStepFns(ml_ingradients)\ntrain_step = ml_steps.CreateTrainStepFn()\ntest_step = ml_steps.CreateTestStepFn()\n\n@tf.function\ndef distributed_train_step(dataset_inputs):\n    losses = train_step(dataset_inputs)\n    return losses\n\n@tf.function\ndef distributed_test_step(dataset_inputs):\n    test_step(dataset_inputs)\n\nif MODE == 'tpu':\n    @tf.function\n    def distributed_train_step(dataset_inputs):\n      per_replica_losses = STRATEGY.run(train_step, args=(dataset_inputs,))\n      return STRATEGY.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,axis=None)\n\n    @tf.function\n    def distributed_test_step(dataset_inputs):\n        return STRATEGY.run(test_step, args=(dataset_inputs,))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = [24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72]\nsave_weights = partial(template_save_weights,epochs = epochs, model_step = ml_steps, min_seg = '05', pfp = '02', min_seg_fp = '2', units = 256)\n\ntrain_acc = ml_ingradients.train_acc\ntest_acc = ml_ingradients.test_acc\n\nfor epoch in range(GPARAMS.epoch):\n  # TRAIN LOOP\n    total_loss = 0.0\n    num_batches = 0\n    train_it = iter(train_dataset)\n    for _ in range(GPARAMS.iter_per_epoch):\n        total_loss += distributed_train_step(next(train_it))\n        num_batches += 1\n    train_loss = total_loss / num_batches \n\n    if VALIDATION:\n        for x in test_dataset:\n            distributed_test_step(x)\n\n    template = \"Epoch {}, Loss: {}, Train_Acc: {}, Test_Acc: {}\"\n    print (template.format(epoch+1, train_loss,train_acc.result()*100,test_acc.result()*100))\n\n    train_acc.reset_states()\n    test_acc.reset_states()\n    \n    save_weights(epoch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_steps.model.save_weights('modelv7_e72_i128_fp_s512_s2048_minseg05_u256_fpf02.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ndataset = DatasetSrc(GPARAMS).CreateTrainDataset()\nb1 = next(iter(dataset))\nimg, y = b1\n\nix1 = tf.cast(tf.where(y[:,1] == 1), tf.int32)\n#ix1 = tf.cast(tf.where([False] * 16),tf.int32)\ny_true1 = tf.squeeze(tf.one_hot(tf.gather_nd(y[:,0], tf.expand_dims(ix1, -1)),24, on_value = 1.0, off_value = 0.0))\n\nix2 = tf.cast(tf.where(y[:,1] == 0),tf.int32)\n#ix2 = tf.cast(tf.where([True] * 16),tf.int32)\nys = tf.gather_nd(y[:,0], tf.expand_dims(ix2, -1))\ny_true2 = tf.zeros_like(ys,dtype = tf.float32)\nidxx = tf.stack([ix2, ys], axis = -1)\nwith tf.GradientTape() as tape:\n    pred = ml_steps.model(img,training = True)\n    pred1 = tf.concat(pred, axis = -1)\n\n    y_pred1 = tf.squeeze(tf.gather_nd(pred1, tf.expand_dims(ix1, -1)))\n    y_pred2 = tf.gather_nd(pred1, idxx)\n\n    loss1 = ml_steps.loss(y_true1, y_pred1)\n    loss2 = ml_steps.loss(y_true2, y_pred2)\n    loss = loss1 + loss2\ngradients = tape.gradient(loss2, ml_steps.model.trainable_variables)\nprint(tf.shape(y_true1))\nprint(tf.shape(y_pred1))\nprint(loss)\n\nres = 0.0\nfor gr in gradients:\n    res = res + tf.math.reduce_sum(tf.math.abs(gr))\nprint(res)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n    def CreateTrainStepFn(self):\n        def _train_step(inputs):\n            images, y = inputs\n            y_true = tf.one_hot(y[:,0],self.class_n, on_value = 1.0, off_value = 0.0)\n            with tf.GradientTape() as tape:\n                y_pred = self.model(images, training=True)\n                y_pred = tf.concat(y_pred, axis = -1)\n                loss = self.loss(y_true, y_pred)\n\n            gradients = tape.gradient(loss, self.model.trainable_variables)\n            self.optimize(gradients)\n            self.train_acc.update_state(y_true, y_pred)\n            return loss\n        return _train_step\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_dataset =  DatasetSrc(GPARAMS).CreateUnbatchDataset().batch(4)\nsample = next(iter(tr_dataset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_loss(labels, predictions):\n    loss = cfg['model_params']['loss']['fn'](**cfg['model_params']['loss']['params'])\n    return tf.nn.compute_average_loss(loss(y_true = labels,y_pred = predictions))\n\noptimizer = cfg['model_params']['optim']['fn'](**cfg['model_params']['optim']['params'])\n\ndef train_step(inputs, model, optimizer = optimizer):\n    images, targets = inputs\n    with tf.GradientTape() as tape:\n        predictions = model(images, training=True)\n        loss = compute_loss(targets, predictions)\n\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = tf.math.argmax(sample[1],-1)\nidx = tf.convert_to_tensor([[0,14]])#,[1,23]])\npredictions = tf.reshape(tf.transpose(model(sample[0], training=True),[1,2,0]), [2,24])\npred1 = tf.gather_nd(predictions, idx)\npred2 = predictions[1,...]\nloss1 = compute_loss([[1.0]], pred1)\nloss2 = compute_loss(tf.zeros([1,24]), pred2)\nloss = loss1 + loss2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"with SCOPE:\n    cnn_model = cfg['model_params']['ml_model'](include_top = False, weights = 'imagenet', pooling='avg',\n                                           input_shape = (GPARAMS.img_size_h, GPARAMS.img_size_h, 3))\n    model = create_model(cnn_model,GPARAMS)\n    optimizer = cfg['model_params']['optim']['fn'](**cfg['model_params']['optim']['params'])\n    loss = cfg['model_params']['loss']['fn'](**cfg['model_params']['loss']['params'])\n    model.compile(optimizer=optimizer,loss=loss, metrics=[LWLRAP(GPARAMS.class_n)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(tr_dataset,steps_per_epoch = GPARAMS.iter_per_epoch,epochs = GPARAMS.epoch)\nmodel.save_weights('model_aug_e16_i64_tp_s512_f18000_v2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_train_history(history, 'Just_train_e16_i64_16000_augcor')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ndef train_step(inputs, model, optimizer = optimizer):\n    images = inputs[0]\n    idx = tf.math.argmax(inputs[1],-1)\n    idx1 = tf.convert_to_tensor([[0,21]])\n    idx2 = tf.convert_to_tensor([[1,23]])\n    with tf.GradientTape() as tape:\n        predictions = tf.reshape(tf.transpose(model(sample[0], training=True),[1,2,0]), [2,24])\n        pred1 = tf.gather_nd(predictions, idx1)\n        pred2 = tf.gather_nd(predictions, idx2)#predictions[1,...]\n        loss1 = compute_loss([[1.0]], pred1)\n        loss2 = compute_loss([[1.0]], pred2)#compute_loss(tf.zeros([1,24]), pred2)\n        loss = loss1 + loss2\n\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    return (loss, gradients)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}