{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n!pip install iterative-stratification\n\nimport numpy as np \nimport scipy as sp\nimport sklearn as sl\nimport pandas as pd\nimport librosa\nimport IPython\nimport matplotlib.pyplot as plt\nfrom dataclasses import dataclass\nfrom functools import partial\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nfrom tqdm import tqdm\n\nimport tensorflow as tf\nimport tensorflow.keras as tfk\nimport tensorflow.keras.layers as tfkl\nimport tensorflow.data as tfd\nimport tensorflow_addons as tfa\nimport tensorflow_hub as hub\n\nimport os\nfrom kaggle_datasets import KaggleDatasets\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cfg = { \n    'Training' : False,\n    'parse_params': {\n        'sample_rate' : 48000,\n        'cut' : 5.5,\n        'cut_step': 5.0\n    },\n    'data_params': {\n        'frame_length' : 2048,\n        'frame_step' : 512,\n        'mel_highest_freq' : 16000.0,\n        'mel_lowest_freq' : 100.0,\n        'mel_num_bins' : 256,\n        'img_shape' : (256, 512),\n        'patch_cut' : 5.5\n    },\n    'model_params': {\n        'ml_model': tf.keras.applications.ResNet50, #tf.keras.applications.EfficientNetB3\n        'batchsize_per_tpu': 16,\n        'ml_model': {\n            'fn' : tf.keras.applications.ResNet50,\n            'params' : {'include_top': False, 'weights' : 'imagenet', 'pooling' : 'avg' },\n            'top_drops' : 0.4,\n            'top_size' : 256,\n            'name' : 'JustSecondModel'  \n        },\n    }\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nGCS_DS_PATH = KaggleDatasets().get_gcs_path(\"rfcx-species-audio-detection\")\n\n@dataclass(frozen=True)  # Instances of this class are immutable.\nclass Params:\n    class_n: int = 24\n    sr: float = cfg['parse_params']['sample_rate'] # all wave's sample rate may be 48k \n    cut: float = cfg['parse_params']['cut']\n    cut_step: float = cfg['parse_params']['cut_step']  \n    training: bool = cfg['Training']\n        \n    @property\n    def pfrm_len(self):\n        return int(cfg['parse_params']['cut'] * self.sr)\n    @property\n    def pfrm_step(self):\n        return int(cfg['parse_params']['cut_step'] * self.sr)  \n    @property\n    def step_cnt(self):\n        return int(60.0 / self.cut_step)\n        \n    frm_len: int = cfg['data_params']['frame_length']\n    frm_step: int = cfg['data_params']['frame_step']\n    mel_frq_h: float = cfg['data_params']['mel_highest_freq']\n    mel_frq_l: float = cfg['data_params']['mel_lowest_freq']\n    mel_bins: int = cfg['data_params']['img_shape'][0]\n    img_size_h: int = cfg['data_params']['img_shape'][0]\n    img_size_w: int = cfg['data_params']['img_shape'][1]\n    patch_cut: float = cfg['data_params']['patch_cut']\n        \n    @property\n    def model_fn(self):\n        model_fn = cfg['model_params']['ml_model']\n        model_fn['params']['input_shape'] = (self.img_size_h, self.img_size_w, 3)\n        return model_fn\n\n    test_tfrec: str = GCS_DS_PATH + \"/tfrecords/test\"\n        \n    subm_file: str = \"submission_unspecified.csv\"\n    \n    @property\n    def all_test_tfrec(self):\n        return [os.path.join(self.test_tfrec,filename) for filename in tf.io.gfile.listdir(self.test_tfrec)]\n\n    path_tp_model: str = '/kaggle/input/model-weights-part5/model_v3_e52_s2048_minseg05.h5'\n    path_fp_model: str = ''\n    \nGPARAMS = Params()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_description = {\n    'recording_id': tf.io.FixedLenFeature([], tf.string, default_value=''),\n    'audio_wav': tf.io.FixedLenFeature([], tf.string, default_value=''),\n    'label_info': tf.io.FixedLenFeature([], tf.string, default_value=''),\n}\n\nparse_dtype = {\n    'audio_wav': tf.float32,\n    'recording_id': tf.string,\n}\n\n@tf.function\ndef parse_test_fun(example_proto, params):\n    sample = tf.io.parse_single_example(example_proto, feature_description)\n    wav, _ = tf.audio.decode_wav(sample['audio_wav'], desired_channels=1)\n    seq_len = tf.cast(params.sr * 60.0, tf.int32)\n    wav = tf.reshape(wav,[seq_len])\n    def _cut_slices(i):\n        r = tf.math.minimum(seq_len, i + params.pfrm_len)\n        s = wav[i : r - 1]\n        paddings = tf.convert_to_tensor([[0, params.pfrm_len - r + i]])    \n        s = tf.pad(s,paddings)\n        return {'audio_wav' : s, 'recording_id' : sample['recording_id']}\n    irange = tf.range(params.step_cnt, dtype = tf.int32) * params.pfrm_step\n    return tf.map_fn(_cut_slices, irange, dtype = parse_dtype) \n\n@tf.function\ndef convert_to_spect(sample, params):\n    waveform = sample[\"audio_wav\"]\n    with tf.name_scope('log_mel_features'):\n        fft_length = 2 ** int(np.ceil(np.log(params.frm_len) / np.log(2.0)))\n        num_spectrogram_bins = fft_length // 2 + 1\n        magnitude_spectrogram = tf.abs(tf.signal.stft(signals=waveform,frame_length=params.frm_len,\n                                                        frame_step=params.frm_step,fft_length=fft_length))\n        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(num_mel_bins=params.mel_bins,\n                                                                            num_spectrogram_bins=num_spectrogram_bins,\n                                                                            sample_rate=params.sr,\n                                                                            lower_edge_hertz=params.mel_frq_l,\n                                                                            upper_edge_hertz=params.mel_frq_h)\n        mel_spectrogram = tf.matmul(magnitude_spectrogram, linear_to_mel_weight_matrix)\n        log_mel_spectrogram = tf.math.log(mel_spectrogram + 0.001)\n        return {'x' : tf.transpose(log_mel_spectrogram,[0,2,1])[...,:params.img_size_w], 'y' : sample[\"recording_id\"]}\n    \n\n@tf.function\ndef fit_output(sample, params):\n    img = tf.image.per_image_standardization(tf.expand_dims(sample['x'],-1)) \n    img = tf.squeeze(img)\n    img = (img - tf.math.reduce_min(img)) / (tf.math.reduce_max(img) - tf.math.reduce_min(img))\n    return (img, sample[\"y\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(cnn_model, params):\n    for layer in cnn_model.layers:\n        layer.trainable = True\n    input = tfkl.Input(shape = (params.img_size_h, params.img_size_w))\n    x = tfkl.Reshape((params.img_size_h, params.img_size_w,1))(input)\n    x = tfkl.Conv2D(filters = 3, kernel_size = 7, padding='same', activation = 'sigmoid')(x)\n    x = cnn_model(x)\n    x = tfkl.Dropout(0.4)(x)\n    x = tfkl.Dense(1024, activation='relu')(x)\n    x = tfkl.Dropout(0.4)(x)\n    output = tfkl.Dense(params.class_n, activation = 'sigmoid')(x)\n    model = tfk.Model(name='yamnet_frames', inputs=input,outputs=output)\n    return model\n\ndef create_modelV2(cnn_model, params):   \n    inputs = tfkl.Input(shape = (params.img_size_h, params.img_size_w))\n    x = tfkl.Reshape((params.img_size_h, params.img_size_w,1))(inputs)\n    x = tfkl.Conv2D(filters = 3, kernel_size = 7, padding='same', activation = 'sigmoid')(x)\n    x = cnn_model(x)\n    outputs = []\n    for _ in range(params.class_n):\n        t = tfkl.Dropout(0.4)(x, training = False)\n        t = tfkl.Dense(params.model_fn['top_size'], activation='relu')(t)\n        t = tfkl.Dropout(params.model_fn['top_drops'])(t, training = False)\n        t = tfkl.Dense(1, activation = 'sigmoid')(t)\n        outputs.append(t)\n    outputs = tfkl.concatenate(outputs)\n    model = tfk.Model(name=params.model_fn['name'], inputs=inputs,outputs=outputs)\n    return model\n\ndef FetchModel(params, ver = 2):\n    cnn_model = cnn_model = params.model_fn['fn'](**params.model_fn['params'])\n    model = None\n    if ver == 1:\n        model = create_model(cnn_model,params)\n    else:\n        model = create_modelV2(cnn_model,params)\n    model.load_weights(params.path_tp_model)\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_mix(epoch, version, ms = '1',shuffle = 2048):\n    root = './'\n    files = [os.path.join(root,file) for file in os.listdir(root) if file.endswith(\".csv\")]\n    cols = ['s{}'.format(i) for i in range(24)]\n    df = pd.read_csv(files[0])\n    mm = None\n    for i,file in enumerate(files):\n        print(f\"{i} -- {file}\")\n        dff = pd.read_csv(file)\n        m = dff[cols].to_numpy()\n        if i == 0:\n            mm = m\n        else:\n            mm = np.maximum(mm,m)\n    df[cols] = mm\n    df.to_csv(f'./submission_mix_v{version}_e{epoch}_ms{ms}_s{shuffle}_f16_f18_f20.csv', index = False)\n\n#---------------------------------------------------------------------------------------------------------------------------\n\ndef make_prediction(params):\n    print(params)\n    print(\"-------------------Begin------------------------------------\")\n    testdataset = (tfd.TFRecordDataset(params.all_test_tfrec)\n                   .map(partial(parse_test_fun, params = params), num_parallel_calls=AUTOTUNE)\n                   .map(partial(convert_to_spect, params = params), num_parallel_calls=AUTOTUNE)\n                   .map(partial(fit_output, params = params), num_parallel_calls=AUTOTUNE))\n\n    model = FetchModel(params)\n\n    recids = []\n    rows = []\n    for data,recid in tqdm(testdataset):\n        prob = model(data, training = False)\n        prob = tf.reduce_max(prob, axis = 0)\n        row = [recid[0].numpy().decode()] + list(prob.numpy())\n        rows.append(row)\n    cols = ['recording_id'] + ['s{}'.format(i) for i in range(24)]\n    subdf = pd.DataFrame(rows, columns = cols)\n    subdf.to_csv(params.subm_file,index=False)\n    print(\"------------------End---------------------------------------\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\npath_tp_model = ['/kaggle/input/model-weights-v7-fpf02/model_v7_e44_s2048_ms05_msfp2_u256_tp0_pfp02.h5',               \n                 '/kaggle/input/model-weights-v7-fpf02/model_v7_e48_s2048_ms05_msfp2_u256_tp0_pfp02.h5',               \n                 '/kaggle/input/model-weights-v7-fpf02/model_v7_e52_s2048_ms05_msfp2_u256_tp0_pfp02.h5',                 \n                 '/kaggle/input/model-weights-v7-fpf02/model_v7_e56_s2048_ms05_msfp2_u256_tp0_pfp02.h5',\n                 '/kaggle/input/model-weights-v7-fpf02/model_v7_e60_s2048_ms05_msfp2_u256_tp0_pfp02.h5',                \n                 '/kaggle/input/model-weights-v7-fpf02/model_v7_e64_s2048_ms05_msfp2_u256_tp0_pfp02.h5',                 \n                 '/kaggle/input/model-weights-v7-fpf02/model_v7_e68_s2048_ms05_msfp2_u256_tp0_pfp02.h5',\n                 '/kaggle/input/model-weights-v7-fpf02/modelv7_e72_i128_fp_s512_s2048_minseg05_u256_fpf02.h5',\n                 '/kaggle/input/model-weights-v7-fpf02/model_v7_e68_s2048_ms05_msfp2_u256_tp0_pfp02.h5',\n                 '/kaggle/input/model-weights-v7-fpf02/modelv7_e72_i128_fp_s512_s2048_minseg05_u256_fpf02.h5']\nepochs = [44,48,52,56,60,64,68,72,68,72]\nfrqhv = [(16000.0,),(16000.0,),(16000.0,),(16000.0,),(16000.0,),(16000.0,),(16000.0,),(16000.0,),(18000.0,),(18000.0,)]\n'''\npath_tp_model = ['/kaggle/../input/model-weights-v7-fpf03/model_v7_e64_s2048_ms05_msfp2_u256_tp0_pfp03.h5',               \n                 '/kaggle/../input/model-weights-v7-fpf03/model_v7_e68_s2048_ms05_msfp2_u256_tp0_pfp03.h5',               \n                 '/kaggle/../input/model-weights-v7-fpf03/model_v7_e72_i128_fp_s512_s2048_minseg05_u256.h5']\nepochs = [64,68,72]\nfrqhv = [(16000.0,),(16000.0,),(16000.0,)]\n\nversion = 7\nshuffle = 2048\nu = 256\nms = '05'\nfpf = '02'\n\nfor tp_path, frqv, e in zip(path_tp_model,frqhv,epochs):\n    for i in range(len(frqv)):\n        subm_file = f\"submission_v{version}_e{e}_s{shuffle}_ms{ms}_f{int(frqv[i])}_u{u}_fpf{fpf}.csv\"\n        params = Params(subm_file = subm_file, mel_frq_h = frqv[i], path_tp_model = tp_path)\n        make_prediction(params) \n    \nmake_mix(epoch = '64___72_pfp03', version = version, ms = ms, shuffle = shuffle)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1000000):\n    print(\"########################################################################################################\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch = 48\nversion = 5\nshuffle = 2048\nms = '05'\npath_tp_model = '/kaggle/input/model-weights-part5/model_v3_e48_s2048_minseg05.h5'\nfrqhv = [16000.0,18000.0,20000.0, 24000.0]\n\nfor frq in frqhv:\n    subm_file = f\"submission_v{version}_e{epoch}_s{shuffle}_ms{ms}_f{int(frq)}.csv\"\n    params = Params(subm_file = subm_file, mel_frq_h = frq, path_tp_model = path_tp_model)\n    make_prediction(params) \n    \nmake_mix(epoch = epoch, version = version, ms = ms, shuffle = shuffle)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(100000):\n    print(\"########################################################################################################\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_tp_model = '/kaggle/input/model-weights-part4/modelv3_e28_i64_tp_s512_s2048.h5'\nsubm_file = \"submission_v3_e28_i64_tp_s512_s2048_f20000.csv\"\nmel_frq_h = 20000.0\n\nGPARAMS = Params(path_tp_model = path_tp_model, subm_file = subm_file, mel_frq_h = mel_frq_h)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_prediction(params):\n    testdataset = (tfd.TFRecordDataset(params.all_test_tfrec)\n                   .map(partial(parse_test_fun, params = params), num_parallel_calls=AUTOTUNE)\n                   .map(partial(convert_to_spect, params = params), num_parallel_calls=AUTOTUNE)\n                   .map(partial(fit_output, params = params), num_parallel_calls=AUTOTUNE))\n\n    model = FetchModel(params)\n\n    recids = []\n    rows = []\n    for data,recid in tqdm(testdataset):\n        prob = model(data, training = False)\n        prob = tf.reduce_max(prob, axis = 0)\n        row = [recid[0].numpy().decode()] + list(prob.numpy())\n        rows.append(row)\n    cols = ['recording_id'] + ['s{}'.format(i) for i in range(24)]\n    subdf = pd.DataFrame(rows, columns = cols)\n    subdf.to_csv(params.subm_file,index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(GPARAMS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdataset = (tfd.TFRecordDataset(GPARAMS.all_test_tfrec)\n               .map(partial(parse_test_fun, params = GPARAMS), num_parallel_calls=AUTOTUNE)\n               .map(partial(convert_to_spect, params = GPARAMS), num_parallel_calls=AUTOTUNE)\n               .map(partial(fit_output, params = GPARAMS), num_parallel_calls=AUTOTUNE))\n\nmodel = FetchModel(GPARAMS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recids = []\nrows = []\nfor data,recid in tqdm(testdataset):\n    prob = model(data, training = False)\n    prob = tf.reduce_max(prob, axis = 0)\n    row = [recid[0].numpy().decode()] + list(prob.numpy())\n    rows.append(row)\ncols = ['recording_id'] + ['s{}'.format(i) for i in range(24)]\nsubdf = pd.DataFrame(rows, columns = cols)\nsubdf.to_csv(GPARAMS.subm_file,index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"path_tp_model = '/kaggle/input/model-weights-part4/modelv3_e28_i64_tp_s512_s2048.h5'\nsubm_file = \"submission_v3_e28_i64_tp_s512_s2048_f20000.csv\"\nmel_frq_h = 20000.0\n\nGPARAMS = Params(path_tp_model = path_tp_model, subm_file = subm_file, mel_frq_h = mel_frq_h)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(GPARAMS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdataset = (tfd.TFRecordDataset(GPARAMS.all_test_tfrec)\n               .map(partial(parse_test_fun, params = GPARAMS), num_parallel_calls=AUTOTUNE)\n               .map(partial(convert_to_spect, params = GPARAMS), num_parallel_calls=AUTOTUNE)\n               .map(partial(fit_output, params = GPARAMS), num_parallel_calls=AUTOTUNE))\n\nmodel = FetchModel(GPARAMS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recids = []\nrows = []\nfor data,recid in tqdm(testdataset):\n    prob = model(data, training = False)\n    prob = tf.reduce_max(prob, axis = 0)\n    row = [recid[0].numpy().decode()] + list(prob.numpy())\n    rows.append(row)\ncols = ['recording_id'] + ['s{}'.format(i) for i in range(24)]\nsubdf = pd.DataFrame(rows, columns = cols)\nsubdf.to_csv(GPARAMS.subm_file,index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"path_tp_model = '/kaggle/input/model-weights-part4/modelv3_e34_i64_tp_s512_s2048.h5'\nsubm_file = \"submission_v3_e34_i64_tp_s512_s2048_f16000.csv\"\nmel_frq_h = 16000.0\n\nGPARAMS = Params(path_tp_model = path_tp_model, subm_file = subm_file, mel_frq_h = mel_frq_h)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(GPARAMS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdataset = (tfd.TFRecordDataset(GPARAMS.all_test_tfrec)\n               .map(partial(parse_test_fun, params = GPARAMS), num_parallel_calls=AUTOTUNE)\n               .map(partial(convert_to_spect, params = GPARAMS), num_parallel_calls=AUTOTUNE)\n               .map(partial(fit_output, params = GPARAMS), num_parallel_calls=AUTOTUNE))\n\nmodel = FetchModel(GPARAMS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recids = []\nrows = []\nfor data,recid in tqdm(testdataset):\n    prob = model(data, training = False)\n    prob = tf.reduce_max(prob, axis = 0)\n    row = [recid[0].numpy().decode()] + list(prob.numpy())\n    rows.append(row)\ncols = ['recording_id'] + ['s{}'.format(i) for i in range(24)]\nsubdf = pd.DataFrame(rows, columns = cols)\nsubdf.to_csv(GPARAMS.subm_file,index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"path_tp_model = '/kaggle/input/model-weights-part4/modelv3_e34_i64_tp_s512_s2048.h5'\nsubm_file = \"submission_v3_e34_i64_tp_s512_s2048_f18000.csv\"\nmel_frq_h = 18000.0\n\nGPARAMS = Params(path_tp_model = path_tp_model, subm_file = subm_file, mel_frq_h = mel_frq_h)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(GPARAMS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdataset = (tfd.TFRecordDataset(GPARAMS.all_test_tfrec)\n               .map(partial(parse_test_fun, params = GPARAMS), num_parallel_calls=AUTOTUNE)\n               .map(partial(convert_to_spect, params = GPARAMS), num_parallel_calls=AUTOTUNE)\n               .map(partial(fit_output, params = GPARAMS), num_parallel_calls=AUTOTUNE))\n\nmodel = FetchModel(GPARAMS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recids = []\nrows = []\nfor data,recid in tqdm(testdataset):\n    prob = model(data, training = False)\n    prob = tf.reduce_max(prob, axis = 0)\n    row = [recid[0].numpy().decode()] + list(prob.numpy())\n    rows.append(row)\ncols = ['recording_id'] + ['s{}'.format(i) for i in range(24)]\nsubdf = pd.DataFrame(rows, columns = cols)\nsubdf.to_csv(GPARAMS.subm_file,index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 5"},{"metadata":{"trusted":true},"cell_type":"code","source":"path_tp_model = '/kaggle/input/model-weights-part4/modelv3_e34_i64_tp_s512_s2048.h5'\nsubm_file = \"submission_v3_e34_i64_tp_s512_s2048_f20000.csv\"\nmel_frq_h = 20000.0\n\nGPARAMS = Params(path_tp_model = path_tp_model, subm_file = subm_file, mel_frq_h = mel_frq_h)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(GPARAMS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdataset = (tfd.TFRecordDataset(GPARAMS.all_test_tfrec)\n               .map(partial(parse_test_fun, params = GPARAMS), num_parallel_calls=AUTOTUNE)\n               .map(partial(convert_to_spect, params = GPARAMS), num_parallel_calls=AUTOTUNE)\n               .map(partial(fit_output, params = GPARAMS), num_parallel_calls=AUTOTUNE))\n\nmodel = FetchModel(GPARAMS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recids = []\nrows = []\nfor data,recid in tqdm(testdataset):\n    prob = model(data, training = False)\n    prob = tf.reduce_max(prob, axis = 0)\n    row = [recid[0].numpy().decode()] + list(prob.numpy())\n    rows.append(row)\ncols = ['recording_id'] + ['s{}'.format(i) for i in range(24)]\nsubdf = pd.DataFrame(rows, columns = cols)\nsubdf.to_csv(GPARAMS.subm_file,index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(100000):\n    print(\"########################################################################################################\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}