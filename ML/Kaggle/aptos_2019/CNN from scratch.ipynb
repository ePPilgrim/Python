{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "VLD_BATCH_SIZE = 50\n",
    "TRAIN_BATCH_SIZE = 30\n",
    "SHUFFLE_BUFFER_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "\n",
    "TRAIN_DIR = './data/pre_512_30/train_images/'\n",
    "TRAIN_DIR = './data/pre/train_images/'\n",
    "\n",
    "SAVE_TO_DIR = './data/augment/'\n",
    "\n",
    "TRAIN_DF = pd.read_csv('./data/train.csv')\n",
    "TRAIN_SET = [[1]]\n",
    "TRAIN_CNTS = [[300]]\n",
    "VLD_CNTS = [[70]]\n",
    "TRAIN_CNT = 1800\n",
    "VLD_CNT = 198\n",
    "\n",
    "for i in range(100):\n",
    "    TRAIN_DF = TRAIN_DF.sample(frac = 1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4], dtype=int64),\n",
       " array([1805,  370,  999,  193,  295], dtype=int64))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(TRAIN_DF['diagnosis'].values,return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DF['diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divintosets(df, train, test, classes):\n",
    "    traindic = {'filename' : [], 'class' : []}\n",
    "    testdic = {'filename' : [], 'class' : []}\n",
    "    clsid = 0\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(classes[i])):\n",
    "            lx = df['diagnosis'] == classes[i][j]\n",
    "            fn = [x + '.png' for x in df['id_code'][lx].values]\n",
    "            traindic['filename'] += fn[:train[i][j]]\n",
    "            traindic['class'] += [str(clsid)] * train[i][j]\n",
    "            testdic['filename'] += fn[train[i][j] : train[i][j] + test[i][j]]\n",
    "            testdic['class'] += [str(clsid)] * test[i][j]\n",
    "        clsid += 1\n",
    "    train_df = pd.DataFrame(data = traindic)\n",
    "    test_df = pd.DataFrame(data = testdic)\n",
    "    for i in range(10):\n",
    "        train_df = train_df.sample(frac = 1).reset_index(drop=True)\n",
    "        test_df = test_df.sample(frac = 1).reset_index(drop=True)\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = divintosets(TRAIN_DF, TRAIN_CNTS, VLD_CNTS, TRAIN_SET) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_gen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range = 40,\n",
    "                                                          width_shift_range = 0.2,\n",
    "                                                          height_shift_range = 0.2,\n",
    "                                                          shear_range = 0.2,\n",
    "                                                          zoom_range = 0.2,\n",
    "                                                          fill_mode = 'nearest')\n",
    "tr_gen = tran_gen.flow_from_dataframe(train_df,\n",
    "                                      target_size = (IMG_SIZE, IMG_SIZE), \n",
    "                                      directory = TRAIN_DIR,\n",
    "                                      save_to_dir = SAVE_TO_DIR\n",
    "                                 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for img in tr_gen:\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = './data/temp/'\n",
    "df = pd.DataFrame({'filename' : ['xxx.png','yyy.png', 'zzz.png'], 'class' : ['7','8','9']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "def dumy(img):\n",
    "    noise = np.random.normal(0,9,img.shape)\n",
    "    img=cv2.addWeighted ( img.astype(float),1, noise ,1 ,0)\n",
    "    lx = img < 0\n",
    "    img[lx] = 0\n",
    "    lx = img > 255\n",
    "    img[lx] = 255\n",
    "    return img\n",
    "\n",
    "gen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range = 360,\n",
    "                                                    preprocessing_function = dumy)\n",
    "tr_gen = gen.flow_from_dataframe(df,\n",
    "                                      target_size = (IMG_SIZE, IMG_SIZE), \n",
    "                                      directory = p,\n",
    "                                      save_to_dir = p,\n",
    "                                      class_mode = 'categorical',\n",
    "                                 batch_size = 3,\n",
    "                                 shuffle = True\n",
    "                                 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = iter(tr_gen).next()\n",
    "#img = img[0].reshape(224,224,3).astype(int)\n",
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "#model.add(layers.Input((IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(layers.GaussianNoise(stddev = 0.1,input_shape=(IMG_SIZE,IMG_SIZE,3))(training = False))\n",
    "\n",
    "#model.compile()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = iter(tr_gen).next()\n",
    "#img = model.predict(tr_gen)\n",
    "img = tf.keras.layers.GaussianNoise(stddev = 224)(inputs = img, training = True)\n",
    "#cv2.imwrite(p+ 'qqq.png')\n",
    "img = img[0].numpy().reshape((224,224,3)).astype(int)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255.)\n",
    "tr_gen = gen.flow_from_dataframe(train_df, \n",
    "                                 target_size = (IMG_SIZE, IMG_SIZE), \n",
    "                                 class_mode = 'binary',\n",
    "                                 directory = TRAIN_DIR,\n",
    "                                 batch_size = TRAIN_BATCH_SIZE\n",
    "                                 )\n",
    "vld_gen = gen.flow_from_dataframe(test_df, \n",
    "                                 target_size = (IMG_SIZE, IMG_SIZE), \n",
    "                                 class_mode = 'binary',\n",
    "                                 directory = TRAIN_DIR,\n",
    "                                  batch_size = 1,\n",
    "                                  shuffle = False\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape=(IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3,3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "#model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(512, activation = 'relu'))\n",
    "model.add(layers.Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(tr_gen,\n",
    "                    steps_per_epoch = TRAIN_CNT//TRAIN_BATCH_SIZE,\n",
    "                    epochs = 3,\n",
    "                    validation_data = vld_gen,\n",
    "                    validation_steps = VLD_CNT//VLD_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = TRAIN_DF.copy()\n",
    "v = [x + '.png' for x in pred_df['id_code'].values]\n",
    "pred_df['id_code'] = v\n",
    "v = [str(x%2) for x in pred_df['diagnosis'].values]\n",
    "pred_df['diagnosis'] = v\n",
    "pred_df.columns = ['filename','class']\n",
    "pred_gen = gen.flow_from_dataframe(pred_df, \n",
    "                                 target_size = (IMG_SIZE, IMG_SIZE), \n",
    "                                 class_mode = 'binary',\n",
    "                                 directory = TRAIN_DIR,\n",
    "                                  batch_size = 64,\n",
    "                                  shuffle = False\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "vv = model.predict(pred_gen)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c1,c2 in vld_gen:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = c1.reshape(224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR + test_df['filename'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = TRAIN_DIR + test_df['filename'][0]\n",
    "img = tf.io.read_file(file_path)\n",
    "img = tf.image.decode_png(img, channels=3)\n",
    "img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "#img = (img/255)\n",
    "#model.predict(tf.reshape(img,(1,224,224,3)))[0,0]\n",
    "#test_df['class'][0]\n",
    "print(\"min = {}, max = {}\".format(np.min(img), np.max(img)))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictt = {'p' : [], 'c' : []}\n",
    "acc = 0.0\n",
    "for i in range(test_df.shape[0]):  \n",
    "    x = vv[i][0]\n",
    "    ccc = test_df.iat[i,1]\n",
    "    if x > 0.5 and ccc == '2':\n",
    "        acc += 1.0\n",
    "    if x <=0.5 and ccc == '0':\n",
    "        acc += 1.0\n",
    "    dictt['p'].append(x)\n",
    "    dictt['c'].append(ccc)       \n",
    "print(acc / 198)  \n",
    "newdf = pd.DataFrame(dictt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictt = {'p' : [], 'c' : []}\n",
    "acc = 0.0\n",
    "for _,fn in test_df.iterrows():  \n",
    "    file_path = TRAIN_DIR + fn['filename']\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = (img/255) - 1\n",
    "    x = model.predict(tf.reshape(img,(1,224,224,3)))\n",
    "    x = x[0,0]\n",
    "    if x > 0.5 and fn['class'] == '2':\n",
    "        acc += 1.0\n",
    "    if x <=0.5 and fn['class'] == '0':\n",
    "        acc += 1.0\n",
    "    dictt['p'].append(x)\n",
    "    dictt['c'].append(fn['class'])       \n",
    "print(acc / 198)  \n",
    "newdf = pd.DataFrame(dictt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictt['p'] += 4.9\n",
    "print(dictt['p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _,row in test_df.iterrows():\n",
    "    print(row['filename'],row['class'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
