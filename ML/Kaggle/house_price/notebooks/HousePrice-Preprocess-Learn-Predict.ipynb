{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as npma\n",
    "import scipy as sc\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing.data import QuantileTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, Lasso, LassoLars,TheilSenRegressor, OrthogonalMatchingPursuit,  BayesianRidge, LassoLarsIC, Ridge,ARDRegression,SGDRegressor,HuberRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "os.sys.path.append(os.path.pardir)\n",
    "from src.models.ConvexRegressor import ConvexRegressor\n",
    "from src.models.ConvexRegressor import convregparam\n",
    "from src.models.ConvexRegressor import convregconv\n",
    "\n",
    "#############################################################################################################\n",
    "project_dir =os.path.pardir\n",
    "raw_path = os.path.join(project_dir,'data','processed')\n",
    "train_path = os.path.join(raw_path, 'train.csv')\n",
    "test_path = os.path.join(raw_path, 'test.csv')\n",
    "sns.set()\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "train = train.drop(['Id','Unnamed: 0'],axis = 1)\n",
    "test = test.drop(['Unnamed: 0'],axis = 1)\n",
    "y = train['SalePrice'].values\n",
    "Ids = test['Id'].values\n",
    "train = train.drop('SalePrice',axis = 1)\n",
    "flds = train.columns\n",
    "train_x = train.values\n",
    "test_x = test.drop('Id',axis = 1).values\n",
    "\n",
    "#################################################################################################################\n",
    "def Score(x, y, scaler, solver, q = 0.4, fldmask = None):\n",
    "    scaler = scaler.fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    yscaler = QuantileTransformer(output_distribution='normal').fit(y.reshape([-1,1]))\n",
    "    y = yscaler.transform(y.reshape([-1,1])).ravel()\n",
    "    if fldmask is not None:\n",
    "        x = x[:,fldmask]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=q, random_state=0)   \n",
    "    yscaler = QuantileTransformer(output_distribution='normal').fit(y_train.reshape([-1,1]))\n",
    "    y_train = yscaler.transform(y_train.reshape([-1,1])).ravel()        \n",
    "    solver = solver.fit(x_train, y_train)\n",
    "    score = solver.score(x_test, y_test)\n",
    "    print(score)\n",
    "    return solver\n",
    "\n",
    "def LearnAndPredict(x_test,x, y, scaler, solver, ids,issplit = True, plot = False, fldmask = None, filename = 'temp.csv'):\n",
    "    yscaler = QuantileTransformer(output_distribution='normal').fit(y.reshape([-1,1]))\n",
    "    y = yscaler.transform(y.reshape([-1,1])).ravel()\n",
    "    if fldmask is not None:\n",
    "        x = x[:,fldmask]\n",
    "        x_test = x_test[:,fldmask]\n",
    "    if scaler is not None:\n",
    "        if issplit == False:\n",
    "            rx = np.arange(x.shape[0])\n",
    "            x = np.vstack((x,x_test))   \n",
    "        scaler = scaler.fit(x)\n",
    "        x = scaler.transform(x)\n",
    "        if issplit == False:\n",
    "            x_test = x[np.arange(rx.shape[0],x.shape[0])]\n",
    "            x = x[rx]\n",
    "        else:\n",
    "            x_test = scaler.transform(x_test)\n",
    "    solver = solver.fit(x, y)\n",
    "    y = solver.predict(x_test)\n",
    "    y = yscaler.inverse_transform(y.reshape([-1,1])).ravel()\n",
    "    df_submission = pd.DataFrame({'Id': ids, 'SalePrice' : y} )\n",
    "    submission_data_path = os.path.join(os.path.pardir,'data','external')\n",
    "    submission_file_path = os.path.join(submission_data_path, filename)\n",
    "    df_submission.to_csv(submission_file_path, index=False)\n",
    "    if hasattr(solver, 'best_score_'):\n",
    "        print(solver.best_score_)\n",
    "    if hasattr(solver, 'best_params_'):\n",
    "        print(solver.best_params_)\n",
    "    if plot == True:\n",
    "        sns.distplot(y,fit = norm)\n",
    "    return solver\n",
    "\n",
    "def linear_ml_solve(x, y, scaler, solver, q = 0.4):\n",
    "    yscaler = QuantileTransformer(output_distribution='normal').fit(y.reshape([-1,1]))\n",
    "    y = yscaler.transform(y.reshape([-1,1])).ravel()\n",
    "    if scaler is not None:\n",
    "        x = scaler.fit_transform(x)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=q, random_state=0)\n",
    "    solver = solver.fit(x_train, y_train)\n",
    "    score = solver.score(x_test,y_test)\n",
    "    print(score)\n",
    "    y = solver.predict(x_test)\n",
    "    y = yscaler.inverse_transform(y.reshape([-1,1])).ravel()\n",
    "    if hasattr(solver, 'best_score_'):\n",
    "        print(solver.best_score_)\n",
    "    if hasattr(solver, 'best_params_'):\n",
    "        print(solver.best_params_)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = LearnAndPredict(test_x,train_x, y, scaler = RobustScaler(), solver = Lasso(alpha = 0.001,max_iter = 10000,tol = 0.0001), ids = Ids, filename = 'LassoRidge.csv')\n",
    "fldmask = solver.coef_ == 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Lasso(alpha = 0.001,max_iter = 10000,tol = 0.0001)\n",
    "Score(train_x, y, scaler, solver, q = 0.4, fldmask = fldmask)\n",
    "#0.6838057972470732\n",
    "Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)\n",
    "#0.9182196591388715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids, filename = 'Lasso.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.ARDRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = ARDRegression()\n",
    "Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)\n",
    "#0.9091333855168815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids, fldmask =, filename = 'ARDRegression.csv')\n",
    "#0.13142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids, fldmask = fldmask, filename = 'ARDRegressionReduced.csv')\n",
    "#0.24144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "est1 = Ridge()\n",
    "est2 = Lasso()\n",
    "estimators = [est1,est2]\n",
    "cest = ConvexRegressor(ests=estimators)\n",
    "param_grid = convregparam(est2,{'alpha': [ 7.0, 6.0, 3.0, 0.02,0.001, 0.00099, 0.009, 0.0008]})\n",
    "param_grid.update(convregparam(est1,{'alpha' : [7.0, 6.0, 4.0, 2.0, 0.6,0.5,0.55,0.45]}))\n",
    "param_grid.update({'convparams' : [convregconv(estimators,[0.11, 0.89]), convregconv(estimators,[0.1,0.9]),\n",
    "                                   convregconv(estimators,[0.09, 0.91]), convregconv(estimators,[0.05,0.95]),\n",
    "                                   convregconv(estimators,[0.01,0.99]), convregconv(estimators,[0.001,0.999])]})\n",
    "\n",
    "gsolver = GridSearchCV(cest, cv=5,param_grid=param_grid)\n",
    "house_price = LearnAndPredict(test_x,train_x, y, scaler, solver = gsolver, ids = Ids, q = 0.4, filename = 'LassoRidge.csv')\n",
    "#0.919300261382389\n",
    "#{'Lasso$$&&$$alpha': 0.001, 'Ridge$$&&$$alpha': 7.0, 'convparams': {'Ridge': 0.001, 'Lasso': 0.999}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "loss = ['squared_loss','huber','epsilon_insensitive','squared_epsilon_insensitive']\n",
    "penalty = ['l1','l2']\n",
    "param_grid = { 'alpha': [0.0005, 0.0009, 0.001, 0.0015, 0.0019, 0.002,0.005,0.01,0.05,0.1]}\n",
    "#Such as this task is solved by iteration so the is no reason to use gread search routines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## 4.1 Huber + L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = SGDRegressor(alpha = 0.001, loss = 'huber', penalty = 'l1', epsilon = 1.5, max_iter = 200000, warm_start = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solver = SGDRegressor(alpha = 0.001, loss = 'huber', penalty = 'l1', epsilon = 0.1, max_iter = 150000, warm_start = True)\n",
    "solver = LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids, filename = 'SGDRegressor_huber_l1.csv')\n",
    "#0.124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)\n",
    "#0.9184762393457621"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Epsilon_insensitive + L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = SGDRegressor(alpha = 0.001, loss = 'epsilon_insensitive',epsilon = 0.1, penalty = 'l1', max_iter = 150000, warm_start = True)\n",
    "solver = Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)\n",
    "#0.855235126971956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.max_iter = 300000\n",
    "solver = LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids, filename = 'SGDRegressor_EpsilonInsensitive_l1.csv')\n",
    "#0.13001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Squared_Epsilon_Insensitive + L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = SGDRegressor(alpha = 0.001, loss = 'squared_epsilon_insensitive',epsilon = 0.1, penalty = 'l1', max_iter = 150000, warm_start = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Huber Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = HuberRegressor(epsilon=2.35, max_iter=1000, alpha=0.0001, warm_start=True, fit_intercept=True, tol=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = HuberRegressor(epsilon=2.35, max_iter=1000, alpha=0.0001, warm_start=True, fit_intercept=True, tol=1e-05)\n",
    "solver = Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)\n",
    "#0.9213839425014468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids, filename = 'HuberRegressor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = HuberRegressor(epsilon=2.35, max_iter=10000, alpha=0.0001, warm_start=False, fit_intercept=True, tol=1e-05)\n",
    "param_grid = {'alpha': [0.00001, 0.00005,0.00008, 0.0001, 0.0005, 0.0009, 0.001, 0.0015, 0.0019, 0.002]}#,\n",
    "             #'epsilon' : [1.0, 1.5, 2.0, 2.35, 2.5, 2.75,3.0]}\n",
    "solver = GridSearchCV(solver, cv=5,param_grid=param_grid)\n",
    "solver = LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids, filename = 'HuberRegressor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = HuberRegressor(epsilon=2.35, max_iter=1000, alpha=0.0001, warm_start=True, fit_intercept=True, tol=1e-05)\n",
    "solver = Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = HuberRegressor(epsilon=2.35, max_iter=1000, alpha=0.0001, warm_start=True, fit_intercept=True, tol=1e-05)\n",
    "param_grid = {'alpha': [0.00001, 0.00005,0.00008, 0.0001, 0.0005, 0.0009, 0.001, 0.0015, 0.0019, 0.002],\n",
    "             'epsilon' : [2.7, 2.71, 2.72, 2.73, 2.74, 2.75, 2.76, 2.77, 2.78, 2.79, 2.8]}\n",
    "solver = GridSearchCV(solver, cv=5,param_grid=param_grid)\n",
    "solver = LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids, filename = 'HuberRegressor.csv')\n",
    "#this the last one and it is the most high performance\n",
    "#0.9158018800233361\n",
    "#{'alpha': 5e-05, 'epsilon': 2.7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = HuberRegressor(epsilon=2.35, max_iter=1000, alpha=0.0001, warm_start=True, fit_intercept=True, tol=1e-05)\n",
    "solver = LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids, issplit = False,  filename = 'HuberRegressor.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 6. OrthogonalMatchingPursuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = OrthogonalMatchingPursuit(n_nonzero_coefs=100, tol=None, fit_intercept=False, normalize=True, precompute='auto')\n",
    "scaler = StandardScaler()\n",
    "scaler = RobustScaler()\n",
    "solver = Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = OrthogonalMatchingPursuit(n_nonzero_coefs=None, tol=None, fit_intercept=False, normalize=True, precompute='auto')\n",
    "#scaler = StandardScaler()\n",
    "scaler = RobustScaler()\n",
    "solver = LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids,  filename = 'ORMATCHPURS.csv')\n",
    "#Not so good method - only 0.125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. TheilSenRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "solver = TheilSenRegressor(fit_intercept=True, copy_X=True, max_subpopulation=10000.0, \n",
    "                           n_subsamples=None, max_iter=300, tol=0.001, random_state=None, n_jobs=None, verbose=False)\n",
    "solver = Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "solver = TheilSenRegressor(fit_intercept=True, copy_X=True, max_subpopulation=10000.0, \n",
    "                           n_subsamples=None, max_iter=3000, tol=0.001, random_state=None, n_jobs=None, verbose=False)\n",
    "solver = LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids,  filename = 'TheilSenReg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "solver = BayesianRidge(n_iter=1000, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06, \n",
    "                       compute_score=False, fit_intercept=True, normalize=False, copy_X=True, verbose=False)\n",
    "solver = Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "solver = BayesianRidge(n_iter=30000, tol=0.001, alpha_1=1e-09, alpha_2=8e-01, lambda_1=8e-01, lambda_2=1e-09, \n",
    "                       compute_score=False, fit_intercept=True, normalize=False, copy_X=True, verbose=False)\n",
    "param_grid = {'alpha_1': [1e-07, 1e-06,1e-05,1e-04,1e-03,1e-02,1e-01],\n",
    "             'alpha_2' : [1e-01,1.3e-01,1.5e-01,2e-01, 2.5e-01, 3e-01],\n",
    "             'lambda_2': [1e-07, 1e-06,1e-05,1e-04,1e-03,1e-02,1e-01],\n",
    "             'lambda_1': [1e-01,1.3e-01,1.5e-01,2e-01, 2.5e-01, 3e-01]}\n",
    "#solver = GridSearchCV(solver, cv=5,param_grid=param_grid)\n",
    "solver = LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids,  filename = 'BayesianRidge.csv')\n",
    "#0.9159600824373367\n",
    "#{'alpha_1': 1e-07, 'alpha_2': 0.1, 'lambda_1': 0.1, 'lambda_2': 1e-07}\n",
    "#0.12264 - for optimal given above\n",
    "#0.12267 - for default implementation \n",
    "#0.9157352390453596\n",
    "#{'alpha_1': 1e-07, 'alpha_2': 0.3, 'lambda_1': 0.1, 'lambda_2': 0.1}\n",
    "#0.12361\n",
    "#0.9159698654626581\n",
    "#{'alpha_1': 1e-07, 'alpha_2': 0.3, 'lambda_1': 0.3, 'lambda_2': 1e-07}\n",
    "#0.12259\n",
    "#0.12254\n",
    "#0.12246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "solver = BayesianRidge(n_iter=1000, tol=0.001, alpha_1=1e-07, alpha_2=1e-01, lambda_1=1e-06, lambda_2=1e-06, \n",
    "                       compute_score=False, fit_intercept=True, normalize=False, copy_X=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Convex combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "s1 = HuberRegressor(epsilon=2.7, max_iter=1000, alpha=5e-05, warm_start=False, fit_intercept=False, tol=1e-05)\n",
    "s2 = Lasso(alpha = 0.001,max_iter = 10000,tol = 0.0001)\n",
    "s3 = BayesianRidge(n_iter=1000, tol=0.001, alpha_1=1e-08, alpha_2=0.5, lambda_1=0.5, lambda_2=1e-08, \n",
    "                       compute_score=False, fit_intercept=True, normalize=False, copy_X=True, verbose=False)\n",
    "estimators = [s1,s2,s3]\n",
    "solver = ConvexRegressor(ests=estimators,convparams = convregconv(estimators,[0.3,0,0.8]))\n",
    "param_grid1 = {'convparams' : [convregconv(estimators,[0.5, 0.4,0.1]), convregconv(estimators,[0.6,0.3,0.1]),\n",
    "                                convregconv(estimators,[0.6, 0.1,0.3]), convregconv(estimators,[0.6,0.0,0.4]),\n",
    "                                convregconv(estimators,[0.6,0.2,0.2]), convregconv(estimators,[0.8,0.1,0.1])]}\n",
    "\n",
    "param_grid2 = {'convparams' : [convregconv(estimators,[0.5, 0.25,0.0]), convregconv(estimators,[0.6,0.4,0]),\n",
    "                                convregconv(estimators,[0.7, 0.3,0]), convregconv(estimators,[0.8,0.2,0]),\n",
    "                                convregconv(estimators,[0.9,0.1,0]), convregconv(estimators,[0.4,0.6,0])]}\n",
    "\n",
    "#solver = GridSearchCV(solver, cv=5,param_grid=param_grid1)\n",
    "solver = LearnAndPredict(test_x,train_x, y, scaler = scaler, solver = solver, ids = Ids,  filename = 'HuberLasso.csv')\n",
    "#0.9187263622916003\n",
    "#{'convparams': {'HuberRegressor': 0.4, 'Lasso': 0.6, 'BayesianRidge': 0}}\n",
    "#0.12248\n",
    "#0.9179347873508138\n",
    "#{'convparams': {'HuberRegressor': 0.5, 'Lasso': 0.4, 'BayesianRidge': 0.1}}\n",
    "#0.12197\n",
    "#convregconv(estimators,[0.7,0,0.3]) - 0.12196\n",
    "#convregconv(estimators,[0.5,0,0.5]) - 0.12175\n",
    "#convregconv(estimators,[0.3,0,0.8]) - 0.12775"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "solver = KernelRidge(alpha=35, kernel='linear', gamma=1, degree=1, coef0=1, kernel_params=None)\n",
    "solver = Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)\n",
    "#degree=3   0.9113532569817305\n",
    "#0.9192918459212212\n",
    "#0.9196149350223377 - alpha 20\n",
    "#0.9197754264469626 - alpha 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "solver = KernelRidge(alpha=25, kernel='linear', gamma=1, degree=1, coef0=1, kernel_params=None)\n",
    "solver = LearnAndPredict(test_x,train_x, y, scaler = scaler, solver = solver, ids = Ids,  filename = 'KernelRidge.csv')\n",
    "#0.12088 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "solver = SVR(kernel='linear', degree=1, gamma=0.001, coef0=0.0, tol=0.001, C=1, epsilon=0.5, shrinking=True,\n",
    "             cache_size=200, verbose=False,max_iter=-1)\n",
    "solver = Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "solver = SVR(kernel='linear', degree=1, gamma=0.001, coef0=0.0, tol=0.001, C=1, epsilon=0.1, shrinking=True,\n",
    "             cache_size=200, verbose=False,max_iter=-1)\n",
    "solver = LearnAndPredict(test_x,train_x, y, scaler = scaler, solver = solver, ids = Ids,  filename = 'SVR.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "solver = LinearSVR(epsilon=0.0, tol=0.0001, C=0.01, loss='epsilon_insensitive', fit_intercept=True, intercept_scaling=1.0, dual=True, verbose=0, random_state=None, max_iter=1000)\n",
    "solver = Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)\n",
    "#0.9183937382600859 C = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "solver = LinearSVR(epsilon=0.0, tol=0.0001, C=0.01, loss='epsilon_insensitive', fit_intercept=True,\n",
    "                   intercept_scaling=1.0, dual=True, verbose=0, random_state=None, max_iter=1000)\n",
    "param_grid = {'C' : [0.1, 0.05, 0.01, 0.009, 0.006, 0.003, 0.001, 0.0005, 0.0001]}\n",
    "\n",
    "#solver = GridSearchCV(solver, cv=5,param_grid=param_grid)\n",
    "solver = LearnAndPredict(test_x,train_x, y, scaler = scaler, solver = solver, ids = Ids,  filename = 'LinearSVR.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = KNeighborsRegressor(n_neighbors=5, weights='distance', algorithm='auto', leaf_size=30, p=2, metric='minkowski',\n",
    "                    metric_params=None, n_jobs=None)\n",
    "solver = Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RadiusNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = RadiusNeighborsRegressor(radius=1.0, weights='uniform', algorithm='auto',\n",
    "                                  leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "solver = Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
