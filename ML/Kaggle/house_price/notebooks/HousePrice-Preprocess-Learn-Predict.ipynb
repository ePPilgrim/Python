{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as npma\n",
    "import scipy as sc\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing.data import QuantileTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, Lasso, LassoLars,  BayesianRidge, LassoLarsIC, Ridge,ARDRegression,SGDRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "os.sys.path.append(os.path.pardir)\n",
    "from src.models.ConvexRegressor import ConvexRegressor\n",
    "from src.models.ConvexRegressor import convregparam\n",
    "from src.models.ConvexRegressor import convregconv\n",
    "\n",
    "#############################################################################################################\n",
    "project_dir =os.path.pardir\n",
    "raw_path = os.path.join(project_dir,'data','processed')\n",
    "train_path = os.path.join(raw_path, 'train.csv')\n",
    "test_path = os.path.join(raw_path, 'test.csv')\n",
    "sns.set()\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "train = train.drop(['Id','Unnamed: 0'],axis = 1)\n",
    "test = test.drop(['Unnamed: 0'],axis = 1)\n",
    "y = train['SalePrice'].values\n",
    "Ids = test['Id'].values\n",
    "train_x = train.drop('SalePrice',axis = 1).values\n",
    "test_x = test.drop('Id',axis = 1).values\n",
    "\n",
    "#################################################################################################################\n",
    "def Score(x, y, scaler, solver, q = 0.4, fldmask = None):\n",
    "    scaler = scaler.fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    yscaler = QuantileTransformer(output_distribution='normal').fit(y.reshape([-1,1]))\n",
    "    y = yscaler.transform(y.reshape([-1,1])).ravel()\n",
    "    if fldmask is not None:\n",
    "        x = x[:,fldmask]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=q, random_state=0)   \n",
    "    yscaler = QuantileTransformer(output_distribution='normal').fit(y_train.reshape([-1,1]))\n",
    "    y_train = yscaler.transform(y_train.reshape([-1,1])).ravel()        \n",
    "    solver = solver.fit(x_train, y_train)\n",
    "    score = solver.score(x_test, y_test)\n",
    "    print(score)\n",
    "    return solver\n",
    "\n",
    "def LearnAndPredict(x_test,x, y, scaler, solver, ids, plot = False, fldmask = None, filename = 'temp.csv'):\n",
    "    yscaler = QuantileTransformer(output_distribution='normal').fit(y.reshape([-1,1]))\n",
    "    y = yscaler.transform(y.reshape([-1,1])).ravel()\n",
    "    if fldmask is not None:\n",
    "        x = x[:,fldmask]\n",
    "        x_test = x_test[:,fldmask]\n",
    "    scaler = scaler.fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    solver = solver.fit(x, y)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    y = solver.predict(x_test)\n",
    "    y = yscaler.inverse_transform(y.reshape([-1,1])).ravel()\n",
    "    df_submission = pd.DataFrame({'Id': ids, 'SalePrice' : y} )\n",
    "    submission_data_path = os.path.join(os.path.pardir,'data','external')\n",
    "    submission_file_path = os.path.join(submission_data_path, filename)\n",
    "    df_submission.to_csv(submission_file_path, index=False)\n",
    "    if hasattr(solver, 'best_score_'):\n",
    "        print(solver.best_score_)\n",
    "    if hasattr(solver, 'best_params_'):\n",
    "        print(solver.best_params_)\n",
    "    if plot == True:\n",
    "        sns.distplot(y,fit = norm)\n",
    "    return solver\n",
    "\n",
    "def linear_ml_solve(x, y, scaler, solver, q = 0.4):\n",
    "    yscaler = QuantileTransformer(output_distribution='normal').fit(y.reshape([-1,1]))\n",
    "    y = yscaler.transform(y.reshape([-1,1])).ravel()\n",
    "    x = scaler.fit_transform(x)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=q, random_state=0)\n",
    "    solver = solver.fit(x_train, y_train)\n",
    "    score = solver.score(x_test,y_test)\n",
    "    print(score)\n",
    "    y = solver.predict(x_test)\n",
    "    y = yscaler.inverse_transform(y.reshape([-1,1])).ravel()\n",
    "    if hasattr(solver, 'best_score_'):\n",
    "        print(solver.best_score_)\n",
    "    if hasattr(solver, 'best_params_'):\n",
    "        print(solver.best_params_)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = LearnAndPredict(test_x,train_x, y, scaler = RobustScaler(), solver = Lasso(alpha = 0.001,max_iter = 10000,tol = 0.0001), ids = Ids, filename = 'LassoRidge.csv')\n",
    "fldmask = solver.coef_ == 0.0\n",
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6838057972470732\n",
      "0.9182196591388715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9182196591388715"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver = Lasso(alpha = 0.001,max_iter = 10000,tol = 0.0001)\n",
    "Score(train_x, y, scaler, solver, q = 0.4, fldmask = fldmask)\n",
    "Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=10000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids, filename = 'Lasso.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.ARDRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = ARDRegression()\n",
    "Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)\n",
    "#0.9091333855168815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ARDRegression(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
       "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
       "       normalize=False, threshold_lambda=10000.0, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids, fldmask =, filename = 'ARDRegression.csv')\n",
    "#0.13142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ARDRegression(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
       "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
       "       normalize=False, threshold_lambda=10000.0, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids, fldmask = fldmask, filename = 'ARDRegressionReduced.csv')\n",
    "#0.24144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "est1 = Ridge()\n",
    "est2 = Lasso()\n",
    "estimators = [est1,est2]\n",
    "cest = ConvexRegressor(ests=estimators)\n",
    "param_grid = convregparam(est2,{'alpha': [ 7.0, 6.0, 3.0, 0.02,0.001, 0.00099, 0.009, 0.0008]})\n",
    "param_grid.update(convregparam(est1,{'alpha' : [7.0, 6.0, 4.0, 2.0, 0.6,0.5,0.55,0.45]}))\n",
    "param_grid.update({'convparams' : [convregconv(estimators,[0.11, 0.89]), convregconv(estimators,[0.1,0.9]),\n",
    "                                   convregconv(estimators,[0.09, 0.91]), convregconv(estimators,[0.05,0.95]),\n",
    "                                   convregconv(estimators,[0.01,0.99]), convregconv(estimators,[0.001,0.999])]})\n",
    "\n",
    "gsolver = GridSearchCV(cest, cv=5,param_grid=param_grid)\n",
    "house_price = LearnAndPredict(test_x,train_x, y, scaler, solver = gsolver, ids = Ids, q = 0.4, filename = 'LassoRidge.csv')\n",
    "#0.919300261382389\n",
    "#{'Lasso$$&&$$alpha': 0.001, 'Ridge$$&&$$alpha': 7.0, 'convparams': {'Ridge': 0.001, 'Lasso': 0.999}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "est1 = Ridge()\n",
    "est2 = Lasso()\n",
    "estimators = [est1,est2]\n",
    "cest = ConvexRegressor(ests=estimators)\n",
    "param_grid = convregparam(est2,{'alpha': [0.0005, 0.0009, 0.001, 0.0015, 0.0019, 0.002]})\n",
    "param_grid.update(convregparam(est1,{'alpha' : [7.0, 7.5, 8.0, 8.5, 9.0]}))\n",
    "param_grid.update({'convparams' : [convregconv(estimators,[0.0001,0.9999]), convregconv(estimators,[0.001,0.999])]})\n",
    "\n",
    "gsolver = GridSearchCV(cest, cv=5,param_grid=param_grid)\n",
    "house_price = LearnAndPredict(test_x,train_x, y, scaler, solver = gsolver, ids = Ids, q = 0.4, filename = 'LassoRidge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "est = Ridge()\n",
    "param_grid = {'alpha': [8.0, 7.8, 7.5, 7.3, 7.0]}\n",
    "gsolver = GridSearchCV(Ridge(max_iter = 10000,tol = 0.00001), cv=5,param_grid=param_grid)\n",
    "house_price = LearnAndPredict(test_x,train_x, y, scaler, solver = gsolver, ids = Ids, filename = 'Ridge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ['squared_loss','huber','epsilon_insensitive','squared_epsilon_insensitive']\n",
    "penalty = ['l1','l2']\n",
    "param_grid = { 'alpha': [0.0005, 0.0009, 0.001, 0.0015, 0.0019, 0.002,0.005,0.01,0.05,0.1]}\n",
    "#Such as this task is solved by iteration so the is no reason to use gread search routines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## 4.1 Huber + L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PLDD\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#solver = SGDRegressor(alpha = 0.001, loss = 'huber', penalty = 'l1', epsilon = 0.1, max_iter = 150000, warm_start = True)\n",
    "solver = LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids, filename = 'SGDRegressor_huber_l1.csv')\n",
    "#0.124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PLDD\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9209888026337525\n"
     ]
    }
   ],
   "source": [
    "solver = Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)\n",
    "#0.9184762393457621"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Epsilon_insensitive + L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PLDD\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-16969.23300839353\n"
     ]
    }
   ],
   "source": [
    "solver = SGDRegressor(alpha = 0.001, loss = 'epsilon_insensitive',epsilon = 0.1, penalty = 'l1', max_iter = 150000, warm_start = True)\n",
    "solver = Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)\n",
    "#0.855235126971956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.max_iter = 300000\n",
    "solver = LearnAndPredict(test_x,train_x, y, scaler, solver = solver, ids = Ids, filename = 'SGDRegressor_EpsilonInsensitive_l1.csv')\n",
    "#0.3001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Squared_Epsilon_Insensitive + L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = SGDRegressor(alpha = 0.001, loss = 'squared_epsilon_insensitive',epsilon = 0.1, penalty = 'l1', max_iter = 150000, warm_start = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PLDD\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.747526557568158e+25\n"
     ]
    }
   ],
   "source": [
    "solver = Score(train_x, y, scaler, solver, q = 0.4, fldmask = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
