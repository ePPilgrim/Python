{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "project_dir = 'C:\\\\Users\\\\PLDD\\\\python\\\\Python\\\\ML\\\\Kaggle\\\\house_price'\n",
    "raw_path = os.path.join(project_dir,'data','raw')\n",
    "train_path = os.path.join(raw_path, 'train.csv')\n",
    "test_path = os.path.join(raw_path, 'test.csv')\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTrainTestSets(train_path, test_path):   \n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "    col = ['FireplaceQu','Alley','PoolQC','Fence','MiscFeature']\n",
    "    train[col] = train[col].fillna(value = \"No\")\n",
    "    test[col] = test[col].fillna(value = \"No\")\n",
    "    \n",
    "    catcol = [['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2'],\n",
    "              ['GarageType','GarageFinish','GarageQual','GarageCond']]\n",
    "    numcol = [['BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath'],\n",
    "              ['GarageYrBlt','GarageCars','GarageArea']]\n",
    "    keyflds = ['TotalBsmtSF','GarageArea']\n",
    "    for (catflds,numflds,keyfld) in zip(catcol, numcol, keyflds):\n",
    "        lx = (train[keyfld] == 0) & (train[catflds].isnull().any(axis = 1))\n",
    "        train.loc[lx,catflds] = train[lx][catflds].fillna(value = \"No\")\n",
    "        lx = (train[keyfld] == 0) & (train[numflds].isnull().any(axis = 1))\n",
    "        train.loc[lx,numflds] = train[lx][numflds].fillna(value = 0)\n",
    "        lx = (test[keyfld] == 0) & (test[catflds].isnull().any(axis = 1))\n",
    "        test.loc[lx,catflds] = test[lx][catflds].fillna(value = \"No\")\n",
    "        lx = (test[keyfld] == 0) & (test[numflds].isnull().any(axis = 1))\n",
    "        test.loc[lx,numflds] = test[lx][numflds].fillna(value = 0)\n",
    "    train = train.drop('Utilities', axis = 1)\n",
    "    test = test.drop('Utilities', axis = 1)\n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProccessOutliers(train, test):\n",
    "    lx1 = (train['SalePrice'] <= 200000) & (train['GrLivArea'] >= 4000) \n",
    "    lx2 = train['LotFrontage'] > 300 \n",
    "    lx = lx1 | lx2\n",
    "    train = train[~lx]\n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProccessNumNans(df):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['LotFrontage', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt','GarageCars', 'GarageArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = GetTrainTestSets(train_path, test_path)\n",
    "(train, test) = ProccessOutliers(train,test)\n",
    "test['SalePrice'] = 0\n",
    "df = train.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x22fa23c42e8>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccol = 'GarageCars'\n",
    "ddf = df[['LotFrontage','Neighborhood','LotConfig',ccol,'LotArea']]\n",
    "#ddf[ddf['LotFrontage'].isnull()]['Neighborhood'].unique()\n",
    "#sns.catplot(y = 'LotFrontage',x = 'Neighborhood',hue = 'LotConfig',data = ddf,aspect = 1,row = ccol)\n",
    "\n",
    "lx = ddf['LotFrontage'].isnull()# == 'Inside'\n",
    "lx = ~lx\n",
    "v1 = ddf[lx][['LotFrontage','LotConfig']]\n",
    "v1['Loot'] = ddf[lx]['LotArea']\n",
    "v1['LotFrontage'] = v1['LotFrontage'] \n",
    "v1['Loot'] = np.sqrt(v1['Loot'])\n",
    "#v1 = v1[v1['LotConfig'] == 'FR2']\n",
    "#v1[['LotFrontage', 'Loot']].corr()\n",
    "#sns.pairplot(v11)\n",
    "#gg = sns.lmplot(x='Loot',y='LotFrontage', row = 'LotConfig', data = v1,logx=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PLDD\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5788136890483405\n"
     ]
    }
   ],
   "source": [
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing.data import QuantileTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler3 = RobustScaler()\n",
    "scaler4 = Normalizer()\n",
    "scaler5 = QuantileTransformer()\n",
    "\n",
    "solver1 = linear_model.RidgeCV(alphas = np.arange(0.001, 5, 0.001))\n",
    "solver2 = linear_model.LassoCV()\n",
    "solver3 = linear_model.ElasticNetCV(alphas = np.arange(0.001, 5, 0.001), max_iter = 20000 )\n",
    "solver4 = linear_model.BayesianRidge()\n",
    "solver5 = KernelRidge(alpha=1.0,kernel='polynomial')\n",
    "solver5_1 = GridSearchCV(KernelRidge(kernel='rbf', gamma=0.1), cv=5,\n",
    "                  param_grid={\"alpha\": [1e0, 0.1, 1e-2, 1e-3],\n",
    "                              \"gamma\": np.logspace(-2, 2, 5)})\n",
    "solver6 = linear_model.PassiveAggressiveRegressor(C = 10,tol = 0.00001, max_iter = 50000)\n",
    "solver7 = linear_model.HuberRegressor(max_iter=10000)\n",
    "solver8 = Pipeline([('poly', PolynomialFeatures(degree=2)),  ('linear', solver1)])\n",
    "\n",
    "scaler = scaler5\n",
    "solver = solver5_1\n",
    "\n",
    "dff = df[['LotFrontage','LotArea','LotConfig','Neighborhood']]\n",
    "dff = pd.get_dummies(dff)\n",
    "lx = dff['LotFrontage'].isnull()\n",
    "dfy = dff['LotFrontage']\n",
    "dfx = dff.drop('LotFrontage', axis = 1)\n",
    "\n",
    "X = dfx[~lx].as_matrix().astype('float')\n",
    "y = dfy[~lx].ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "solver.fit(X_train, y_train)\n",
    "print(solver.score(X_test, y_test))\n",
    "\n",
    "X = scaler.fit_transform(X)    \n",
    "XX = scaler.transform(dfx[lx].as_matrix().astype('float'))\n",
    "solver.fit(X, y) \n",
    "pred_y = solver.predict(XX).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PLDD\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>Loot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loot</th>\n",
       "      <td>0.857509</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LotFrontage      Loot\n",
       "LotFrontage     1.000000  0.857509\n",
       "Loot            0.857509  1.000000"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = df[['LotFrontage','LotArea','LotConfig']]\n",
    "ff.loc[lx,['LotFrontage']] = pred_y\n",
    "ff['Loot'] = ff['LotArea']\n",
    "ff.loc[:,['Loot']] = np.sqrt(ff['Loot'])\n",
    "v1 = ff[ff['LotConfig'] == 'FR3']\n",
    "v1[['LotFrontage', 'Loot']].corr()\n",
    "#sns.pairplot(ff)\n",
    "#gg = sns.lmplot(x='Loot',y='LotFrontage', row = 'LotConfig', data = ff,logx=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LotArea'].isnull().sum()\n",
    "# Inside = 0.7034\n",
    "# FR2 = 0.824\n",
    "# Corner = 0.734\n",
    "# CulDSac = 0.24\n",
    "# FR3 = 0.83\n",
    "\n",
    "# Inside = 0.7034\n",
    "# FR2 = 0.824\n",
    "# Corner = 0.72\n",
    "# CulDSac = 0.195\n",
    "# FR3 = 0.836\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf=df.select_dtypes(include=[np.number])\n",
    "cdf=df.select_dtypes(include=[np.object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LotFrontage', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
       "       'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt',\n",
       "       'GarageCars', 'GarageArea'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nndf = ndf[ndf.columns[ndf.isnull().any()]]\n",
    "nndf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = [1,2,3]\n",
    "v2 = [3,3,4]\n",
    "v1  v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train_df.columns 'LotFrontage', 'LotArea'\n",
    "df = train[['SalePrice','Neighborhood','GarageYrBlt']]\n",
    "#lx = (df['YearBuilt'] > 1997) & (df['SalePrice'] < 500000)\n",
    "sns.catplot(x = 'GarageYrBlt', y = 'SalePrice',data = df,kind=\"swarm\",aspect = 3.4)\n",
    "# scatter plot matrix\n",
    "#columns = ['GrLivArea','SalePrice']\n",
    "#pd.plotting.scatter_matrix(train_df[columns],figsize=(10,10))\n",
    "#plt.figure()\n",
    "#train_df[columns].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Create data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines train and test data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDataFrame(train_path, test_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    test_df['SalePrice'] = 0.0\n",
    "    df = train_df.append(test_df)\n",
    "    df.index = list(range(train_df.index.size + test_df.index.size))\n",
    "    # 2916 out of 2919 Utilities are AllPub so i think it should be droped off\n",
    "    df = df.drop('Utilities', axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proccess outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProccessOutliers(df):\n",
    "#'LotFrontage', 'LotArea', 'MasVnrArea', 'GrLivArea', 'GarageArea', 'PoolArea', 'SalePrice']\n",
    "#copydf['LotFrontage'].plot.hist()\n",
    "#copydf['LotFrontage'].plot.box()\n",
    "#copydf['LotArea'].plot.hist()\n",
    "#copydf['LotArea'].plot.box()\n",
    "#copydf['GrLivArea'].plot.hist()\n",
    "#copydf['GrLivArea'].plot.box()\n",
    "#plt.show()\n",
    "    lx = (df['LotFrontage'] > 200) | (df['LotArea'] > 100000) | (df['GrLivArea'] > 4000)\n",
    "#df = df.drop(df.index[lx], axis = 0)\n",
    "    df.loc[df['LotFrontage'] > 200,'LotFrontage'] = np.nan\n",
    "    df.loc[df['LotArea'] > 100000,'LotArea'] = np.nan\n",
    "    df.loc[df['GrLivArea'] > 4000,'GrLivArea'] = np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proccess Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReplaceNanValues_LotFrontageArea(df, alables, abins, fromfld, tofld, catclass, targetclass):\n",
    "    fullclass = catclass + [targetclass]\n",
    "    df[tofld]=pd.cut(x = df[fromfld].values, bins = abins, right = False, labels = alables)\n",
    "    validdf = df[fullclass].dropna(axis = 0, how = 'any')\n",
    "    nandf = df[df[targetclass].isnull()]\n",
    "    pvt = validdf.pivot_table(values = targetclass, index = catclass, aggfunc = np.median)\n",
    "    pvt=pvt[pvt.notnull().all(1)]\n",
    "    t1 = pvt.loc[[tuple(x) for x in nandf[catclass].values]]\n",
    "    t1.index = nandf.index\n",
    "    df.loc[nandf.index,targetclass] = t1[targetclass]\n",
    "    df = df.drop(tofld, axis = 1)\n",
    "    return df\n",
    "\n",
    "def ProccessNanValues(df):\n",
    "    DefSeqCat = ['Alley','BsmtQual', 'BsmtCond', 'BsmtExposure','BsmtFinType1', 'BsmtFinType2', 'FireplaceQu',\n",
    "                 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC',\n",
    "                 'Fence', 'MiscFeature']\n",
    "    UndefSeqCat1 = ['MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd','Electrical', 'KitchenQual',\n",
    "                    'Functional', 'SaleType'] # there are defenetly lost elements \n",
    "    UndefSeqCat2 = ['MasVnrType'] # i may just not make it clear the property of the column\n",
    "    UndefSeqNum = ['LotFrontage', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n",
    "                   'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt', 'GarageCars', 'GarageArea']\n",
    "\n",
    "    replace=dict.fromkeys(DefSeqCat, 'None')\n",
    "    df = df.fillna(replace)\n",
    "#'MasVnrType'\n",
    "    ix = df.index[df['MasVnrType'].isnull()]\n",
    "    df.loc[ix,'MasVnrType'] = 'None'\n",
    "    df.loc[ix,'MasVnrArea'] = 0\n",
    "\n",
    "    NanCol = ['LotFrontage', 'MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
    "              'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "              'Electrical', 'BsmtFullBath', 'BsmtHalfBath', 'KitchenQual',\n",
    "              'Functional', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'SaleType']\n",
    "    #Replace NAN values in 'LotFrontage' and 'LotArea' with iterpolated value.\n",
    "    yearlable = ['1906', '1942', '1975', '1991', '2011']\n",
    "    yearbin = [1800,1906,1942,1975, 1991, 2011]\n",
    "\n",
    "#case 1\n",
    "    catclass = ['Neighborhood', 'LotConfig','LotShape','YearInt']\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage' )\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "\n",
    "    catclass = ['LotConfig','LotShape','YearInt']\n",
    "#case 2\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage')\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "\n",
    "#case 3\n",
    "    yearlable = ['1942', '1991', '2011']\n",
    "    yearbin = [1800, 1942, 1991, 2011]\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage')\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "\n",
    "#case 4\n",
    "    yearlable = ['1975', '1991', '2011']\n",
    "    yearbin = [1800, 1975, 1991, 2011]\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage')\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "\n",
    "#case 5\n",
    "    yearlable = ['2011']\n",
    "    yearbin = [1800, 2011]\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage')\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "    #print(df[df['LotArea'].isnull()].index.size)\n",
    "    \n",
    "    #Replace Nan in 'MSZoning'\n",
    "    ind1 = [1915, 2216, 2250] # C - assign by many factors\n",
    "    ind2 = [2904] # RL - by Lot Area, LotFrontage and YearBuilt \n",
    "    df.loc[ind1,'MSZoning'] = 'C'\n",
    "    df.loc[ind2,'MSZoning'] = 'RL'\n",
    "    \n",
    "    #Replace Nan in 'Exterior1st' and 'Exterior2nd'\n",
    "    targetclass = ['Exterior1st', 'Exterior2nd']\n",
    "    ind = [2151]\n",
    "    df.loc[ind,targetclass] = 'AsbShng'\n",
    "    \n",
    "    #Add column 'RangeYrBlt' and remove columns 'GarageYrBlt' and 'YearBilt'\n",
    "    yearbins = [1800, 1895, 1905, 1917, 1927, 1937,1947,1960, 1973, 1989, 1998, 2012]\n",
    "    yearlabels = ['1895', '1905', '1917', '1927', '1937', '1947', '1960', '1973', '1989', '1998', '2012']\n",
    "    if df.columns.isin(['YearBuilt']).any():\n",
    "        df['RangeYrBlt']=pd.cut(x = df['YearBuilt'].values, bins = yearbins, right = False, labels = yearlabels)\n",
    "        df = df.drop('YearBuilt', axis = 1)\n",
    "    if df.columns.isin(['GarageYrBlt']).any():\n",
    "        df = df.drop('GarageYrBlt', axis = 1)\n",
    "    \n",
    "    #Replace Nan in 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF' (row index - 2120)\n",
    "    # There is no basement in this house so all areas we take as 0\n",
    "    df.loc[2120,['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF']] = 0\n",
    "    \n",
    "    #Replase Nan in 'Electrical' (row index - 1379)\n",
    "    df.loc[1379, 'Electrical'] = 'SBrkr' #  all houses in 2012 year built have this type of Electrical\n",
    "    \n",
    "    #Replase Nan in 'GrLivArea'\n",
    "    if df.columns.isin(['GrLivArea']).any():\n",
    "        df = df.drop('GrLivArea', axis = 1) # it is sum of '1stFlrSF' and '2ndFlrSF'\n",
    "        \n",
    "    #Replace Nan in 'BsmtFullBath' and 'BsmtHalfBath' (row indexes are 2120 and 2188) # all these houses have no basements\n",
    "    df.loc[[2120,2188],['BsmtFullBath', 'BsmtHalfBath']] = 0\n",
    "    \n",
    "    #Replace Nan in 'KitchenQual' (row index is 1555)\n",
    "    # Value of 'KitchenQual' depends on 'OverallQual', 'OverallCond'\n",
    "    df.loc[1555, 'KitchenQual'] = 'TA'\n",
    "    \n",
    "    #Replace Nan in 'Functional' (row indexes are 2216, 2473)\n",
    "    # The most used functionality is 'Typ'\n",
    "    df.loc[[2216, 2473],'Functional'] = 'Typ'\n",
    "    \n",
    "    #Replace Nan in 'GarageCars', 'GarageArea' (row index is 2576)\n",
    "    #there is no garage so its area is 0\n",
    "    df.loc[2576,'GarageArea'] = 0\n",
    "    if df.columns.isin(['GarageCars']).any():\n",
    "        df = df.drop('GarageCars', axis = 1) # it has straight dependency on garage area\n",
    "        \n",
    "    #Replace Nan in 'SaleType' (row index is 2489)\n",
    "    df.loc[2489, 'SaleType'] = 'WD' # the most used type according to sold year and sale condition\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_columns(df, what, bby):\n",
    "    t_df = df.loc[df[bby] != 0]\n",
    "    t_df = t_df.groupby([what]).agg({bby : 'median'})\n",
    "    t_df = t_df.sort_values(by = bby, axis = 0 )\n",
    "    return t_df.index.values\n",
    "\n",
    "def Categorizing(copydf):\n",
    "\n",
    "    OrderedCat = ['MSZoning', 'Street','Alley', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofMatl']\n",
    "    NonOrderedCat = ['LandContour', 'LotConfig', 'LotShape', 'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'RoofStyle'\n",
    "                'Exterior1st','Exterior2nd']\n",
    "\n",
    "    copydf['MSZoning'] = pd.Categorical(copydf['MSZoning'].values, ['C', 'C (all)', 'RM', 'RH', 'RL', 'FV'], ordered = True)\n",
    "    copydf['Street'] = pd.Categorical(copydf['Street'].values, ['Grvl','Pave'], ordered = True)\n",
    "    copydf['Alley'] = pd.Categorical(copydf['Alley'].values, ['None', 'Grvl', 'Pave'], ordered = True)\n",
    "    copydf['LotShape'] = pd.Categorical(copydf['LotShape'].values, ['Reg', 'IR1', 'IR2', 'IR3'], ordered = True) # can be droped\n",
    "    copydf['LandContour'] = pd.Categorical(copydf['LandContour'].values, ['Lvl', 'Bnk', 'Low', 'HLS'], ordered = True)\n",
    "    copydf['LotConfig'] = pd.Categorical(copydf['LotConfig'].values, ['FR2', 'Corner', 'Inside', 'CulDSac', 'FR3'], ordered = True)\n",
    "    copydf['LandSlope'] = pd.Categorical(copydf['LandSlope'].values, ['Sev', 'Mod', 'Gtl'], ordered = True)\n",
    "    copydf['Neighborhood'] = pd.Categorical(copydf['Neighborhood'].values, sorted_columns(copydf.loc[copydf.SalePrice != 0], 'Neighborhood' , 'SalePrice'), ordered = True)\n",
    "    copydf['Condition1'] = pd.Categorical(copydf['Condition1'].values, ['PosA', 'PosN', 'Norm', 'RRNn', 'RRNe', 'RRAe',  'RRAn', 'Feedr', 'Artery'], ordered = True)\n",
    "    copydf['Condition2'] = pd.Categorical(copydf['Condition2'].values, ['PosA', 'PosN', 'Norm', 'RRNn', 'RRAe', 'RRAn','Feedr', 'Artery'], ordered = True)\n",
    "    copydf['BldgType'] = pd.Categorical(copydf['BldgType'].values, ['2fmCon', 'Duplex', 'Twnhs', 'TwnhsE', '1Fam'], ordered = True)\n",
    "    copydf['HouseStyle'] = pd.Categorical(copydf['HouseStyle'].values, ['1.5Unf', '1.5Fin', 'SFoyer', 'SLvl', '1Story', '2.5Unf', '2.5Fin', '2Story'], ordered = True)\n",
    "    copydf['RoofStyle'] = pd.Categorical(copydf['RoofStyle'].values, sorted_columns(copydf.loc[copydf.SalePrice != 0], 'RoofStyle', 'SalePrice'), ordered = True)\n",
    "    copydf['RoofMatl'] = pd.Categorical(copydf['RoofMatl'].values, ['Roll', 'ClyTile', 'Metal', 'CompShg', 'Tar&Grv', 'Membran', 'WdShake', 'WdShngl'], ordered = True)\n",
    "    copydf['Exterior1st'] = pd.Categorical(copydf['Exterior1st'].values, sorted_columns(copydf.loc[copydf.SalePrice != 0], 'Exterior1st', 'SalePrice'), ordered = True)\n",
    "    copydf['Exterior2nd'] = pd.Categorical(copydf['Exterior2nd'].values, sorted_columns(copydf.loc[copydf.SalePrice != 0], 'Exterior2nd', 'SalePrice'), ordered = True)\n",
    "    copydf['MasVnrType'] = pd.Categorical(copydf['MasVnrType'].values, sorted_columns(copydf.loc[copydf.SalePrice != 0], 'MasVnrType', 'SalePrice'), ordered = True)\n",
    "    copydf['ExterQual'] = pd.Categorical(copydf['ExterQual'].values, ['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['ExterCond'] = pd.Categorical(copydf['ExterCond'].values, ['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['Foundation'] = pd.Categorical(copydf['Foundation'].values, ['Slab', 'Stone', 'Wood', 'BrkTil', 'CBlock', 'PConc'], ordered = True)\n",
    "    copydf['BsmtQual'] = pd.Categorical(copydf['BsmtQual'].values, ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['BsmtCond'] = pd.Categorical(copydf['BsmtCond'].values, ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['BsmtExposure'] = pd.Categorical(copydf['BsmtExposure'].values, ['None', 'No', 'Mn', 'Av', 'Gd'], ordered = True)\n",
    "    copydf['BsmtFinType1'] = pd.Categorical(copydf['BsmtFinType1'].values, ['None', 'LwQ', 'Rec','Unf','BLQ','ALQ','GLQ'], ordered = True)\n",
    "    copydf['BsmtFinType2'] = pd.Categorical(copydf['BsmtFinType2'].values, ['None', 'LwQ', 'Rec','Unf','BLQ','ALQ','GLQ'], ordered = True)\n",
    "    copydf['Heating'] = pd.Categorical(copydf['Heating'].values, ['Floor', 'Grav', 'Wall', 'OthW', 'GasW','GasA'], ordered = True)\n",
    "    copydf['HeatingQC'] = pd.Categorical(copydf['HeatingQC'].values, ['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['CentralAir'] = pd.Categorical(copydf['CentralAir'].values, ['N', 'Y'], ordered = True)\n",
    "    copydf['Electrical'] = pd.Categorical(copydf['Electrical'].values, ['Mix', 'FuseP', 'FuseF', 'FuseA', 'SBrkr' ], ordered = True)\n",
    "    copydf['KitchenQual'] = pd.Categorical(copydf['KitchenQual'].values, ['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['Functional'] = pd.Categorical(copydf['Functional'].values, ['Sev', 'Maj2', 'Maj1', 'Min1', 'Min2', 'Mod', 'Typ'], ordered = True)\n",
    "    copydf['FireplaceQu'] = pd.Categorical(copydf['FireplaceQu'].values, ['None','Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['GarageType'] = pd.Categorical(copydf['GarageType'].values, ['None', 'CarPort','Detchd', '2Types', 'Basment', 'Attchd', 'BuiltIn'], ordered = True)\n",
    "    copydf['GarageFinish'] = pd.Categorical(copydf['GarageFinish'].values, ['None', 'Unf', 'RFn', 'Fin'], ordered = True)\n",
    "    copydf['GarageQual'] = pd.Categorical(copydf['GarageQual'].values, ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['GarageCond'] = pd.Categorical(copydf['GarageCond'].values, ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['PavedDrive'] = pd.Categorical(copydf['PavedDrive'].values, ['N', 'P', 'Y'], ordered = True)\n",
    "\n",
    "    copydf['PoolQC'] = pd.Categorical(copydf['PoolQC'].values, ['None', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['Fence'] = pd.Categorical(copydf['Fence'].values, ['MnWw', 'GdWo', 'MnPrv', 'GdPrv', 'None'], ordered = True)\n",
    "    copydf['MiscFeature'] = pd.Categorical(copydf['MiscFeature'].values, ['Othr', 'Shed', 'Gar2', 'None', 'TenC'], ordered = True)\n",
    "    copydf['SaleType'] = pd.Categorical(copydf['SaleType'].values, ['Oth', 'ConLD', 'ConLw', 'COD', 'WD', 'ConLI', 'CWD', 'Con', 'New'], ordered = True)\n",
    "    copydf['SaleCondition'] = pd.Categorical(copydf['SaleCondition'].values, ['AdjLand', 'Abnorml', 'Family', 'Alloca', 'Normal', 'Partial'], ordered = True)\n",
    "\n",
    "    #print(copydf.columns[copydf.dtypes == 'object'].size)\n",
    "    return copydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FormatAndSave(df):\n",
    "    dff = df.copy()\n",
    "    categorical_flds = dff.columns[dff.dtypes == 'category'].values\n",
    "    dff = pd.get_dummies(dff, columns = categorical_flds)\n",
    "    \n",
    "    processed_data_path = os.path.join(os.path.pardir,'data','processed')\n",
    "    write_train_path = os.path.join(processed_data_path, 'train.csv')\n",
    "    write_test_path = os.path.join(processed_data_path, 'test.csv')\n",
    "    \n",
    "    # train data\n",
    "    dff.loc[dff.SalePrice != 0].to_csv(write_train_path) \n",
    "    # test data\n",
    "    columns = [column for column in dff.columns if column != 'SalePrice']\n",
    "    dff.loc[dff.SalePrice == 0, columns].to_csv(write_test_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CreateDataFrame(train_path, test_path)\n",
    "df = df.pipe(ProccessOutliers).pipe(ProccessNanValues).pipe(Categorizing).pipe(FormatAndSave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert implementation into script file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_processed_data_script_file = os.path.join(os.path.pardir,'src','data','get_processed_data.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $get_processed_data_script_file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def CreateDataFrame():\n",
    "    project_dir = 'C:\\\\Users\\\\PLDD\\\\python\\\\Python\\\\ML\\\\Kaggle\\\\house_price'\n",
    "    raw_path = os.path.join(project_dir,'data','raw')\n",
    "    train_path = os.path.join(raw_path, 'train.csv')\n",
    "    test_path = os.path.join(raw_path, 'test.csv')\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    test_df['SalePrice'] = 0.0\n",
    "    df = train_df.append(test_df)\n",
    "    df.index = list(range(train_df.index.size + test_df.index.size))\n",
    "    df = df.drop('Utilities', axis = 1)\n",
    "    return df\n",
    "\n",
    "def ProccessOutliers(df):\n",
    "    lx = (df['LotFrontage'] > 200) | (df['LotArea'] > 100000) | (df['GrLivArea'] > 4000)\n",
    "    df.loc[df['LotFrontage'] > 200,'LotFrontage'] = np.nan\n",
    "    df.loc[df['LotArea'] > 100000,'LotArea'] = np.nan\n",
    "    df.loc[df['GrLivArea'] > 4000,'GrLivArea'] = np.nan\n",
    "    return df\n",
    "\n",
    "def ReplaceNanValues_LotFrontageArea(df, alables, abins, fromfld, tofld, catclass, targetclass):\n",
    "    fullclass = catclass + [targetclass]\n",
    "    df[tofld]=pd.cut(x = df[fromfld].values, bins = abins, right = False, labels = alables)\n",
    "    validdf = df[fullclass].dropna(axis = 0, how = 'any')\n",
    "    nandf = df[df[targetclass].isnull()]\n",
    "    pvt = validdf.pivot_table(values = targetclass, index = catclass, aggfunc = np.median)\n",
    "    pvt=pvt[pvt.notnull().all(1)]\n",
    "    t1 = pvt.loc[[tuple(x) for x in nandf[catclass].values]]\n",
    "    t1.index = nandf.index\n",
    "    df.loc[nandf.index,targetclass] = t1[targetclass]\n",
    "    df = df.drop(tofld, axis = 1)\n",
    "    return df\n",
    "\n",
    "def ProccessNanValues(df):\n",
    "    DefSeqCat = ['Alley','BsmtQual', 'BsmtCond', 'BsmtExposure','BsmtFinType1', 'BsmtFinType2', 'FireplaceQu',\n",
    "                 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC',\n",
    "                 'Fence', 'MiscFeature']\n",
    "    UndefSeqCat1 = ['MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd','Electrical', 'KitchenQual',\n",
    "                    'Functional', 'SaleType'] # there are defenetly lost elements \n",
    "    UndefSeqCat2 = ['MasVnrType'] # i may just not make it clear the property of the column\n",
    "    UndefSeqNum = ['LotFrontage', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n",
    "                   'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt', 'GarageCars', 'GarageArea']\n",
    "    replace=dict.fromkeys(DefSeqCat, 'None')\n",
    "    df = df.fillna(replace)\n",
    "#'MasVnrType'\n",
    "    ix = df.index[df['MasVnrType'].isnull()]\n",
    "    df.loc[ix,'MasVnrType'] = 'None'\n",
    "    df.loc[ix,'MasVnrArea'] = 0\n",
    "    NanCol = ['LotFrontage', 'MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
    "              'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "              'Electrical', 'BsmtFullBath', 'BsmtHalfBath', 'KitchenQual',\n",
    "              'Functional', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'SaleType']\n",
    "    #Replace NAN values in 'LotFrontage' and 'LotArea' with iterpolated value.\n",
    "    yearlable = ['1906', '1942', '1975', '1991', '2011']\n",
    "    yearbin = [1800,1906,1942,1975, 1991, 2011]\n",
    "#case 1\n",
    "    catclass = ['Neighborhood', 'LotConfig','LotShape','YearInt']\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage' )\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "    catclass = ['LotConfig','LotShape','YearInt']\n",
    "#case 2\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage')\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "#case 3\n",
    "    yearlable = ['1942', '1991', '2011']\n",
    "    yearbin = [1800, 1942, 1991, 2011]\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage')\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "#case 4\n",
    "    yearlable = ['1975', '1991', '2011']\n",
    "    yearbin = [1800, 1975, 1991, 2011]\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage')\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "#case 5\n",
    "    yearlable = ['2011']\n",
    "    yearbin = [1800, 2011]\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage')\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')   \n",
    "#Replace Nan in 'MSZoning'\n",
    "    ind1 = [1915, 2216, 2250] # C - assign by many factors\n",
    "    ind2 = [2904] # RL - by Lot Area, LotFrontage and YearBuilt \n",
    "    df.loc[ind1,'MSZoning'] = 'C'\n",
    "    df.loc[ind2,'MSZoning'] = 'RL'    \n",
    "#Replace Nan in 'Exterior1st' and 'Exterior2nd'\n",
    "    targetclass = ['Exterior1st', 'Exterior2nd']\n",
    "    ind = [2151]\n",
    "    df.loc[ind,targetclass] = 'AsbShng'  \n",
    "#Add column 'RangeYrBlt' and remove columns 'GarageYrBlt' and 'YearBilt'\n",
    "    yearbins = [1800, 1895, 1905, 1917, 1927, 1937,1947,1960, 1973, 1989, 1998, 2012]\n",
    "    yearlabels = ['1895', '1905', '1917', '1927', '1937', '1947', '1960', '1973', '1989', '1998', '2012']\n",
    "    if df.columns.isin(['YearBuilt']).any():\n",
    "        df['RangeYrBlt']=pd.cut(x = df['YearBuilt'].values, bins = yearbins, right = False, labels = yearlabels)\n",
    "        df = df.drop('YearBuilt', axis = 1)\n",
    "    if df.columns.isin(['GarageYrBlt']).any():\n",
    "        df = df.drop('GarageYrBlt', axis = 1)\n",
    "    df.loc[2120,['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF']] = 0\n",
    "    df.loc[1379, 'Electrical'] = 'SBrkr' #  all houses in 2012 year built have this type of Electrical\n",
    "    if df.columns.isin(['GrLivArea']).any():\n",
    "        df = df.drop('GrLivArea', axis = 1) # it is sum of '1stFlrSF' and '2ndFlrSF'\n",
    "    df.loc[[2120,2188],['BsmtFullBath', 'BsmtHalfBath']] = 0\n",
    "    df.loc[1555, 'KitchenQual'] = 'TA'\n",
    "    df.loc[[2216, 2473],'Functional'] = 'Typ'\n",
    "    df.loc[2576,'GarageArea'] = 0\n",
    "    if df.columns.isin(['GarageCars']).any():\n",
    "        df = df.drop('GarageCars', axis = 1) # it has straight dependency on garage area\n",
    "    df.loc[2489, 'SaleType'] = 'WD' # the most used type according to sold year and sale condition\n",
    "    return df\n",
    "\n",
    "def sorted_columns(df, what, bby):\n",
    "    t_df = df.loc[df[bby] != 0]\n",
    "    t_df = t_df.groupby([what]).agg({bby : 'median'})\n",
    "    t_df = t_df.sort_values(by = bby, axis = 0 )\n",
    "    return t_df.index.values\n",
    "\n",
    "def FormatAndSave(df):\n",
    "    dff = df.copy()\n",
    "    categorical_flds = dff.columns[dff.dtypes == 'category' ].values\n",
    "    dff = pd.get_dummies(dff)#, columns = categorical_flds)\n",
    "    processed_data_path = os.path.join(os.path.pardir,'data','processed')\n",
    "    write_train_path = os.path.join(processed_data_path, 'train.csv')\n",
    "    write_test_path = os.path.join(processed_data_path, 'test.csv')\n",
    "    dff.loc[dff.SalePrice != 0].to_csv(write_train_path) \n",
    "    columns = [column for column in dff.columns if column != 'SalePrice']\n",
    "    dff.loc[dff.SalePrice == 0, columns].to_csv(write_test_path) \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = CreateDataFrame()\n",
    "    df = df.pipe(ProccessOutliers).pipe(ProccessNanValues).pipe(FormatAndSave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python $get_processed_data_script_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = os.path.join(os.path.pardir,'data','processed')\n",
    "write_train_path = os.path.join(processed_data_path, 'train.csv')\n",
    "write_test_path = os.path.join(processed_data_path, 'test.csv')\n",
    "train_df = pd.read_csv(write_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = os.path.join(os.path.pardir,'data','processed')\n",
    "train_path = os.path.join(processed_data_path, 'train.csv')\n",
    "test_path = os.path.join(processed_data_path, 'test.csv')\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_ml_solve(train_df, test_df, scaler, solver, q = 0.4, target = 'temp.csv'):\n",
    "    X = train_df.loc[:,train_df.columns != 'SalePrice'].as_matrix().astype('float')\n",
    "    y = train_df['SalePrice'].ravel()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=q, random_state=0)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    if q != 0:\n",
    "        X_test = scaler.transform(X_test)\n",
    "        solver.fit(X_train, y_train)\n",
    "        print(solver.score(X_test, y_test))\n",
    "    else: \n",
    "        print(\"No test subsets!!!!\")\n",
    "    X = scaler.fit_transform(X)    \n",
    "    XX = scaler.transform(test_df.as_matrix().astype('float'))\n",
    "    solver.fit(X, y) \n",
    "    pred_y = solver.predict(XX).astype('int')\n",
    "    df_submission = pd.DataFrame({'Id': test_df['Id'].values, 'SalePrice' : pred_y} )\n",
    "    submission_data_path = os.path.join(os.path.pardir,'data','external')\n",
    "    submission_file_path = os.path.join(submission_data_path, target)\n",
    "    df_submission.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing.data import QuantileTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler3 = RobustScaler()\n",
    "scaler4 = Normalizer()\n",
    "scaler5 = QuantileTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver1 = linear_model.RidgeCV(alphas = np.arange(0.001, 5, 0.001))\n",
    "solver2 = linear_model.LassoCV()\n",
    "solver3 = linear_model.ElasticNetCV(alphas = np.arange(0.001, 5, 0.001), max_iter = 20000 )\n",
    "solver4 = linear_model.BayesianRidge()\n",
    "solver5 = KernelRidge(alpha=1.0,kernel='polynomial')\n",
    "solver5_1 = GridSearchCV(KernelRidge(kernel='rbf', gamma=0.1), cv=5,\n",
    "                  param_grid={\"alpha\": [1e0, 0.1, 1e-2, 1e-3],\n",
    "                              \"gamma\": np.logspace(-2, 2, 5)})\n",
    "solver6 = linear_model.PassiveAggressiveRegressor(C = 10,tol = 0.00001, max_iter = 50000)\n",
    "solver7 = linear_model.HuberRegressor(max_iter=10000)\n",
    "solver8 = Pipeline([('poly', PolynomialFeatures(degree=2)),  ('linear', solver1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_ml_solve(train_df, test_df, scaler5, solver5_1, 0.4,'03_KernelRidge_RBF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
