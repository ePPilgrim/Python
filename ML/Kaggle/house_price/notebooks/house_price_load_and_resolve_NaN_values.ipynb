{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "project_dir = 'C:\\\\Users\\\\PLDD\\\\python\\\\Python\\\\ML\\\\Kaggle\\\\house_price'\n",
    "raw_path = os.path.join(project_dir,'data','raw')\n",
    "train_path = os.path.join(raw_path, 'train.csv')\n",
    "test_path = os.path.join(raw_path, 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Create data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines train and test data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateDataFrame(train_path, test_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    test_df['SalePrice'] = 0.0\n",
    "    df = train_df.append(test_df)\n",
    "    df.index = list(range(train_df.index.size + test_df.index.size))\n",
    "    # 2916 out of 2919 Utilities are AllPub so i think it should be droped off\n",
    "    df = df.drop('Utilities', axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proccess outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ProccessOutliers(df):\n",
    "#'LotFrontage', 'LotArea', 'MasVnrArea', 'GrLivArea', 'GarageArea', 'PoolArea', 'SalePrice']\n",
    "#copydf['LotFrontage'].plot.hist()\n",
    "#copydf['LotFrontage'].plot.box()\n",
    "#copydf['LotArea'].plot.hist()\n",
    "#copydf['LotArea'].plot.box()\n",
    "#copydf['GrLivArea'].plot.hist()\n",
    "#copydf['GrLivArea'].plot.box()\n",
    "#plt.show()\n",
    "    lx = (df['LotFrontage'] > 200) | (df['LotArea'] > 100000) | (df['GrLivArea'] > 4000)\n",
    "#df = df.drop(df.index[lx], axis = 0)\n",
    "    df.loc[df['LotFrontage'] > 200,'LotFrontage'] = np.nan\n",
    "    df.loc[df['LotArea'] > 100000,'LotArea'] = np.nan\n",
    "    df.loc[df['GrLivArea'] > 4000,'GrLivArea'] = np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proccess Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ReplaceNanValues_LotFrontageArea(df, alables, abins, fromfld, tofld, catclass, targetclass):\n",
    "    fullclass = catclass + [targetclass]\n",
    "    df[tofld]=pd.cut(x = df[fromfld].values, bins = abins, right = False, labels = alables)\n",
    "    validdf = df[fullclass].dropna(axis = 0, how = 'any')\n",
    "    nandf = df[df[targetclass].isnull()]\n",
    "    pvt = validdf.pivot_table(values = targetclass, index = catclass, aggfunc = np.median)\n",
    "    pvt=pvt[pvt.notnull().all(1)]\n",
    "    t1 = pvt.loc[[tuple(x) for x in nandf[catclass].values]]\n",
    "    t1.index = nandf.index\n",
    "    df.loc[nandf.index,targetclass] = t1[targetclass]\n",
    "    df = df.drop(tofld, axis = 1)\n",
    "    return df\n",
    "\n",
    "def ProccessNanValues(df):\n",
    "    DefSeqCat = ['Alley','BsmtQual', 'BsmtCond', 'BsmtExposure','BsmtFinType1', 'BsmtFinType2', 'FireplaceQu',\n",
    "                 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC',\n",
    "                 'Fence', 'MiscFeature']\n",
    "    UndefSeqCat1 = ['MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd','Electrical', 'KitchenQual',\n",
    "                    'Functional', 'SaleType'] # there are defenetly lost elements \n",
    "    UndefSeqCat2 = ['MasVnrType'] # i may just not make it clear the property of the column\n",
    "    UndefSeqNum = ['LotFrontage', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n",
    "                   'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt', 'GarageCars', 'GarageArea']\n",
    "\n",
    "    replace=dict.fromkeys(DefSeqCat, 'None')\n",
    "    df = df.fillna(replace)\n",
    "#'MasVnrType'\n",
    "    ix = df.index[df['MasVnrType'].isnull()]\n",
    "    df.loc[ix,'MasVnrType'] = 'None'\n",
    "    df.loc[ix,'MasVnrArea'] = 0\n",
    "\n",
    "    NanCol = ['LotFrontage', 'MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
    "              'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "              'Electrical', 'BsmtFullBath', 'BsmtHalfBath', 'KitchenQual',\n",
    "              'Functional', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'SaleType']\n",
    "    #Replace NAN values in 'LotFrontage' and 'LotArea' with iterpolated value.\n",
    "    yearlable = ['1906', '1942', '1975', '1991', '2011']\n",
    "    yearbin = [1800,1906,1942,1975, 1991, 2011]\n",
    "\n",
    "#case 1\n",
    "    catclass = ['Neighborhood', 'LotConfig','LotShape','YearInt']\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage' )\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "\n",
    "    catclass = ['LotConfig','LotShape','YearInt']\n",
    "#case 2\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage')\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "\n",
    "#case 3\n",
    "    yearlable = ['1942', '1991', '2011']\n",
    "    yearbin = [1800, 1942, 1991, 2011]\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage')\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "\n",
    "#case 4\n",
    "    yearlable = ['1975', '1991', '2011']\n",
    "    yearbin = [1800, 1975, 1991, 2011]\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage')\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "\n",
    "#case 5\n",
    "    yearlable = ['2011']\n",
    "    yearbin = [1800, 2011]\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage')\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "    #print(df[df['LotArea'].isnull()].index.size)\n",
    "    \n",
    "    #Replace Nan in 'MSZoning'\n",
    "    ind1 = [1915, 2216, 2250] # C - assign by many factors\n",
    "    ind2 = [2904] # RL - by Lot Area, LotFrontage and YearBuilt \n",
    "    df.loc[ind1,'MSZoning'] = 'C'\n",
    "    df.loc[ind2,'MSZoning'] = 'RL'\n",
    "    \n",
    "    #Replace Nan in 'Exterior1st' and 'Exterior2nd'\n",
    "    targetclass = ['Exterior1st', 'Exterior2nd']\n",
    "    ind = [2151]\n",
    "    df.loc[ind,targetclass] = 'AsbShng'\n",
    "    \n",
    "    #Add column 'RangeYrBlt' and remove columns 'GarageYrBlt' and 'YearBilt'\n",
    "    yearbins = [1800, 1895, 1905, 1917, 1927, 1937,1947,1960, 1973, 1989, 1998, 2012]\n",
    "    yearlabels = ['1895', '1905', '1917', '1927', '1937', '1947', '1960', '1973', '1989', '1998', '2012']\n",
    "    if df.columns.isin(['YearBuilt']).any():\n",
    "        df['RangeYrBlt']=pd.cut(x = df['YearBuilt'].values, bins = yearbins, right = False, labels = yearlabels)\n",
    "        df = df.drop('YearBuilt', axis = 1)\n",
    "    if df.columns.isin(['GarageYrBlt']).any():\n",
    "        df = df.drop('GarageYrBlt', axis = 1)\n",
    "    \n",
    "    #Replace Nan in 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF' (row index - 2120)\n",
    "    # There is no basement in this house so all areas we take as 0\n",
    "    df.loc[2120,['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF']] = 0\n",
    "    \n",
    "    #Replase Nan in 'Electrical' (row index - 1379)\n",
    "    df.loc[1379, 'Electrical'] = 'SBrkr' #  all houses in 2012 year built have this type of Electrical\n",
    "    \n",
    "    #Replase Nan in 'GrLivArea'\n",
    "    if df.columns.isin(['GrLivArea']).any():\n",
    "        df = df.drop('GrLivArea', axis = 1) # it is sum of '1stFlrSF' and '2ndFlrSF'\n",
    "        \n",
    "    #Replace Nan in 'BsmtFullBath' and 'BsmtHalfBath' (row indexes are 2120 and 2188) # all these houses have no basements\n",
    "    df.loc[[2120,2188],['BsmtFullBath', 'BsmtHalfBath']] = 0\n",
    "    \n",
    "    #Replace Nan in 'KitchenQual' (row index is 1555)\n",
    "    # Value of 'KitchenQual' depends on 'OverallQual', 'OverallCond'\n",
    "    df.loc[1555, 'KitchenQual'] = 'TA'\n",
    "    \n",
    "    #Replace Nan in 'Functional' (row indexes are 2216, 2473)\n",
    "    # The most used functionality is 'Typ'\n",
    "    df.loc[[2216, 2473],'Functional'] = 'Typ'\n",
    "    \n",
    "    #Replace Nan in 'GarageCars', 'GarageArea' (row index is 2576)\n",
    "    #there is no garage so its area is 0\n",
    "    df.loc[2576,'GarageArea'] = 0\n",
    "    if df.columns.isin(['GarageCars']).any():\n",
    "        df = df.drop('GarageCars', axis = 1) # it has straight dependency on garage area\n",
    "        \n",
    "    #Replace Nan in 'SaleType' (row index is 2489)\n",
    "    df.loc[2489, 'SaleType'] = 'WD' # the most used type according to sold year and sale condition\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sorted_columns(df, what, bby):\n",
    "    t_df = df.loc[df[bby] != 0]\n",
    "    t_df = t_df.groupby([what]).agg({bby : 'median'})\n",
    "    t_df = t_df.sort_values(by = bby, axis = 0 )\n",
    "    return t_df.index.values\n",
    "\n",
    "def Categorizing(copydf):\n",
    "\n",
    "    OrderedCat = ['MSZoning', 'Street','Alley', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofMatl']\n",
    "    NonOrderedCat = ['LandContour', 'LotConfig', 'LotShape', 'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'RoofStyle'\n",
    "                'Exterior1st','Exterior2nd']\n",
    "\n",
    "    copydf['MSZoning'] = pd.Categorical(copydf['MSZoning'].values, ['C', 'C (all)', 'RM', 'RH', 'RL', 'FV'], ordered = True)\n",
    "    copydf['Street'] = pd.Categorical(copydf['Street'].values, ['Grvl','Pave'], ordered = True)\n",
    "    copydf['Alley'] = pd.Categorical(copydf['Alley'].values, ['None', 'Grvl', 'Pave'], ordered = True)\n",
    "    copydf['LotShape'] = pd.Categorical(copydf['LotShape'].values, ['Reg', 'IR1', 'IR2', 'IR3'], ordered = True) # can be droped\n",
    "    copydf['LandContour'] = pd.Categorical(copydf['LandContour'].values, ['Lvl', 'Bnk', 'Low', 'HLS'], ordered = True)\n",
    "    copydf['LotConfig'] = pd.Categorical(copydf['LotConfig'].values, ['FR2', 'Corner', 'Inside', 'CulDSac', 'FR3'], ordered = True)\n",
    "    copydf['LandSlope'] = pd.Categorical(copydf['LandSlope'].values, ['Sev', 'Mod', 'Gtl'], ordered = True)\n",
    "    copydf['Neighborhood'] = pd.Categorical(copydf['Neighborhood'].values, sorted_columns(copydf.loc[copydf.SalePrice != 0], 'Neighborhood' , 'SalePrice'), ordered = True)\n",
    "    copydf['Condition1'] = pd.Categorical(copydf['Condition1'].values, ['PosA', 'PosN', 'Norm', 'RRNn', 'RRNe', 'RRAe',  'RRAn', 'Feedr', 'Artery'], ordered = True)\n",
    "    copydf['Condition2'] = pd.Categorical(copydf['Condition2'].values, ['PosA', 'PosN', 'Norm', 'RRNn', 'RRAe', 'RRAn','Feedr', 'Artery'], ordered = True)\n",
    "    copydf['BldgType'] = pd.Categorical(copydf['BldgType'].values, ['2fmCon', 'Duplex', 'Twnhs', 'TwnhsE', '1Fam'], ordered = True)\n",
    "    copydf['HouseStyle'] = pd.Categorical(copydf['HouseStyle'].values, ['1.5Unf', '1.5Fin', 'SFoyer', 'SLvl', '1Story', '2.5Unf', '2.5Fin', '2Story'], ordered = True)\n",
    "    copydf['RoofStyle'] = pd.Categorical(copydf['RoofStyle'].values, sorted_columns(copydf.loc[copydf.SalePrice != 0], 'RoofStyle', 'SalePrice'), ordered = True)\n",
    "    copydf['RoofMatl'] = pd.Categorical(copydf['RoofMatl'].values, ['Roll', 'ClyTile', 'Metal', 'CompShg', 'Tar&Grv', 'Membran', 'WdShake', 'WdShngl'], ordered = True)\n",
    "    copydf['Exterior1st'] = pd.Categorical(copydf['Exterior1st'].values, sorted_columns(copydf.loc[copydf.SalePrice != 0], 'Exterior1st', 'SalePrice'), ordered = True)\n",
    "    copydf['Exterior2nd'] = pd.Categorical(copydf['Exterior2nd'].values, sorted_columns(copydf.loc[copydf.SalePrice != 0], 'Exterior2nd', 'SalePrice'), ordered = True)\n",
    "    copydf['MasVnrType'] = pd.Categorical(copydf['MasVnrType'].values, sorted_columns(copydf.loc[copydf.SalePrice != 0], 'MasVnrType', 'SalePrice'), ordered = True)\n",
    "    copydf['ExterQual'] = pd.Categorical(copydf['ExterQual'].values, ['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['ExterCond'] = pd.Categorical(copydf['ExterCond'].values, ['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['Foundation'] = pd.Categorical(copydf['Foundation'].values, ['Slab', 'Stone', 'Wood', 'BrkTil', 'CBlock', 'PConc'], ordered = True)\n",
    "    copydf['BsmtQual'] = pd.Categorical(copydf['BsmtQual'].values, ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['BsmtCond'] = pd.Categorical(copydf['BsmtCond'].values, ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['BsmtExposure'] = pd.Categorical(copydf['BsmtExposure'].values, ['None', 'No', 'Mn', 'Av', 'Gd'], ordered = True)\n",
    "    copydf['BsmtFinType1'] = pd.Categorical(copydf['BsmtFinType1'].values, ['None', 'LwQ', 'Rec','Unf','BLQ','ALQ','GLQ'], ordered = True)\n",
    "    copydf['BsmtFinType2'] = pd.Categorical(copydf['BsmtFinType2'].values, ['None', 'LwQ', 'Rec','Unf','BLQ','ALQ','GLQ'], ordered = True)\n",
    "    copydf['Heating'] = pd.Categorical(copydf['Heating'].values, ['Floor', 'Grav', 'Wall', 'OthW', 'GasW','GasA'], ordered = True)\n",
    "    copydf['HeatingQC'] = pd.Categorical(copydf['HeatingQC'].values, ['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['CentralAir'] = pd.Categorical(copydf['CentralAir'].values, ['N', 'Y'], ordered = True)\n",
    "    copydf['Electrical'] = pd.Categorical(copydf['Electrical'].values, ['Mix', 'FuseP', 'FuseF', 'FuseA', 'SBrkr' ], ordered = True)\n",
    "    copydf['KitchenQual'] = pd.Categorical(copydf['KitchenQual'].values, ['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['Functional'] = pd.Categorical(copydf['Functional'].values, ['Sev', 'Maj2', 'Maj1', 'Min1', 'Min2', 'Mod', 'Typ'], ordered = True)\n",
    "    copydf['FireplaceQu'] = pd.Categorical(copydf['FireplaceQu'].values, ['None','Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['GarageType'] = pd.Categorical(copydf['GarageType'].values, ['None', 'CarPort','Detchd', '2Types', 'Basment', 'Attchd', 'BuiltIn'], ordered = True)\n",
    "    copydf['GarageFinish'] = pd.Categorical(copydf['GarageFinish'].values, ['None', 'Unf', 'RFn', 'Fin'], ordered = True)\n",
    "    copydf['GarageQual'] = pd.Categorical(copydf['GarageQual'].values, ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['GarageCond'] = pd.Categorical(copydf['GarageCond'].values, ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['PavedDrive'] = pd.Categorical(copydf['PavedDrive'].values, ['N', 'P', 'Y'], ordered = True)\n",
    "\n",
    "    copydf['PoolQC'] = pd.Categorical(copydf['PoolQC'].values, ['None', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)\n",
    "    copydf['Fence'] = pd.Categorical(copydf['Fence'].values, ['MnWw', 'GdWo', 'MnPrv', 'GdPrv', 'None'], ordered = True)\n",
    "    copydf['MiscFeature'] = pd.Categorical(copydf['MiscFeature'].values, ['Othr', 'Shed', 'Gar2', 'None', 'TenC'], ordered = True)\n",
    "    copydf['SaleType'] = pd.Categorical(copydf['SaleType'].values, ['Oth', 'ConLD', 'ConLw', 'COD', 'WD', 'ConLI', 'CWD', 'Con', 'New'], ordered = True)\n",
    "    copydf['SaleCondition'] = pd.Categorical(copydf['SaleCondition'].values, ['AdjLand', 'Abnorml', 'Family', 'Alloca', 'Normal', 'Partial'], ordered = True)\n",
    "\n",
    "    #print(copydf.columns[copydf.dtypes == 'object'].size)\n",
    "    return copydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FormatAndSave(df):\n",
    "    dff = df.copy()\n",
    "    categorical_flds = dff.columns[dff.dtypes == 'category'].values\n",
    "    dff = pd.get_dummies(dff, columns = categorical_flds)\n",
    "    \n",
    "    processed_data_path = os.path.join(os.path.pardir,'data','processed')\n",
    "    write_train_path = os.path.join(processed_data_path, 'train.csv')\n",
    "    write_test_path = os.path.join(processed_data_path, 'test.csv')\n",
    "    \n",
    "    # train data\n",
    "    dff.loc[dff.SalePrice != 0].to_csv(write_train_path) \n",
    "    # test data\n",
    "    columns = [column for column in dff.columns if column != 'SalePrice']\n",
    "    dff.loc[dff.SalePrice == 0, columns].to_csv(write_test_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = CreateDataFrame(train_path, test_path)\n",
    "df = df.pipe(ProccessOutliers).pipe(ProccessNanValues).pipe(Categorizing).pipe(FormatAndSave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert implementation into script file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_processed_data_script_file = os.path.join(os.path.pardir,'src','data','get_processed_data.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ..\\src\\data\\get_processed_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $get_processed_data_script_file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def CreateDataFrame():\n",
    "    project_dir = 'C:\\\\Users\\\\PLDD\\\\python\\\\Python\\\\ML\\\\Kaggle\\\\house_price'\n",
    "    raw_path = os.path.join(project_dir,'data','raw')\n",
    "    train_path = os.path.join(raw_path, 'train.csv')\n",
    "    test_path = os.path.join(raw_path, 'test.csv')\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    test_df['SalePrice'] = 0.0\n",
    "    df = train_df.append(test_df)\n",
    "    df.index = list(range(train_df.index.size + test_df.index.size))\n",
    "    df = df.drop('Utilities', axis = 1)\n",
    "    return df\n",
    "\n",
    "def ProccessOutliers(df):\n",
    "    lx = (df['LotFrontage'] > 200) | (df['LotArea'] > 100000) | (df['GrLivArea'] > 4000)\n",
    "    df.loc[df['LotFrontage'] > 200,'LotFrontage'] = np.nan\n",
    "    df.loc[df['LotArea'] > 100000,'LotArea'] = np.nan\n",
    "    df.loc[df['GrLivArea'] > 4000,'GrLivArea'] = np.nan\n",
    "    return df\n",
    "\n",
    "def ReplaceNanValues_LotFrontageArea(df, alables, abins, fromfld, tofld, catclass, targetclass):\n",
    "    fullclass = catclass + [targetclass]\n",
    "    df[tofld]=pd.cut(x = df[fromfld].values, bins = abins, right = False, labels = alables)\n",
    "    validdf = df[fullclass].dropna(axis = 0, how = 'any')\n",
    "    nandf = df[df[targetclass].isnull()]\n",
    "    pvt = validdf.pivot_table(values = targetclass, index = catclass, aggfunc = np.median)\n",
    "    pvt=pvt[pvt.notnull().all(1)]\n",
    "    t1 = pvt.loc[[tuple(x) for x in nandf[catclass].values]]\n",
    "    t1.index = nandf.index\n",
    "    df.loc[nandf.index,targetclass] = t1[targetclass]\n",
    "    df = df.drop(tofld, axis = 1)\n",
    "    return df\n",
    "\n",
    "def ProccessNanValues(df):\n",
    "    DefSeqCat = ['Alley','BsmtQual', 'BsmtCond', 'BsmtExposure','BsmtFinType1', 'BsmtFinType2', 'FireplaceQu',\n",
    "                 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC',\n",
    "                 'Fence', 'MiscFeature']\n",
    "    UndefSeqCat1 = ['MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd','Electrical', 'KitchenQual',\n",
    "                    'Functional', 'SaleType'] # there are defenetly lost elements \n",
    "    UndefSeqCat2 = ['MasVnrType'] # i may just not make it clear the property of the column\n",
    "    UndefSeqNum = ['LotFrontage', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n",
    "                   'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt', 'GarageCars', 'GarageArea']\n",
    "    replace=dict.fromkeys(DefSeqCat, 'None')\n",
    "    df = df.fillna(replace)\n",
    "#'MasVnrType'\n",
    "    ix = df.index[df['MasVnrType'].isnull()]\n",
    "    df.loc[ix,'MasVnrType'] = 'None'\n",
    "    df.loc[ix,'MasVnrArea'] = 0\n",
    "    NanCol = ['LotFrontage', 'MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
    "              'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "              'Electrical', 'BsmtFullBath', 'BsmtHalfBath', 'KitchenQual',\n",
    "              'Functional', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'SaleType']\n",
    "    #Replace NAN values in 'LotFrontage' and 'LotArea' with iterpolated value.\n",
    "    yearlable = ['1906', '1942', '1975', '1991', '2011']\n",
    "    yearbin = [1800,1906,1942,1975, 1991, 2011]\n",
    "#case 1\n",
    "    catclass = ['Neighborhood', 'LotConfig','LotShape','YearInt']\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage' )\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "    catclass = ['LotConfig','LotShape','YearInt']\n",
    "#case 2\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage')\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "#case 3\n",
    "    yearlable = ['1942', '1991', '2011']\n",
    "    yearbin = [1800, 1942, 1991, 2011]\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage')\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "#case 4\n",
    "    yearlable = ['1975', '1991', '2011']\n",
    "    yearbin = [1800, 1975, 1991, 2011]\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage')\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')\n",
    "    #print(df[df['LotFrontage'].isnull()].index.size)\n",
    "#case 5\n",
    "    yearlable = ['2011']\n",
    "    yearbin = [1800, 2011]\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotFrontage')\n",
    "    df = ReplaceNanValues_LotFrontageArea(df, yearlable, yearbin, 'YearBuilt', 'YearInt', catclass, 'LotArea')   \n",
    "#Replace Nan in 'MSZoning'\n",
    "    ind1 = [1915, 2216, 2250] # C - assign by many factors\n",
    "    ind2 = [2904] # RL - by Lot Area, LotFrontage and YearBuilt \n",
    "    df.loc[ind1,'MSZoning'] = 'C'\n",
    "    df.loc[ind2,'MSZoning'] = 'RL'    \n",
    "#Replace Nan in 'Exterior1st' and 'Exterior2nd'\n",
    "    targetclass = ['Exterior1st', 'Exterior2nd']\n",
    "    ind = [2151]\n",
    "    df.loc[ind,targetclass] = 'AsbShng'  \n",
    "#Add column 'RangeYrBlt' and remove columns 'GarageYrBlt' and 'YearBilt'\n",
    "    yearbins = [1800, 1895, 1905, 1917, 1927, 1937,1947,1960, 1973, 1989, 1998, 2012]\n",
    "    yearlabels = ['1895', '1905', '1917', '1927', '1937', '1947', '1960', '1973', '1989', '1998', '2012']\n",
    "    if df.columns.isin(['YearBuilt']).any():\n",
    "        df['RangeYrBlt']=pd.cut(x = df['YearBuilt'].values, bins = yearbins, right = False, labels = yearlabels)\n",
    "        df = df.drop('YearBuilt', axis = 1)\n",
    "    if df.columns.isin(['GarageYrBlt']).any():\n",
    "        df = df.drop('GarageYrBlt', axis = 1)\n",
    "    df.loc[2120,['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF']] = 0\n",
    "    df.loc[1379, 'Electrical'] = 'SBrkr' #  all houses in 2012 year built have this type of Electrical\n",
    "    if df.columns.isin(['GrLivArea']).any():\n",
    "        df = df.drop('GrLivArea', axis = 1) # it is sum of '1stFlrSF' and '2ndFlrSF'\n",
    "    df.loc[[2120,2188],['BsmtFullBath', 'BsmtHalfBath']] = 0\n",
    "    df.loc[1555, 'KitchenQual'] = 'TA'\n",
    "    df.loc[[2216, 2473],'Functional'] = 'Typ'\n",
    "    df.loc[2576,'GarageArea'] = 0\n",
    "    if df.columns.isin(['GarageCars']).any():\n",
    "        df = df.drop('GarageCars', axis = 1) # it has straight dependency on garage area\n",
    "    df.loc[2489, 'SaleType'] = 'WD' # the most used type according to sold year and sale condition\n",
    "    return df\n",
    "\n",
    "def sorted_columns(df, what, bby):\n",
    "    t_df = df.loc[df[bby] != 0]\n",
    "    t_df = t_df.groupby([what]).agg({bby : 'median'})\n",
    "    t_df = t_df.sort_values(by = bby, axis = 0 )\n",
    "    return t_df.index.values\n",
    "\n",
    "def FormatAndSave(df):\n",
    "    dff = df.copy()\n",
    "    categorical_flds = dff.columns[dff.dtypes == 'category' ].values\n",
    "    dff = pd.get_dummies(dff)#, columns = categorical_flds)\n",
    "    processed_data_path = os.path.join(os.path.pardir,'data','processed')\n",
    "    write_train_path = os.path.join(processed_data_path, 'train.csv')\n",
    "    write_test_path = os.path.join(processed_data_path, 'test.csv')\n",
    "    dff.loc[dff.SalePrice != 0].to_csv(write_train_path) \n",
    "    columns = [column for column in dff.columns if column != 'SalePrice']\n",
    "    dff.loc[dff.SalePrice == 0, columns].to_csv(write_test_path) \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = CreateDataFrame()\n",
    "    df = df.pipe(ProccessOutliers).pipe(ProccessNanValues).pipe(FormatAndSave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python $get_processed_data_script_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_data_path = os.path.join(os.path.pardir,'data','processed')\n",
    "write_train_path = os.path.join(processed_data_path, 'train.csv')\n",
    "write_test_path = os.path.join(processed_data_path, 'test.csv')\n",
    "train_df = pd.read_csv(write_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_data_path = os.path.join(os.path.pardir,'data','processed')\n",
    "train_path = os.path.join(processed_data_path, 'train.csv')\n",
    "test_path = os.path.join(processed_data_path, 'test.csv')\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_ml_solve(train_df, test_df, scaler, solver, q = 0.4, target = 'temp.csv'):\n",
    "    X = train_df.loc[:,train_df.columns != 'SalePrice'].as_matrix().astype('float')\n",
    "    y = train_df['SalePrice'].ravel()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=q, random_state=0)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    if q != 0:\n",
    "        X_test = scaler.transform(X_test)\n",
    "        solver.fit(X_train, y_train)\n",
    "        print(solver.score(X_test, y_test))\n",
    "    else: \n",
    "        print(\"No test subsets!!!!\")\n",
    "    X = scaler.fit_transform(X)    \n",
    "    XX = scaler.transform(test_df.as_matrix().astype('float'))\n",
    "    solver.fit(X, y) \n",
    "    pred_y = solver.predict(XX).astype('int')\n",
    "    df_submission = pd.DataFrame({'Id': test_df['Id'].values, 'SalePrice' : pred_y} )\n",
    "    submission_data_path = os.path.join(os.path.pardir,'data','external')\n",
    "    submission_file_path = os.path.join(submission_data_path, target)\n",
    "    df_submission.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing.data import QuantileTransformer\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler3 = RobustScaler()\n",
    "scaler4 = Normalizer()\n",
    "scaler5 = QuantileTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver1 = linear_model.RidgeCV(alphas = np.arange(0.001, 5, 0.001))\n",
    "solver2 = linear_model.LassoCV()\n",
    "solver3 = linear_model.ElasticNetCV(alphas = np.arange(0.001, 5, 0.001), max_iter = 20000 )\n",
    "solver4 = linear_model.BayesianRidge()\n",
    "solver5 = KernelRidge(alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78525701856\n"
     ]
    }
   ],
   "source": [
    "linear_ml_solve(train_df, test_df, scaler5, solver5, 0.4,'01_KernelRidgeCV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.35168188e+09,   4.07434521e+09,   3.47830409e+09],\n",
       "       [  3.35145278e+09,   4.07411892e+09,   3.47809741e+09],\n",
       "       [  3.35122128e+09,   4.07389038e+09,   3.47788856e+09],\n",
       "       ..., \n",
       "       [  7.05220451e+08,   1.05793903e+09,   1.36422944e+09],\n",
       "       [  7.08151297e+08,   1.06957325e+09,   1.41638254e+09],\n",
       "       [  7.21870661e+08,   1.09479161e+09,   1.50137744e+09]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver3.mse_path_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
