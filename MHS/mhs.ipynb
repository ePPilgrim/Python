{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import os as os\n",
    "import fetchyc\n",
    "import collections\n",
    "import kerastuner as kt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#!pip install -q requests\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fetch and expand to new terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NelsonSiegelLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, thau0 = 64.0, eps = 0.00001):\n",
    "        super(NelsonSiegelLayer, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.thau = self.add_weight(name = \"Thau\", shape = (), \n",
    "                                     initializer = tf.keras.initializers.Constant(thau0),\n",
    "                                     #constraint = tf.keras.constraints.NonNeg(),\n",
    "                                     trainable = True)\n",
    "        self.alpha0 = self.add_weight(name = \"Alpha0\", shape = (), \n",
    "                                     initializer = tf.keras.initializers.RandomUniform(0.0, 1.0),\n",
    "                                     constraint = tf.keras.constraints.NonNeg(),\n",
    "                                     trainable = True)\n",
    "        self.alpha1 = self.add_weight(name = \"Alpha1\", shape = (), \n",
    "                                     initializer = tf.keras.initializers.RandomUniform(0.0, 1.0),\n",
    "                                     constraint = tf.keras.constraints.NonNeg(),\n",
    "                                     trainable = True)\n",
    "        self.alpha2 = self.add_weight(name = \"Alpha2\", shape = (), \n",
    "                                     initializer = \"random_normal\",                           \n",
    "                                     trainable = True)\n",
    "        #self.bias = self.add_weight(name = \"Bias\", shape = (), trainable = True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        val1 = tf.divide(inputs, self.thau)\n",
    "        val2 = tf.math.exp(-val1)\n",
    "        val3 = tf.divide(1.0 - val2, val1)\n",
    "        eps = self.eps\n",
    "        return tf.add(tf.math.multiply(self.alpha0 + eps, 1.0 - val3), \n",
    "                                       tf.add(tf.math.multiply(self.alpha1 + eps, val3),\n",
    "                                        tf.math.multiply(self.alpha2, val3 - val2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapelement(window):\n",
    "    obss = tf.convert_to_tensor(np.array([[-256.0], [-256.0]]), dtype = tf.float32)\n",
    "    for key, x in TermMapToMonth.items():\n",
    "        if key not in table:\n",
    "            continue\n",
    "        xy = table[key]\n",
    "        xy = tf.stack([xy, tf.repeat(x,xy.shape[0])])\n",
    "        obss = tf.concat([obss,xy], axis = 1) \n",
    "    lx = obss[0] > -255.0\n",
    "    print(obss)\n",
    "    obss = tf.boolean_mask(obss, lx, axis = 1)\n",
    "    median = table['Date'].shape[0] // 2\n",
    "    return {'Date' : table['Date'][median], 'XY' : obss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "TermMapToMonth = { 'M01' : 1.0, 'M02' : 2.0, 'M03' : 3.0, 'M04' : 4.0, 'M05' : 5.0, 'M06' : 6.0, 'M07' : 7.0, 'M08' : 8.0,\n",
    "                    'M09' : 9.0, 'M10' : 10.0, 'M11' : 11.0, \n",
    "                    'Y01' : 12.0, 'Y02' : 24.0, 'Y03' : 36.0, 'Y04' : 48.0, 'Y05' : 60.0, 'Y06' : 72.0, 'Y07' : 84.0,\n",
    "                    'Y08' : 96.0, 'Y09' : 108.0, 'Y10' : 120.0, 'Y12' : 144.0, 'Y15' : 180.0, 'Y20' : 240.0,\n",
    "                    'Y25' : 300.0, 'Y30' : 360.0, 'Y40' : 480.0, 'Y50' : 600.0}\n",
    "\n",
    "class NelsonSiegelParameters:\n",
    "    def __init__(self, ww = 7, thauv = [16, 32, 64, 128], lr = 0.1, epochs = 256):\n",
    "        self.ww = ww\n",
    "        self.thauv = thauv\n",
    "        self.nsld = {'Thau_{}'.format(thau) : NelsonSiegelLayer(thau0 = thau) for thau in self.thauv}\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.modelv = [self.__create_model(nsl) for nsl in self.nsld.values()]\n",
    "        self.histv = None\n",
    "        self.resdf = pd.DataFrame(columns = ['Date', 'Alpha0', 'Alpha1', 'Alpha2', 'Thau'])\n",
    "                                  \n",
    "    def __create_model(self,nsl):\n",
    "        inputs = tf.keras.Input(shape = ())\n",
    "        outputs = nsl(inputs)\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "        model.compile(optimizer=Adam(lr=self.lr), loss=\"mse\")\n",
    "        return model        \n",
    "    \n",
    "    def __train_step(self, x, y):\n",
    "        self.histv = [model.fit(x, y, epochs = self.epochs, verbose = 0) for model in self.modelv]\n",
    "        \n",
    "    def find_parameters(self, filename):\n",
    "        cv = list(pd.read_csv(filename, nrows = 0).columns)\n",
    "        rec = [tf.float32] * len(cv)\n",
    "        rec[cv.index('Date')] = tf.string\n",
    "        dataset = tf.data.experimental.CsvDataset(filename, rec, header = True).window(self.ww,1,1,True)\n",
    "        resdict = {key : [] for key in self.resdf.columns}\n",
    "        for window in dataset:\n",
    "            mdate, x, y = None, None, None\n",
    "            for column, component in zip(cv, window):\n",
    "                if column == 'Date':\n",
    "                    mdate = list(component.as_numpy_iterator())\n",
    "                    mdate = mdate[len(mdate) // 2]\n",
    "                    continue\n",
    "                _y = np.array(list(component.as_numpy_iterator()))\n",
    "                _y = _y[_y > -255.0]\n",
    "                if _y.shape[0] == 0:\n",
    "                    continue\n",
    "                _x = np.repeat(TermMapToMonth[column], _y.shape[0])\n",
    "                if x is None:\n",
    "                    x, y = (_x, _y)\n",
    "                    continue\n",
    "                x = np.concatenate([x, _x])\n",
    "                y = np.concatenate([y,_y])\n",
    "            self.__train_step(x,y)\n",
    "            resdict['Date'] += [mdate] * len(self.thauv)\n",
    "            for val in self.nsld.values():\n",
    "                resdict['Alpha0'].append(val.alpha0.numpy())\n",
    "                resdict['Alpha1'].append(val.alpha1.numpy())\n",
    "                resdict['Alpha2'].append(val.alpha2.numpy())\n",
    "                resdict['Thau'].append(val.thau.numpy())\n",
    "        self.resdf = pd.DataFrame(resdict)\n",
    "        self.resdf['Date'] = self.resdf['Date'].str.decode('utf-8')\n",
    "        return self.resdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = NelsonSiegelParameters(thauv = [64, 128])\n",
    "ddf = tt.find_parameters('./EU_France_9480.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Alpha0</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Thau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986-01-08</td>\n",
       "      <td>8.154904</td>\n",
       "      <td>7.465635</td>\n",
       "      <td>7.247425</td>\n",
       "      <td>59.262356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986-01-08</td>\n",
       "      <td>7.703991</td>\n",
       "      <td>8.221745</td>\n",
       "      <td>7.484064</td>\n",
       "      <td>119.891510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1986-01-09</td>\n",
       "      <td>8.159197</td>\n",
       "      <td>7.469697</td>\n",
       "      <td>7.251604</td>\n",
       "      <td>59.262669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986-01-09</td>\n",
       "      <td>7.708381</td>\n",
       "      <td>8.225805</td>\n",
       "      <td>7.488358</td>\n",
       "      <td>119.876961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Alpha0    Alpha1    Alpha2        Thau\n",
       "0  1986-01-08  8.154904  7.465635  7.247425   59.262356\n",
       "1  1986-01-08  7.703991  8.221745  7.484064  119.891510\n",
       "2  1986-01-09  8.159197  7.469697  7.251604   59.262669\n",
       "3  1986-01-09  7.708381  8.225805  7.488358  119.876961"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1986-01-08\n",
       "1   1986-01-08\n",
       "2   1986-01-09\n",
       "3   1986-01-09\n",
       "Name: Date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(ddf['Date'].str.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Alpha0</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Alpha0, Alpha1, Alpha2]\n",
       "Index: []"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(columns = ['Date', 'Alpha0', 'Alpha1', 'Alpha2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = {'a':5, 'b':8}\n",
    "list(dd.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>M01</th>\n",
       "      <th>M03</th>\n",
       "      <th>M06</th>\n",
       "      <th>M09</th>\n",
       "      <th>Y01</th>\n",
       "      <th>Y02</th>\n",
       "      <th>Y03</th>\n",
       "      <th>Y04</th>\n",
       "      <th>Y05</th>\n",
       "      <th>Y06</th>\n",
       "      <th>Y07</th>\n",
       "      <th>Y08</th>\n",
       "      <th>Y09</th>\n",
       "      <th>Y10</th>\n",
       "      <th>Y15</th>\n",
       "      <th>Y20</th>\n",
       "      <th>Y25</th>\n",
       "      <th>Y30</th>\n",
       "      <th>Y50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986-01-03</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>9.993</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986-01-06</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>9.997</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "      <td>-256.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    M01    M03    M06    M09    Y01    Y02    Y03    Y04    Y05  \\\n",
       "0  1986-01-03 -256.0 -256.0 -256.0 -256.0 -256.0 -256.0 -256.0 -256.0 -256.0   \n",
       "1  1986-01-06 -256.0 -256.0 -256.0 -256.0 -256.0 -256.0 -256.0 -256.0 -256.0   \n",
       "\n",
       "     Y06    Y07    Y08    Y09    Y10    Y15    Y20    Y25    Y30    Y50  \n",
       "0 -256.0 -256.0 -256.0 -256.0  9.993 -256.0 -256.0 -256.0 -256.0 -256.0  \n",
       "1 -256.0 -256.0 -256.0 -256.0  9.997 -256.0 -256.0 -256.0 -256.0 -256.0  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./EU_France_9480.csv', nrows = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'1986-01-22'\n",
      "[120. 120. 120. 120. 120. 120. 120. 120. 120. 120. 120. 120. 120. 120.\n",
      " 120. 120. 120. 120. 120. 120. 120. 120. 120. 120. 120. 120. 120.]\n",
      "[ 9.993  9.997 10.002 10.006 10.018 10.023 10.027 10.031 10.035 10.048\n",
      " 10.052 10.056 10.061 10.065 10.078 10.082 10.086 10.091 10.095 10.103\n",
      " 10.103 10.093 10.093 10.136 10.165 10.144 10.073]\n"
     ]
    }
   ],
   "source": [
    "TermMapToMonth = { 'M01' : 1.0, 'M02' : 2.0, 'M03' : 3.0, 'M04' : 4.0, 'M05' : 5.0, 'M06' : 6.0, 'M07' : 7.0, 'M08' : 8.0,\n",
    "                    'M09' : 9.0, 'M10' : 10.0, 'M11' : 11.0, \n",
    "                    'Y01' : 12.0, 'Y02' : 24.0, 'Y03' : 36.0, 'Y04' : 48.0, 'Y05' : 60.0, 'Y06' : 72.0, 'Y07' : 84.0,\n",
    "                    'Y08' : 96.0, 'Y09' : 108.0, 'Y10' : 120.0, 'Y12' : 144.0, 'Y15' : 180.0, 'Y20' : 240.0,\n",
    "                    'Y25' : 300.0, 'Y30' : 360.0, 'Y40' : 480.0, 'Y50' : 600.0}\n",
    "\n",
    "RecordDefaults = [tf.string] + [tf.float32] * 19\n",
    "dataset = tf.data.experimental.CsvDataset('./EU_France_9480.csv', RecordDefaults,header = True).window(27,1,1,True).take(1)\n",
    "df = pd.read_csv('./EU_France_9480.csv', nrows = 0)\n",
    "cv = list(df.columns)\n",
    "for window in dataset:\n",
    "    mdate, x, y = None, None, None\n",
    "    for column, component in zip(cv, window):\n",
    "        if column == 'Date':\n",
    "            mdate = list(component.as_numpy_iterator())\n",
    "            mdate = mdate[len(mdate) // 2]\n",
    "            continue\n",
    "        _y = np.array(list(component.as_numpy_iterator()))\n",
    "        _y = _y[_y > -255.0]\n",
    "        if _y.shape[0] > 0:\n",
    "            _x = np.repeat(TermMapToMonth[column], _y.shape[0])\n",
    "            if x is None:\n",
    "                x, y = _x, _y\n",
    "                continue\n",
    "            x = np.concatenate([x, _x])\n",
    "            y = np.concatenate([y,_y])\n",
    "    print(mdate)\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window in dataset:\n",
    "    def to_numpy(ds):\n",
    "        return list(ds.as_numpy_iterator())\n",
    "    print(tuple(to_numpy(component) for component in window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.experimental.make_csv_dataset('./EU_France_9480.csv',batch_size = 360, shuffle = False)\n",
    "rr = None\n",
    "for it in dataset.map(lambda x: fetchyc.mapelement(x)):\n",
    "    d = it['Date'].numpy()\n",
    "    if d > b'2010-01-01':\n",
    "        rr = it\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Fetch and combine all available data into single data frame table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSL = NelsonSiegelLayer(thau0 = 64)\n",
    "inputs = tf.keras.Input(shape = ())\n",
    "outputs = NSL(inputs)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=Adam(lr=0.1), loss=\"mse\")\n",
    "hist = model.fit(rr['XY'][1], rr['XY'][0], epochs = 256, verbose = 0)\n",
    "print(model.evaluate(rr['XY'][1], rr['XY'][0], verbose = 0))\n",
    "print(NSL.thau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(np.array([360.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the Keras session and save the model\n",
    "# The signature definition is defined by the input and output tensors,\n",
    "# and stored with the default serving key\n",
    "import tempfile\n",
    "\n",
    "MODEL_DIR = \"./models\"\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")\n",
    "\n",
    "print('\\nSaved model:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = tf.keras.models.load_model(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.predict(np.array([360.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir {export_path} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -p 8511:8511 \\\n",
    "  --mount type=bind,source=\"C:\\\\Users\\\\PLDD\\\\Practice\\\\GitHub\\\\Python\\\\MHS\\\\models\",target=\"\\\\models\\\\my_model\" \\\n",
    "  -e MODEL_NAME=my_model -t tensorflow/serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"C:\\\\Users\\\\PLDD\\\\Practice\\\\GitHub\\\\Python\\\\MHS\\\\models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_seq = np.arange(600)\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": time_seq.tolist()})\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post('http://localhost:8501/v1/models/my_model:predict', data=data, headers=headers)\n",
    "y = json.loads(json_response.text)['predictions']\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(7).window(3, 1, 1, True)\n",
    "for window in dataset.take(2):\n",
    "    print(list(window.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.epoch, np.log(hist.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_seq = np.arange(600)\n",
    "x = time_seq[:600]\n",
    "y = model.predict(x)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr['XY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning_epoch_cnt = 256\n",
    "def model_builder(hp): \n",
    "    \n",
    "    inputs = tf.keras.Input(shape = ())\n",
    "    hp_thau = hp.Float('thau0',min_value = 1.0, max_value = 120.0, default=64.0,\n",
    "                    step=10.0)\n",
    "    outputs = NelsonSiegelLayer(thau0 = hp_thau)(inputs)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = 'loss', \n",
    "                     max_epochs = tunning_epoch_cnt,\n",
    "                     factor = 2,\n",
    "                     directory = 'keras_tuning', # throw exception when either capital letters or numbers are in name of directory\n",
    "                     project_name = 'some') # throw exception when either capital letters or numbers are in name of directory\n",
    "\n",
    "tuner.search(rr['XY'][1], rr['XY'][0], epochs = tunning_epoch_cnt, verbose = 0)\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thauV = np.arange(1.0, 120.0, 10.)\n",
    "realV = []\n",
    "lossV = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thau in thauV:\n",
    "    NSL = NelsonSiegelLayer(thau0 = thau)\n",
    "    inputs = tf.keras.Input(shape = ())\n",
    "    outputs = NSL(inputs)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    model.fit(rr['XY'][1], rr['XY'][0], epochs = 1024, verbose = 0)\n",
    "    lossV.append(model.evaluate(rr['XY'][1], rr['XY'][0], verbose = 0))\n",
    "    realV.append(NSL.thau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcdir = r'.\\data\\raw\\YC'\n",
    "destdir = './'\n",
    "fetchyc.FirstConversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapelement(table):\n",
    "    valpairs = None\n",
    "    for key, x in TermMapToMonth.items():\n",
    "        if key in not table:\n",
    "            continue\n",
    "        xy = table[key][table[key] > 256.0]\n",
    "        if table[key].dtype == tf.string:\n",
    "            print(table[key])\n",
    "            #xy = tf.strings.to_number(table[key][table[key] != b''], out_type=tf.dtypes.float32)\n",
    "            xy = tf.strings.to_number(table[key], out_type=tf.dtypes.float32)\n",
    "            print(xy)\n",
    "            print(table[key])\n",
    "        if xy.shape[0] is not None:\n",
    "            xy = tf.stack([xy, tf.repeat(x,xy.shape[0])])\n",
    "            if valpairs is None:\n",
    "                valpairs = xy\n",
    "            else:\n",
    "                valpairs = tf.concat([valpairs,xy], axis = 1)       \n",
    "    m = table['Date'].shape[0] // 2\n",
    "    return {'Date' : table['Date'][m], 'XY' : valpairs}\n",
    "\n",
    "@tf.function\n",
    "def mapelement1(table):\n",
    "    obss = tf.convert_to_tensor(np.array([[-256.0], [-256.0]]), dtype = tf.float32)\n",
    "    tt = 'M01'\n",
    "    x = TermMapToMonth[tt]\n",
    "    xy = tf.convert_to_tensor(table[tt])\n",
    "    print(xy)\n",
    "    lx = xy > -255.0\n",
    "    xy = tf.boolean_mask(xy, lx)\n",
    "    #print(xy)\n",
    "    #print(xy.numpy())\n",
    "    xy = tf.stack([xy, tf.repeat(x,xy.shape[0])])\n",
    "    obss = tf.concat([obss,xy], axis = 1) \n",
    "    print(obss)\n",
    "    lx = obss[0] > -255.0\n",
    "    print(lx)\n",
    "    obss = tf.boolean_mask(obss, lx, axis = 1)\n",
    "    median = table['Date'].shape[0] // 2\n",
    "    return {'Date' : table['Date'][median], 'XY' : xy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(6.5, 20.0, 5)\n",
    "#t = [6.8]\n",
    "b0 = 5\n",
    "b1 = -1\n",
    "b2 = 3\n",
    "b0, b1, b2 = (0.0466, -0.0429, 0.0712)\n",
    "for x in np.linspace(0.0, 100.0, 10):\n",
    "    b0 = np.linspace(0.0, 100.0, 1000)\n",
    "    m = 6.5\n",
    "    y = np.exp(b0) + ((b1 + b2) * (1.0 - np.exp(-x/m))/(x/m)) - b2 * np.exp(-x/m)\n",
    "    plt.plot(b0, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "b0 = np.linspace(-100, 100.0, 100)\n",
    "b2 = 3.14\n",
    "for b1 in np.linspace(0.0, 17.5, 10):\n",
    "    y = (np.exp(b0) + np.exp(b1 - b0) - b2)**2\n",
    "    plt.plot(b0, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
