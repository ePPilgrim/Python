{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import os as os\n",
    "import fetchyc\n",
    "import collections\n",
    "import kerastuner as kt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import ns\n",
    "\n",
    "#!pip install -q requests\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fetch and expand to new terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ns.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "TermMapToMonth = { 'M01' : 1.0, 'M02' : 2.0, 'M03' : 3.0, 'M04' : 4.0, 'M05' : 5.0, 'M06' : 6.0, 'M07' : 7.0, 'M08' : 8.0,\n",
    "                    'M09' : 9.0, 'M10' : 10.0, 'M11' : 11.0, \n",
    "                    'Y01' : 12.0, 'Y02' : 24.0, 'Y03' : 36.0, 'Y04' : 48.0, 'Y05' : 60.0, 'Y06' : 72.0, 'Y07' : 84.0,\n",
    "                    'Y08' : 96.0, 'Y09' : 108.0, 'Y10' : 120.0, 'Y12' : 144.0, 'Y15' : 180.0, 'Y20' : 240.0,\n",
    "                    'Y25' : 300.0, 'Y30' : 360.0, 'Y40' : 480.0, 'Y50' : 600.0}\n",
    "\n",
    "class NelsonSiegelLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, thau0 = 64.0, eps = 0.00001):\n",
    "        super(NelsonSiegelLayer, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.thau = self.add_weight(name = \"Thau\", shape = (), \n",
    "                                     initializer = tf.keras.initializers.Constant(thau0),\n",
    "                                     #constraint = tf.keras.constraints.NonNeg(),\n",
    "                                     trainable = True)\n",
    "        self.alpha0 = self.add_weight(name = \"Alpha0\", shape = (), \n",
    "                                     initializer = tf.keras.initializers.RandomUniform(0.0, 1.0),\n",
    "                                     constraint = tf.keras.constraints.NonNeg(),\n",
    "                                     trainable = True)\n",
    "        self.alpha1 = self.add_weight(name = \"Alpha1\", shape = (), \n",
    "                                     initializer = tf.keras.initializers.RandomUniform(0.0, 1.0),\n",
    "                                     constraint = tf.keras.constraints.NonNeg(),\n",
    "                                     trainable = True)\n",
    "        self.alpha2 = self.add_weight(name = \"Alpha2\", shape = (), \n",
    "                                     initializer = \"random_normal\",                           \n",
    "                                     trainable = True)\n",
    "        #self.bias = self.add_weight(name = \"Bias\", shape = (), trainable = True)\n",
    "        \n",
    "    def reassignValues(self, thau0 = 64.0):\n",
    "        self.thau.assign(thau0)\n",
    "        self.alpha0.assign(tf.random.uniform(shape=(), minval = 0.0, maxval = 1.0))\n",
    "        self.alpha1.assign(tf.random.uniform(shape=(), minval = 0.0, maxval = 1.0))\n",
    "        self.alpha2.assign(tf.random.normal(shape=()))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        val1 = tf.divide(inputs, self.thau)\n",
    "        val2 = tf.math.exp(-val1)\n",
    "        val3 = tf.divide(1.0 - val2, val1)\n",
    "        eps = self.eps\n",
    "        return tf.add(tf.math.multiply(self.alpha0 + eps, 1.0 - val3), \n",
    "                                       tf.add(tf.math.multiply(self.alpha1 + eps, val3),\n",
    "                                        tf.math.multiply(self.alpha2, val3 - val2)))\n",
    "\n",
    "class NelsonSiegelParameters:\n",
    "    def __init__(self, ww = 13, thauv = [32, 64, 128], lr = 0.1, epochs = 200):\n",
    "        self.ww = ww\n",
    "        self.thauv = thauv\n",
    "        self.nsld = {thau : NelsonSiegelLayer(thau0 = thau) for thau in self.thauv}\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.modelv = [self.__create_model(nsl) for nsl in self.nsld.values()]\n",
    "        self.histv = None\n",
    "        self.resdf = pd.DataFrame(columns = ['Date', 'Alpha0', 'Alpha1', 'Alpha2', 'Thau'])\n",
    "                                  \n",
    "    def __create_model(self,nsl):\n",
    "        inputs = tf.keras.Input(shape = ())\n",
    "        outputs = nsl(inputs)\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(lr=self.lr), loss=\"mse\")\n",
    "        return model        \n",
    "    \n",
    "    def __train_step(self, x, y):\n",
    "        for thau,nsl in self.nsld.items():\n",
    "            nsl.reassignValues(thau)\n",
    "        self.histv = [model.fit(x, y, epochs = self.epochs, verbose = 0) for model in self.modelv]\n",
    "        \n",
    "    def find_parameters(self, filename):\n",
    "        cv = list(pd.read_csv(filename, nrows = 0).columns)\n",
    "        rec = [tf.float32] * len(cv)\n",
    "        rec[cv.index('Date')] = tf.string\n",
    "        dataset = tf.data.experimental.CsvDataset(filename, rec, header = True).window(self.ww,1,1,True)\n",
    "        resdict = {key : [] for key in self.resdf.columns}\n",
    "        i = 0\n",
    "        for window in dataset:\n",
    "            mdate, x, y = None, None, None\n",
    "            for column, component in zip(cv, window):\n",
    "                if column == 'Date':\n",
    "                    mdate = list(component.as_numpy_iterator())\n",
    "                    mdate = mdate[len(mdate) // 2]\n",
    "                    continue\n",
    "                _y = np.array(list(component.as_numpy_iterator()))\n",
    "                _y = _y[_y > -255.0]\n",
    "                if _y.shape[0] == 0:\n",
    "                    continue\n",
    "                _x = np.repeat(TermMapToMonth[column], _y.shape[0])\n",
    "                if x is None:\n",
    "                    x, y = (_x, _y)\n",
    "                    continue\n",
    "                x = np.concatenate([x, _x])\n",
    "                y = np.concatenate([y,_y])\n",
    "            self.__train_step(x,y)\n",
    "            resdict['Date'] += [mdate] * len(self.thauv)\n",
    "            print(\"Window - {}\".format(i))\n",
    "            i += 1\n",
    "            for val in self.nsld.values():\n",
    "                resdict['Alpha0'].append(val.alpha0.numpy())\n",
    "                resdict['Alpha1'].append(val.alpha1.numpy())\n",
    "                resdict['Alpha2'].append(val.alpha2.numpy())\n",
    "                resdict['Thau'].append(val.thau.numpy())\n",
    "        self.resdf = pd.DataFrame(resdict)\n",
    "        self.resdf['Date'] = pd.to_datetime(self.resdf['Date'].str.decode('utf-8'))\n",
    "        return self.resdf\n",
    "    \n",
    "def SaveNSParameters(dirpath, ww = 13, epochs = 200):\n",
    "    for filename in os.listdir(dirpath):\n",
    "        filepath = os.path.join(dirpath,filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            engine = NelsonSiegelParameters(ww = ww, epochs = epochs)\n",
    "            df_ext = engine.find_parameters(filepath)\n",
    "            df_orig = pd.read_csv(filepath, converters = {'Date' : lambda x: pd.to_datetime(x)})\n",
    "            df = df_orig.merge(df_ext,on = 'Date', sort = True, how = 'outer')\n",
    "            file_name, file_extension = os.path.splitext(filepath)\n",
    "            newfilepath = file_name + '_ns' + file_extension\n",
    "            df.to_csv(newfilepath)\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.experimental.make_csv_dataset('./EU_France_9480.csv',batch_size = 360, shuffle = False)\n",
    "rr = None\n",
    "for it in dataset.map(lambda x: fetchyc.mapelement(x)):\n",
    "    d = it['Date'].numpy()\n",
    "    if d > b'2010-01-01':\n",
    "        rr = it\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Fetch and combine all available data into single data frame table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSL = NelsonSiegelLayer(thau0 = 64)\n",
    "inputs = tf.keras.Input(shape = ())\n",
    "outputs = NSL(inputs)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=Adam(lr=0.1), loss=\"mse\")\n",
    "hist = model.fit(rr['XY'][1], rr['XY'][0], epochs = 256, verbose = 0)\n",
    "print(model.evaluate(rr['XY'][1], rr['XY'][0], verbose = 0))\n",
    "print(NSL.thau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(np.array([360.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the Keras session and save the model\n",
    "# The signature definition is defined by the input and output tensors,\n",
    "# and stored with the default serving key\n",
    "import tempfile\n",
    "\n",
    "MODEL_DIR = \"./models\"\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")\n",
    "\n",
    "print('\\nSaved model:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = tf.keras.models.load_model(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.predict(np.array([360.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir {export_path} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -p 8511:8511 \\\n",
    "  --mount type=bind,source=\"C:\\\\Users\\\\PLDD\\\\Practice\\\\GitHub\\\\Python\\\\MHS\\\\models\",target=\"\\\\models\\\\my_model\" \\\n",
    "  -e MODEL_NAME=my_model -t tensorflow/serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"C:\\\\Users\\\\PLDD\\\\Practice\\\\GitHub\\\\Python\\\\MHS\\\\models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_seq = np.arange(600)\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": time_seq.tolist()})\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post('http://localhost:8501/v1/models/my_model:predict', data=data, headers=headers)\n",
    "y = json.loads(json_response.text)['predictions']\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.epoch, np.log(hist.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_seq = np.arange(600)\n",
    "x = time_seq[:600]\n",
    "y = model.predict(x)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr['XY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning_epoch_cnt = 256\n",
    "def model_builder(hp): \n",
    "    \n",
    "    inputs = tf.keras.Input(shape = ())\n",
    "    hp_thau = hp.Float('thau0',min_value = 1.0, max_value = 120.0, default=64.0,\n",
    "                    step=10.0)\n",
    "    outputs = NelsonSiegelLayer(thau0 = hp_thau)(inputs)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = 'loss', \n",
    "                     max_epochs = tunning_epoch_cnt,\n",
    "                     factor = 2,\n",
    "                     directory = 'keras_tuning', # throw exception when either capital letters or numbers are in name of directory\n",
    "                     project_name = 'some') # throw exception when either capital letters or numbers are in name of directory\n",
    "\n",
    "tuner.search(rr['XY'][1], rr['XY'][0], epochs = tunning_epoch_cnt, verbose = 0)\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thauV = np.arange(1.0, 120.0, 10.)\n",
    "realV = []\n",
    "lossV = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thau in thauV:\n",
    "    NSL = NelsonSiegelLayer(thau0 = thau)\n",
    "    inputs = tf.keras.Input(shape = ())\n",
    "    outputs = NSL(inputs)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    model.fit(rr['XY'][1], rr['XY'][0], epochs = 1024, verbose = 0)\n",
    "    lossV.append(model.evaluate(rr['XY'][1], rr['XY'][0], verbose = 0))\n",
    "    realV.append(NSL.thau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcdir = r'.\\data\\raw\\YC'\n",
    "destdir = './'\n",
    "fetchyc.FirstConversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapelement(table):\n",
    "    valpairs = None\n",
    "    for key, x in TermMapToMonth.items():\n",
    "        if key in not table:\n",
    "            continue\n",
    "        xy = table[key][table[key] > 256.0]\n",
    "        if table[key].dtype == tf.string:\n",
    "            print(table[key])\n",
    "            #xy = tf.strings.to_number(table[key][table[key] != b''], out_type=tf.dtypes.float32)\n",
    "            xy = tf.strings.to_number(table[key], out_type=tf.dtypes.float32)\n",
    "            print(xy)\n",
    "            print(table[key])\n",
    "        if xy.shape[0] is not None:\n",
    "            xy = tf.stack([xy, tf.repeat(x,xy.shape[0])])\n",
    "            if valpairs is None:\n",
    "                valpairs = xy\n",
    "            else:\n",
    "                valpairs = tf.concat([valpairs,xy], axis = 1)       \n",
    "    m = table['Date'].shape[0] // 2\n",
    "    return {'Date' : table['Date'][m], 'XY' : valpairs}\n",
    "\n",
    "@tf.function\n",
    "def mapelement1(table):\n",
    "    obss = tf.convert_to_tensor(np.array([[-256.0], [-256.0]]), dtype = tf.float32)\n",
    "    tt = 'M01'\n",
    "    x = TermMapToMonth[tt]\n",
    "    xy = tf.convert_to_tensor(table[tt])\n",
    "    print(xy)\n",
    "    lx = xy > -255.0\n",
    "    xy = tf.boolean_mask(xy, lx)\n",
    "    #print(xy)\n",
    "    #print(xy.numpy())\n",
    "    xy = tf.stack([xy, tf.repeat(x,xy.shape[0])])\n",
    "    obss = tf.concat([obss,xy], axis = 1) \n",
    "    print(obss)\n",
    "    lx = obss[0] > -255.0\n",
    "    print(lx)\n",
    "    obss = tf.boolean_mask(obss, lx, axis = 1)\n",
    "    median = table['Date'].shape[0] // 2\n",
    "    return {'Date' : table['Date'][median], 'XY' : xy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(6.5, 20.0, 5)\n",
    "#t = [6.8]\n",
    "b0 = 5\n",
    "b1 = -1\n",
    "b2 = 3\n",
    "b0, b1, b2 = (0.0466, -0.0429, 0.0712)\n",
    "for x in np.linspace(0.0, 100.0, 10):\n",
    "    b0 = np.linspace(0.0, 100.0, 1000)\n",
    "    m = 6.5\n",
    "    y = np.exp(b0) + ((b1 + b2) * (1.0 - np.exp(-x/m))/(x/m)) - b2 * np.exp(-x/m)\n",
    "    plt.plot(b0, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "b0 = np.linspace(-100, 100.0, 100)\n",
    "b2 = 3.14\n",
    "for b1 in np.linspace(0.0, 17.5, 10):\n",
    "    y = (np.exp(b0) + np.exp(b1 - b0) - b2)**2\n",
    "    plt.plot(b0, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
