{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\PLDD\\Anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\PLDD\\Anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\PLDD\\Anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\PLDD\\Anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\PLDD\\Anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\PLDD\\Anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\PLDD\\Anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\PLDD\\Anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "C:\\Users\\PLDD\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "%%writefile ns.py\n",
    "start = time.time()\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "'''\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import os as os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import sklearn as sk \n",
    "import time\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing.data import QuantileTransformer\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "mhsdir = Path(os.getcwd()).parent\n",
    "sys.path.append(os.path.join(mhsdir, 'src'))\n",
    "\n",
    "import ns\n",
    "\n",
    "datarawdir = os.path.join(mhsdir, 'data\\\\raw\\\\YC')\n",
    "dataprepdir = os.path.join(mhsdir, 'data\\\\preprocessed')\n",
    "dataprepnsdir = os.path.join(mhsdir, 'data\\\\preprocessed\\\\ns')\n",
    "modeldir = os.path.join(mhsdir, 'models')\n",
    "\n",
    "repodir = repodir = os.path.join(mhsdir, 'data\\\\train\\\\repository')\n",
    "traindir = os.path.join(repodir, 'train')\n",
    "testdir = os.path.join(repodir, 'test')\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 260491\n",
      "train - 260490\n",
      "train - 963\n",
      "train - 259527\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(repodir,\"train3.txt\")\n",
    "train_df = pd.read_csv(path, sep = ';', header = None)\n",
    "\n",
    "print(\"train - {}\".format(train_df.shape[0]))\n",
    "train_df = train_df.drop_duplicates(subset = [0,1])\n",
    "\n",
    "print(\"train - {}\".format(train_df.shape[0]))\n",
    "\n",
    "lx = (train_df.iloc[:,-13:-1] < -0.00001).any(axis = 1)\n",
    "train_df = train_df[~lx]\n",
    "print(\"train - {}\".format(lx.sum()))\n",
    "\n",
    "print(\"train - {}\".format(train_df.shape[0]))\n",
    "\n",
    "for i in range(100):\n",
    "    train_df = train_df.sample(frac = 1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df\n",
    "df1 = (np.abs(df.iloc[:,2:23]) > 0.000000001).astype('float')\n",
    "df2 = (np.abs(df.iloc[:,-12:]) > 0.000000001).astype('float')\n",
    "df3 = df.iloc[:,2:23]\n",
    "df4 = df.iloc[:,23:44]\n",
    "df5 = df.iloc[:,44:65]\n",
    "df6 = df.iloc[:,65:]\n",
    "x = pd.concat([df3, df5, df1, df2], axis = 1).to_numpy()\n",
    "y = df6.sum(axis = 1).to_numpy()\n",
    "\n",
    "lx = (y >= 0.001) & (y <=100.0)\n",
    "\n",
    "x = x[lx]\n",
    "y = y[lx]\n",
    "\n",
    "i0 = 200000\n",
    "train_x = x[:i0,:]\n",
    "train_y = y[:i0]\n",
    "test_x = x[i0:,:]\n",
    "test_y = y[i0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(repodir,\"train3.txt\")\n",
    "train_df = pd.read_csv(path, sep = ';', header = None)\n",
    "\n",
    "print(\"train - {}\".format(train_df.shape[0]))\n",
    "train_df = train_df.drop_duplicates(subset = [0,1])\n",
    "\n",
    "print(\"train - {}\".format(train_df.shape[0]))\n",
    "\n",
    "lx = (train_df.iloc[:,-13:-1] < -0.00001).any(axis = 1)\n",
    "train_df = train_df[~lx]\n",
    "print(\"train - {}\".format(lx.sum()))\n",
    "\n",
    "print(\"train - {}\".format(train_df.shape[0]))\n",
    "\n",
    "df = train_df\n",
    "df1 = (np.abs(df.iloc[:,2:23]) > 0.000000001).astype('float')\n",
    "df2 = (np.abs(df.iloc[:,-12:]) > 0.000000001).astype('float')\n",
    "df3 = df.iloc[:,2:23]\n",
    "df4 = df.iloc[:,23:44]\n",
    "df5 = df.iloc[:,44:65]\n",
    "df6 = df.iloc[:,65:]\n",
    "x = pd.concat([df3, df5, df1, df2], axis = 1).to_numpy()\n",
    "y = df6.sum(axis = 1).to_numpy()\n",
    "\n",
    "lx = (y >= 0.001) & (y <=100.0)\n",
    "\n",
    "x = x[lx]\n",
    "y = y[lx]\n",
    "\n",
    "i0 = 200000\n",
    "train_x = x[:i0,:]\n",
    "train_y = y[:i0]\n",
    "test_x = x[i0:,:]\n",
    "test_y = y[i0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12413"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lx = np.abs(df.iloc[:,2:23]) > 0.000000001\n",
    "lx = lx.sum(axis = 1) == 6\n",
    "lx.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12 * 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.distplot(train_y,label = 'Train CashFlow')\n",
    "sn.distplot(test_y, label = 'Test CashFlow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259527, 75)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_69 (Dense)             (None, 128)               9728      \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 125,441\n",
      "Trainable params: 125,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnt = 1024\n",
    "model = tf.keras.Sequential([\n",
    "                    tf.keras.layers.Dense(128, activation='relu',input_shape = [train_x.shape[1]]),\n",
    "                    tf.keras.layers.Dense(128, activation='relu'),\n",
    "                    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l1(0.0001)),\n",
    "                    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l1(0.0001)), \n",
    "                    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l1(0.0001)), \n",
    "                    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l1(0.0001)), \n",
    "                    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l1(0.0001)), \n",
    "                    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l1(0.0001)), \n",
    "                    tf.keras.layers.Dense(1)       \n",
    "])\n",
    "model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.Adagrad(0.001),\n",
    "              metrics = ['mae','mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "3125/3125 [==============================] - 12s 4ms/step - loss: 15.0568 - mae: 2.3017 - mse: 14.3073 - val_loss: 10.6191 - val_mae: 1.9252 - val_mse: 9.8712\n",
      "Epoch 2/128\n",
      "3125/3125 [==============================] - 12s 4ms/step - loss: 9.7202 - mae: 1.8335 - mse: 8.9740 - val_loss: 9.2230 - val_mae: 1.7484 - val_mse: 8.4784\n",
      "Epoch 3/128\n",
      "3125/3125 [==============================] - 14s 5ms/step - loss: 8.7070 - mae: 1.6980 - mse: 7.9640 - val_loss: 8.5482 - val_mae: 1.6574 - val_mse: 7.8068\n",
      "Epoch 4/128\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 8.1710 - mae: 1.6226 - mse: 7.4313 - val_loss: 8.1793 - val_mae: 1.6006 - val_mse: 7.4412\n",
      "Epoch 5/128\n",
      "3125/3125 [==============================] - 12s 4ms/step - loss: 7.8267 - mae: 1.5740 - mse: 7.0901 - val_loss: 7.9309 - val_mae: 1.5683 - val_mse: 7.1959\n",
      "Epoch 6/128\n",
      "3125/3125 [==============================] - 12s 4ms/step - loss: 7.5785 - mae: 1.5401 - mse: 6.8451 - val_loss: 7.7653 - val_mae: 1.5419 - val_mse: 7.0335\n",
      "Epoch 7/128\n",
      "3125/3125 [==============================] - 12s 4ms/step - loss: 7.3873 - mae: 1.5135 - mse: 6.6570 - val_loss: 7.6148 - val_mae: 1.5178 - val_mse: 6.8861\n",
      "Epoch 8/128\n",
      "3125/3125 [==============================] - 12s 4ms/step - loss: 7.2366 - mae: 1.4932 - mse: 6.5093 - val_loss: 7.4562 - val_mae: 1.4956 - val_mse: 6.7305\n",
      "Epoch 9/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 7.1081 - mae: 1.4756 - mse: 6.3838 - val_loss: 7.3998 - val_mae: 1.4965 - val_mse: 6.6769\n",
      "Epoch 10/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 7.0063 - mae: 1.4618 - mse: 6.2850 - val_loss: 7.2552 - val_mae: 1.4651 - val_mse: 6.5353\n",
      "Epoch 11/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 6.9094 - mae: 1.4485 - mse: 6.1909 - val_loss: 7.2191 - val_mae: 1.4554 - val_mse: 6.5020\n",
      "Epoch 12/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 6.8297 - mae: 1.4373 - mse: 6.1141 - val_loss: 7.1406 - val_mae: 1.4505 - val_mse: 6.4264\n",
      "Epoch 13/128\n",
      "3125/3125 [==============================] - 11s 4ms/step - loss: 6.7541 - mae: 1.4275 - mse: 6.0413 - val_loss: 7.0898 - val_mae: 1.4363 - val_mse: 6.3783\n",
      "Epoch 14/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 6.6927 - mae: 1.4191 - mse: 5.9827 - val_loss: 7.0248 - val_mae: 1.4291 - val_mse: 6.3161\n",
      "Epoch 15/128\n",
      "3125/3125 [==============================] - 10s 3ms/step - loss: 6.6359 - mae: 1.4117 - mse: 5.9286 - val_loss: 6.9842 - val_mae: 1.4255 - val_mse: 6.2783\n",
      "Epoch 16/128\n",
      "3125/3125 [==============================] - 12s 4ms/step - loss: 6.5825 - mae: 1.4043 - mse: 5.8779 - val_loss: 6.9618 - val_mae: 1.4213 - val_mse: 6.2586\n",
      "Epoch 17/128\n",
      "3125/3125 [==============================] - 12s 4ms/step - loss: 6.5326 - mae: 1.3976 - mse: 5.8307 - val_loss: 6.9174 - val_mae: 1.4124 - val_mse: 6.2169\n",
      "Epoch 18/128\n",
      "3125/3125 [==============================] - 12s 4ms/step - loss: 6.4863 - mae: 1.3909 - mse: 5.7870 - val_loss: 6.8834 - val_mae: 1.4054 - val_mse: 6.1855\n",
      "Epoch 19/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 6.4459 - mae: 1.3856 - mse: 5.7493 - val_loss: 6.8574 - val_mae: 1.4009 - val_mse: 6.1621\n",
      "Epoch 20/128\n",
      "3125/3125 [==============================] - 10s 3ms/step - loss: 6.4057 - mae: 1.3806 - mse: 5.7117 - val_loss: 6.8392 - val_mae: 1.4030 - val_mse: 6.1465\n",
      "Epoch 21/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 6.3726 - mae: 1.3754 - mse: 5.6812 - val_loss: 6.7887 - val_mae: 1.3900 - val_mse: 6.0986\n",
      "Epoch 22/128\n",
      "3125/3125 [==============================] - 12s 4ms/step - loss: 6.3351 - mae: 1.3708 - mse: 5.6463 - val_loss: 6.7899 - val_mae: 1.3899 - val_mse: 6.1023\n",
      "Epoch 23/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 6.3041 - mae: 1.3668 - mse: 5.6177 - val_loss: 6.7285 - val_mae: 1.3825 - val_mse: 6.0434\n",
      "Epoch 24/128\n",
      "3125/3125 [==============================] - 11s 4ms/step - loss: 6.2740 - mae: 1.3626 - mse: 5.5902 - val_loss: 6.7154 - val_mae: 1.3794 - val_mse: 6.0328\n",
      "Epoch 25/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 6.2449 - mae: 1.3585 - mse: 5.5635 - val_loss: 6.7181 - val_mae: 1.3782 - val_mse: 6.0379\n",
      "Epoch 26/128\n",
      "3125/3125 [==============================] - 10s 3ms/step - loss: 6.2160 - mae: 1.3543 - mse: 5.5371 - val_loss: 6.7427 - val_mae: 1.3792 - val_mse: 6.0650\n",
      "Epoch 27/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 6.1909 - mae: 1.3514 - mse: 5.5144 - val_loss: 6.6831 - val_mae: 1.3746 - val_mse: 6.0077\n",
      "Epoch 28/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 6.1666 - mae: 1.3481 - mse: 5.4924 - val_loss: 6.6521 - val_mae: 1.3682 - val_mse: 5.9792\n",
      "Epoch 29/128\n",
      "3125/3125 [==============================] - 12s 4ms/step - loss: 6.1389 - mae: 1.3447 - mse: 5.4672 - val_loss: 6.6508 - val_mae: 1.3694 - val_mse: 5.9803\n",
      "Epoch 30/128\n",
      "3125/3125 [==============================] - 11s 4ms/step - loss: 6.1157 - mae: 1.3414 - mse: 5.4463 - val_loss: 6.6119 - val_mae: 1.3620 - val_mse: 5.9437\n",
      "Epoch 31/128\n",
      "3125/3125 [==============================] - 10s 3ms/step - loss: 6.0912 - mae: 1.3382 - mse: 5.4241 - val_loss: 6.5984 - val_mae: 1.3618 - val_mse: 5.9324\n",
      "Epoch 32/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 6.0722 - mae: 1.3358 - mse: 5.4074 - val_loss: 6.5899 - val_mae: 1.3592 - val_mse: 5.9263\n",
      "Epoch 33/128\n",
      "3125/3125 [==============================] - 10s 3ms/step - loss: 6.0490 - mae: 1.3326 - mse: 5.3864 - val_loss: 6.5778 - val_mae: 1.3562 - val_mse: 5.9164\n",
      "Epoch 34/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 6.0283 - mae: 1.3303 - mse: 5.3680 - val_loss: 6.5524 - val_mae: 1.3535 - val_mse: 5.8932\n",
      "Epoch 35/128\n",
      "3125/3125 [==============================] - 12s 4ms/step - loss: 6.0087 - mae: 1.3275 - mse: 5.3506 - val_loss: 6.5466 - val_mae: 1.3516 - val_mse: 5.8896\n",
      "Epoch 36/128\n",
      "3125/3125 [==============================] - 11s 4ms/step - loss: 5.9897 - mae: 1.3252 - mse: 5.3338 - val_loss: 6.5306 - val_mae: 1.3488 - val_mse: 5.8757\n",
      "Epoch 37/128\n",
      "3125/3125 [==============================] - 10s 3ms/step - loss: 5.9702 - mae: 1.3225 - mse: 5.3164 - val_loss: 6.5157 - val_mae: 1.3473 - val_mse: 5.8630\n",
      "Epoch 38/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 5.9507 - mae: 1.3200 - mse: 5.2991 - val_loss: 6.5089 - val_mae: 1.3464 - val_mse: 5.8584\n",
      "Epoch 39/128\n",
      "3125/3125 [==============================] - 10s 3ms/step - loss: 5.9312 - mae: 1.3182 - mse: 5.2817 - val_loss: 6.5155 - val_mae: 1.3460 - val_mse: 5.8672\n",
      "Epoch 40/128\n",
      "3125/3125 [==============================] - 11s 4ms/step - loss: 5.9169 - mae: 1.3157 - mse: 5.2696 - val_loss: 6.4847 - val_mae: 1.3413 - val_mse: 5.8384\n",
      "Epoch 41/128\n",
      "3125/3125 [==============================] - 11s 4ms/step - loss: 5.8997 - mae: 1.3137 - mse: 5.2544 - val_loss: 6.4536 - val_mae: 1.3388 - val_mse: 5.8093\n",
      "Epoch 42/128\n",
      "3125/3125 [==============================] - 11s 4ms/step - loss: 5.8853 - mae: 1.3116 - mse: 5.2421 - val_loss: 6.4578 - val_mae: 1.3404 - val_mse: 5.8156\n",
      "Epoch 43/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 5.8661 - mae: 1.3098 - mse: 5.2250 - val_loss: 6.4552 - val_mae: 1.3366 - val_mse: 5.8151\n",
      "Epoch 44/128\n",
      "3125/3125 [==============================] - 11s 4ms/step - loss: 5.8548 - mae: 1.3077 - mse: 5.2157 - val_loss: 6.4374 - val_mae: 1.3378 - val_mse: 5.7992\n",
      "Epoch 45/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 5.8381 - mae: 1.3057 - mse: 5.2009 - val_loss: 6.4535 - val_mae: 1.3380 - val_mse: 5.8173\n",
      "Epoch 46/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 5.8215 - mae: 1.3042 - mse: 5.1863 - val_loss: 6.4248 - val_mae: 1.3319 - val_mse: 5.7906\n",
      "Epoch 47/128\n",
      "3125/3125 [==============================] - 11s 3ms/step - loss: 5.8070 - mae: 1.3027 - mse: 5.1737 - val_loss: 6.4325 - val_mae: 1.3328 - val_mse: 5.8002\n",
      "Epoch 48/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.7971 - mae: 1.3006 - mse: 5.1658 - val_loss: 6.3986 - val_mae: 1.3289 - val_mse: 5.7682\n",
      "Epoch 49/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.7824 - mae: 1.2990 - mse: 5.1530 - val_loss: 6.4129 - val_mae: 1.3322 - val_mse: 5.7844\n",
      "Epoch 50/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.7702 - mae: 1.2975 - mse: 5.1427 - val_loss: 6.3950 - val_mae: 1.3270 - val_mse: 5.7684\n",
      "Epoch 51/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.7536 - mae: 1.2959 - mse: 5.1280 - val_loss: 6.3965 - val_mae: 1.3272 - val_mse: 5.7718\n",
      "Epoch 52/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.7446 - mae: 1.2944 - mse: 5.1208 - val_loss: 6.3772 - val_mae: 1.3266 - val_mse: 5.7543\n",
      "Epoch 53/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.7325 - mae: 1.2933 - mse: 5.1104 - val_loss: 6.3713 - val_mae: 1.3241 - val_mse: 5.7502\n",
      "Epoch 54/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.7228 - mae: 1.2914 - mse: 5.1026 - val_loss: 6.3483 - val_mae: 1.3220 - val_mse: 5.7290\n",
      "Epoch 55/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.7066 - mae: 1.2903 - mse: 5.0882 - val_loss: 6.3525 - val_mae: 1.3224 - val_mse: 5.7349\n",
      "Epoch 56/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.6967 - mae: 1.2888 - mse: 5.0801 - val_loss: 6.3431 - val_mae: 1.3209 - val_mse: 5.7273\n",
      "Epoch 57/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.6846 - mae: 1.2877 - mse: 5.0697 - val_loss: 6.3530 - val_mae: 1.3216 - val_mse: 5.7390\n",
      "Epoch 58/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.6728 - mae: 1.2861 - mse: 5.0596 - val_loss: 6.3188 - val_mae: 1.3174 - val_mse: 5.7064\n",
      "Epoch 59/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.6621 - mae: 1.2850 - mse: 5.0506 - val_loss: 6.3216 - val_mae: 1.3178 - val_mse: 5.7110\n",
      "Epoch 60/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.6505 - mae: 1.2837 - mse: 5.0407 - val_loss: 6.3194 - val_mae: 1.3186 - val_mse: 5.7104\n",
      "Epoch 61/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.6385 - mae: 1.2827 - mse: 5.0303 - val_loss: 6.3010 - val_mae: 1.3159 - val_mse: 5.6937\n",
      "Epoch 62/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.6312 - mae: 1.2813 - mse: 5.0247 - val_loss: 6.2958 - val_mae: 1.3141 - val_mse: 5.6902\n",
      "Epoch 63/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.6197 - mae: 1.2803 - mse: 5.0148 - val_loss: 6.2993 - val_mae: 1.3136 - val_mse: 5.6952\n",
      "Epoch 64/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.6078 - mae: 1.2788 - mse: 5.0045 - val_loss: 6.3051 - val_mae: 1.3146 - val_mse: 5.7026\n",
      "Epoch 65/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.5982 - mae: 1.2779 - mse: 4.9966 - val_loss: 6.2760 - val_mae: 1.3112 - val_mse: 5.6751\n",
      "Epoch 66/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.5900 - mae: 1.2769 - mse: 4.9899 - val_loss: 6.2746 - val_mae: 1.3124 - val_mse: 5.6753\n",
      "Epoch 67/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.5789 - mae: 1.2755 - mse: 4.9804 - val_loss: 6.2886 - val_mae: 1.3121 - val_mse: 5.6908\n",
      "Epoch 68/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.5725 - mae: 1.2747 - mse: 4.9755 - val_loss: 6.2607 - val_mae: 1.3095 - val_mse: 5.6645\n",
      "Epoch 69/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.5633 - mae: 1.2738 - mse: 4.9678 - val_loss: 6.2576 - val_mae: 1.3084 - val_mse: 5.6628\n",
      "Epoch 70/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.5518 - mae: 1.2725 - mse: 4.9578 - val_loss: 6.2531 - val_mae: 1.3085 - val_mse: 5.6598\n",
      "Epoch 71/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.5463 - mae: 1.2716 - mse: 4.9537 - val_loss: 6.2493 - val_mae: 1.3082 - val_mse: 5.6575\n",
      "Epoch 72/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.5356 - mae: 1.2706 - mse: 4.9446 - val_loss: 6.2457 - val_mae: 1.3066 - val_mse: 5.6553\n",
      "Epoch 73/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.5268 - mae: 1.2695 - mse: 4.9371 - val_loss: 6.2324 - val_mae: 1.3053 - val_mse: 5.6435\n",
      "Epoch 74/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.5196 - mae: 1.2686 - mse: 4.9314 - val_loss: 6.2386 - val_mae: 1.3056 - val_mse: 5.6510\n",
      "Epoch 75/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.5092 - mae: 1.2677 - mse: 4.9223 - val_loss: 6.2256 - val_mae: 1.3046 - val_mse: 5.6394\n",
      "Epoch 76/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.5019 - mae: 1.2666 - mse: 4.9164 - val_loss: 6.2272 - val_mae: 1.3066 - val_mse: 5.6424\n",
      "Epoch 77/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.4948 - mae: 1.2662 - mse: 4.9107 - val_loss: 6.2265 - val_mae: 1.3061 - val_mse: 5.6430\n",
      "Epoch 78/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.4876 - mae: 1.2649 - mse: 4.9048 - val_loss: 6.2201 - val_mae: 1.3046 - val_mse: 5.6380\n",
      "Epoch 79/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.4766 - mae: 1.2641 - mse: 4.8951 - val_loss: 6.2040 - val_mae: 1.3017 - val_mse: 5.6231\n",
      "Epoch 80/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.4698 - mae: 1.2634 - mse: 4.8896 - val_loss: 6.2002 - val_mae: 1.3021 - val_mse: 5.6206\n",
      "Epoch 81/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.4591 - mae: 1.2623 - mse: 4.8802 - val_loss: 6.1965 - val_mae: 1.3005 - val_mse: 5.6183\n",
      "Epoch 82/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.4546 - mae: 1.2614 - mse: 4.8770 - val_loss: 6.2023 - val_mae: 1.3005 - val_mse: 5.6253\n",
      "Epoch 83/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.4476 - mae: 1.2611 - mse: 4.8712 - val_loss: 6.1821 - val_mae: 1.2984 - val_mse: 5.6063\n",
      "Epoch 84/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.4396 - mae: 1.2596 - mse: 4.8644 - val_loss: 6.1886 - val_mae: 1.2985 - val_mse: 5.6141\n",
      "Epoch 85/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.4328 - mae: 1.2588 - mse: 4.8588 - val_loss: 6.1866 - val_mae: 1.3000 - val_mse: 5.6132\n",
      "Epoch 86/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.4252 - mae: 1.2582 - mse: 4.8524 - val_loss: 6.1701 - val_mae: 1.2976 - val_mse: 5.5980\n",
      "Epoch 87/128\n",
      "3125/3125 [==============================] - 13s 4ms/step - loss: 5.4188 - mae: 1.2575 - mse: 4.8472 - val_loss: 6.1878 - val_mae: 1.2983 - val_mse: 5.6168\n",
      "Epoch 88/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.4094 - mae: 1.2571 - mse: 4.8390 - val_loss: 6.1684 - val_mae: 1.2972 - val_mse: 5.5985\n",
      "Epoch 89/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.4046 - mae: 1.2561 - mse: 4.8353 - val_loss: 6.1695 - val_mae: 1.2990 - val_mse: 5.6008\n",
      "Epoch 90/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.3966 - mae: 1.2553 - mse: 4.8285 - val_loss: 6.1824 - val_mae: 1.2965 - val_mse: 5.6148\n",
      "Epoch 91/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.3910 - mae: 1.2547 - mse: 4.8239 - val_loss: 6.1564 - val_mae: 1.2959 - val_mse: 5.5899\n",
      "Epoch 92/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.3826 - mae: 1.2538 - mse: 4.8167 - val_loss: 6.1646 - val_mae: 1.2971 - val_mse: 5.5992\n",
      "Epoch 93/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.3770 - mae: 1.2529 - mse: 4.8121 - val_loss: 6.1616 - val_mae: 1.2950 - val_mse: 5.5973\n",
      "Epoch 94/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.3704 - mae: 1.2522 - mse: 4.8066 - val_loss: 6.1492 - val_mae: 1.2949 - val_mse: 5.5859\n",
      "Epoch 95/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.3642 - mae: 1.2515 - mse: 4.8014 - val_loss: 6.1339 - val_mae: 1.2927 - val_mse: 5.5716\n",
      "Epoch 96/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.3550 - mae: 1.2511 - mse: 4.7932 - val_loss: 6.1541 - val_mae: 1.2941 - val_mse: 5.5928\n",
      "Epoch 97/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.3505 - mae: 1.2501 - mse: 4.7898 - val_loss: 6.1395 - val_mae: 1.2925 - val_mse: 5.5792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.3462 - mae: 1.2496 - mse: 4.7864 - val_loss: 6.1277 - val_mae: 1.2928 - val_mse: 5.5684\n",
      "Epoch 99/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.3383 - mae: 1.2490 - mse: 4.7795 - val_loss: 6.1356 - val_mae: 1.2919 - val_mse: 5.5772\n",
      "Epoch 100/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.3326 - mae: 1.2485 - mse: 4.7748 - val_loss: 6.1360 - val_mae: 1.2913 - val_mse: 5.5786\n",
      "Epoch 101/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.3275 - mae: 1.2478 - mse: 4.7706 - val_loss: 6.1247 - val_mae: 1.2905 - val_mse: 5.5682\n",
      "Epoch 102/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.3196 - mae: 1.2468 - mse: 4.7635 - val_loss: 6.1376 - val_mae: 1.2930 - val_mse: 5.5820\n",
      "Epoch 103/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.3153 - mae: 1.2466 - mse: 4.7602 - val_loss: 6.1185 - val_mae: 1.2893 - val_mse: 5.5638\n",
      "Epoch 104/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.3073 - mae: 1.2454 - mse: 4.7530 - val_loss: 6.1322 - val_mae: 1.2914 - val_mse: 5.5784\n",
      "Epoch 105/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.3019 - mae: 1.2448 - mse: 4.7485 - val_loss: 6.1337 - val_mae: 1.2917 - val_mse: 5.5807\n",
      "Epoch 106/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2986 - mae: 1.2445 - mse: 4.7461 - val_loss: 6.1120 - val_mae: 1.2885 - val_mse: 5.5599\n",
      "Epoch 107/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2897 - mae: 1.2435 - mse: 4.7380 - val_loss: 6.1355 - val_mae: 1.2914 - val_mse: 5.5842\n",
      "Epoch 108/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2848 - mae: 1.2432 - mse: 4.7338 - val_loss: 6.1117 - val_mae: 1.2896 - val_mse: 5.5612\n",
      "Epoch 109/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2810 - mae: 1.2424 - mse: 4.7309 - val_loss: 6.1208 - val_mae: 1.2897 - val_mse: 5.5711\n",
      "Epoch 110/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2754 - mae: 1.2419 - mse: 4.7261 - val_loss: 6.1125 - val_mae: 1.2893 - val_mse: 5.5636\n",
      "Epoch 111/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2689 - mae: 1.2412 - mse: 4.7204 - val_loss: 6.1008 - val_mae: 1.2886 - val_mse: 5.5526\n",
      "Epoch 112/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2636 - mae: 1.2407 - mse: 4.7158 - val_loss: 6.1123 - val_mae: 1.2880 - val_mse: 5.5648\n",
      "Epoch 113/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2574 - mae: 1.2402 - mse: 4.7103 - val_loss: 6.0864 - val_mae: 1.2861 - val_mse: 5.5397\n",
      "Epoch 114/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2541 - mae: 1.2395 - mse: 4.7078 - val_loss: 6.1005 - val_mae: 1.2879 - val_mse: 5.5545\n",
      "Epoch 115/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2466 - mae: 1.2391 - mse: 4.7010 - val_loss: 6.1144 - val_mae: 1.2892 - val_mse: 5.5690\n",
      "Epoch 116/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2439 - mae: 1.2385 - mse: 4.6989 - val_loss: 6.1039 - val_mae: 1.2884 - val_mse: 5.5592\n",
      "Epoch 117/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2367 - mae: 1.2378 - mse: 4.6923 - val_loss: 6.0870 - val_mae: 1.2857 - val_mse: 5.5430\n",
      "Epoch 118/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2334 - mae: 1.2372 - mse: 4.6898 - val_loss: 6.0954 - val_mae: 1.2855 - val_mse: 5.5520\n",
      "Epoch 119/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2263 - mae: 1.2369 - mse: 4.6832 - val_loss: 6.1171 - val_mae: 1.2872 - val_mse: 5.5743\n",
      "Epoch 120/128\n",
      "3125/3125 [==============================] - 10s 3ms/step - loss: 5.2254 - mae: 1.2363 - mse: 4.6829 - val_loss: 6.0795 - val_mae: 1.2848 - val_mse: 5.5374\n",
      "Epoch 121/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2153 - mae: 1.2360 - mse: 4.6734 - val_loss: 6.0824 - val_mae: 1.2844 - val_mse: 5.5409\n",
      "Epoch 122/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2154 - mae: 1.2355 - mse: 4.6741 - val_loss: 6.0770 - val_mae: 1.2845 - val_mse: 5.5360\n",
      "Epoch 123/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2103 - mae: 1.2345 - mse: 4.6696 - val_loss: 6.0744 - val_mae: 1.2831 - val_mse: 5.5340\n",
      "Epoch 124/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.2052 - mae: 1.2344 - mse: 4.6651 - val_loss: 6.0759 - val_mae: 1.2833 - val_mse: 5.5361\n",
      "Epoch 125/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.1991 - mae: 1.2337 - mse: 4.6595 - val_loss: 6.0724 - val_mae: 1.2828 - val_mse: 5.5330\n",
      "Epoch 126/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.1947 - mae: 1.2335 - mse: 4.6556 - val_loss: 6.0628 - val_mae: 1.2818 - val_mse: 5.5240\n",
      "Epoch 127/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.1907 - mae: 1.2329 - mse: 4.6522 - val_loss: 6.0690 - val_mae: 1.2838 - val_mse: 5.5308\n",
      "Epoch 128/128\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 5.1859 - mae: 1.2325 - mse: 4.6479 - val_loss: 6.0686 - val_mae: 1.2825 - val_mse: 5.5308\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 128\n",
    "history = model.fit(\n",
    "  train_x, train_y,\n",
    "  batch_size = 64,\n",
    "  epochs=EPOCHS, validation_data=(test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 75)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 512)               38912     \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 827,393\n",
      "Trainable params: 827,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                    tf.keras.layers.Dense(512, activation='relu',input_shape = [75]),\n",
    "                    tf.keras.layers.Dense(512, activation='relu'),\n",
    "                    tf.keras.layers.Dense(512, activation='relu'),\n",
    "                    tf.keras.layers.Dense(512, activation='relu'), \n",
    "                    #tf.keras.layers.Dense(128, activation='relu'), \n",
    "                    #tf.keras.layers.Dense(128, activation='relu'), \n",
    "                    #tf.keras.layers.Dense(128, activation='relu'), \n",
    "                    #tf.keras.layers.Dense(128, activation='relu'), \n",
    "                    #tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=tf.keras.regularizers.l1(l=0.00001)),                 \n",
    "                    #tf.keras.layers.Dense(64, activation='relu',kernel_regularizer=tf.keras.regularizers.l1(l=0.0001)),\n",
    "                    tf.keras.layers.Dense(1)       \n",
    "])\n",
    "model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.Adagrad(0.0001),\n",
    "              metrics = ['mae','mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "3125/3125 [==============================] - 52s 17ms/step - loss: 25.6938 - mae: 3.3531 - mse: 25.6938 - val_loss: 52.5683 - val_mae: 4.0931 - val_mse: 52.5683\n",
      "Epoch 2/64\n",
      "3125/3125 [==============================] - 52s 17ms/step - loss: 12.3463 - mae: 2.1986 - mse: 12.3463 - val_loss: 34.2950 - val_mae: 3.2073 - val_mse: 34.2950\n",
      "Epoch 3/64\n",
      "3125/3125 [==============================] - 52s 17ms/step - loss: 8.9259 - mae: 1.8968 - mse: 8.9259 - val_loss: 30.3813 - val_mae: 3.1231 - val_mse: 30.3813\n",
      "Epoch 4/64\n",
      "3125/3125 [==============================] - 53s 17ms/step - loss: 8.2646 - mae: 1.8494 - mse: 8.2646 - val_loss: 29.5386 - val_mae: 3.1317 - val_mse: 29.5386\n",
      "Epoch 5/64\n",
      "3125/3125 [==============================] - 53s 17ms/step - loss: 7.8789 - mae: 1.8086 - mse: 7.8789 - val_loss: 29.1431 - val_mae: 3.1300 - val_mse: 29.1431\n",
      "Epoch 6/64\n",
      "3125/3125 [==============================] - 52s 17ms/step - loss: 7.5755 - mae: 1.7723 - mse: 7.5755 - val_loss: 29.1287 - val_mae: 3.1634 - val_mse: 29.1287\n",
      "Epoch 7/64\n",
      "3125/3125 [==============================] - 46s 15ms/step - loss: 7.3159 - mae: 1.7374 - mse: 7.3159 - val_loss: 28.0158 - val_mae: 3.0898 - val_mse: 28.0158\n",
      "Epoch 8/64\n",
      "3125/3125 [==============================] - 46s 15ms/step - loss: 7.0871 - mae: 1.7084 - mse: 7.0871 - val_loss: 27.4958 - val_mae: 3.0607 - val_mse: 27.4958\n",
      "Epoch 9/64\n",
      "3125/3125 [==============================] - 47s 15ms/step - loss: 6.8807 - mae: 1.6795 - mse: 6.8807 - val_loss: 26.8611 - val_mae: 3.0255 - val_mse: 26.8611\n",
      "Epoch 10/64\n",
      "3125/3125 [==============================] - 47s 15ms/step - loss: 6.6904 - mae: 1.6532 - mse: 6.6904 - val_loss: 26.3348 - val_mae: 2.9952 - val_mse: 26.3348\n",
      "Epoch 11/64\n",
      "3125/3125 [==============================] - 46s 15ms/step - loss: 6.5146 - mae: 1.6280 - mse: 6.5146 - val_loss: 26.5159 - val_mae: 3.0358 - val_mse: 26.5159\n",
      "Epoch 12/64\n",
      "3125/3125 [==============================] - 47s 15ms/step - loss: 6.3506 - mae: 1.6043 - mse: 6.3506 - val_loss: 26.2225 - val_mae: 3.0264 - val_mse: 26.2225\n",
      "Epoch 13/64\n",
      "3125/3125 [==============================] - 47s 15ms/step - loss: 6.2001 - mae: 1.5803 - mse: 6.2001 - val_loss: 25.4959 - val_mae: 2.9775 - val_mse: 25.4959\n",
      "Epoch 14/64\n",
      "3125/3125 [==============================] - 46s 15ms/step - loss: 6.0576 - mae: 1.5597 - mse: 6.0576 - val_loss: 25.1930 - val_mae: 2.9636 - val_mse: 25.1930\n",
      "Epoch 15/64\n",
      "3125/3125 [==============================] - 46s 15ms/step - loss: 5.9269 - mae: 1.5395 - mse: 5.9269 - val_loss: 25.2103 - val_mae: 2.9835 - val_mse: 25.2103\n",
      "Epoch 16/64\n",
      "3125/3125 [==============================] - 49s 16ms/step - loss: 5.8051 - mae: 1.5202 - mse: 5.8051 - val_loss: 24.7604 - val_mae: 2.9543 - val_mse: 24.7604\n",
      "Epoch 17/64\n",
      "3125/3125 [==============================] - 55s 18ms/step - loss: 5.6906 - mae: 1.5016 - mse: 5.6906 - val_loss: 24.5646 - val_mae: 2.9503 - val_mse: 24.5646\n",
      "Epoch 18/64\n",
      "3125/3125 [==============================] - 51s 16ms/step - loss: 5.5844 - mae: 1.4854 - mse: 5.5844 - val_loss: 24.5785 - val_mae: 2.9636 - val_mse: 24.5785\n",
      "Epoch 19/64\n",
      "3125/3125 [==============================] - 52s 17ms/step - loss: 5.4822 - mae: 1.4674 - mse: 5.4822 - val_loss: 23.9914 - val_mae: 2.9232 - val_mse: 23.9914\n",
      "Epoch 20/64\n",
      "3125/3125 [==============================] - 52s 17ms/step - loss: 5.3854 - mae: 1.4520 - mse: 5.3854 - val_loss: 23.5126 - val_mae: 2.8894 - val_mse: 23.5126\n",
      "Epoch 21/64\n",
      "3125/3125 [==============================] - 51s 16ms/step - loss: 5.2984 - mae: 1.4374 - mse: 5.2984 - val_loss: 23.5864 - val_mae: 2.9097 - val_mse: 23.5864\n",
      "Epoch 22/64\n",
      "3125/3125 [==============================] - 51s 16ms/step - loss: 5.2152 - mae: 1.4236 - mse: 5.2152 - val_loss: 23.1749 - val_mae: 2.8776 - val_mse: 23.1749\n",
      "Epoch 23/64\n",
      "3125/3125 [==============================] - 51s 16ms/step - loss: 5.1391 - mae: 1.4104 - mse: 5.1391 - val_loss: 23.1185 - val_mae: 2.8742 - val_mse: 23.1185\n",
      "Epoch 24/64\n",
      "3125/3125 [==============================] - 52s 17ms/step - loss: 5.0668 - mae: 1.3975 - mse: 5.0668 - val_loss: 22.9071 - val_mae: 2.8727 - val_mse: 22.9071\n",
      "Epoch 25/64\n",
      "3125/3125 [==============================] - 50s 16ms/step - loss: 4.9996 - mae: 1.3853 - mse: 4.9996 - val_loss: 22.9228 - val_mae: 2.8945 - val_mse: 22.9228\n",
      "Epoch 26/64\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 4.9367 - mae: 1.3753 - mse: 4.9367"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-f29237b3738a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m   epochs=EPOCHS, validation_data=(test_x,test_y))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m               return_dict=True)\n\u001b[0m\u001b[0;32m   1134\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1377\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TraceContext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 64\n",
    "history = model.fit(\n",
    "  train_x, train_y,\n",
    "  batch_size = 64,\n",
    "  epochs=EPOCHS, validation_data=(test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  1.   ],\n",
       "       [ 0.   ,  0.   ,  8.399, ...,  0.   ,  0.   ,  1.   ],\n",
       "       [11.097, 11.18 ,  0.   , ...,  0.   ,  0.   ,  1.   ],\n",
       "       ...,\n",
       "       [ 3.739,  3.8  ,  3.913, ...,  1.   ,  1.   ,  1.   ],\n",
       "       [ 0.   ,  0.   ,  0.   , ...,  1.   ,  1.   ,  1.   ],\n",
       "       [ 1.238,  1.254,  1.289, ...,  0.   ,  0.   ,  1.   ]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.293377, 14.169633, 25.573283, ...,  2.181129,  2.908976,\n",
       "        2.224539])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_real_0_0_410_38_40938.txt\n",
      "train_real_1600_0_46363.txt\n",
      "train_real_1600_0_58256.txt\n",
      "train_real_1600_0_61440.txt\n",
      "train_real_1600_0_61657.txt\n",
      "train_real_1600_0_67635.txt\n",
      "train_real_410_0_9132.txt\n",
      "train - 345421, test1 - 102230, test2 - 77252\n",
      "train - 345420, test1 - 102230, test2 - 77252\n",
      "test1 - 1\n",
      "test2 - 0\n",
      "train - 21764\n",
      "train - 323656, test1 - 102229, test2 - 77252\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(repodir,\"train.txt\")\n",
    "df = pd.read_csv(path, sep = ';', header = None)\n",
    "\n",
    "for filename in os.listdir(traindir):\n",
    "    print(filename)\n",
    "    path=os.path.join(traindir, filename)\n",
    "    df1 = pd.read_csv(path, sep = ';', header = None)\n",
    "    if df is None:\n",
    "        df = df1\n",
    "        continue\n",
    "    df = pd.concat([df, df1])\n",
    "train_df = df.iloc[:,:-1]\n",
    "test1_df = pd.read_csv(os.path.join(testdir, \"train_real.txt\"), sep = ';', header = None).iloc[:,:-1]\n",
    "test21_df = pd.read_csv(os.path.join(testdir, \"test2_5084.txt\"), sep = ';', header = None).iloc[:,:-1]\n",
    "test22_df = pd.read_csv(os.path.join(testdir, \"test2_72168.txt\"), sep = ';', header = None).iloc[:,:-1]\n",
    "test2_df = pd.concat([test21_df, test22_df])\n",
    "\n",
    "print(\"train - {}, test1 - {}, test2 - {}\".format(train_df.shape[0], test1_df.shape[0], test2_df.shape[0]))\n",
    "train_df = train_df.drop_duplicates(subset = [0,1])\n",
    "test2_df = test2_df.drop_duplicates(subset = [0,1])\n",
    "\n",
    "print(\"train - {}, test1 - {}, test2 - {}\".format(train_df.shape[0], test1_df.shape[0], test2_df.shape[0]))\n",
    "lx = (test1_df.iloc[:,-14:-2] < -0.00001).any(axis = 1)\n",
    "test1_df = test1_df[~lx]\n",
    "print(\"test1 - {}\".format(lx.sum()))\n",
    "\n",
    "lx = (test2_df.iloc[:,-14:-2] < -0.00001).any(axis = 1)\n",
    "test2_df = test2_df[~lx]\n",
    "print(\"test2 - {}\".format(lx.sum()))\n",
    "\n",
    "lx = (train_df.iloc[:,-14:-2] < -0.00001).any(axis = 1)\n",
    "train_df = train_df[~lx]\n",
    "print(\"train - {}\".format(lx.sum()))\n",
    "\n",
    "print(\"train - {}, test1 - {}, test2 - {}\".format(train_df.shape[0], test1_df.shape[0], test2_df.shape[0]))\n",
    "\n",
    "for i in range(100):\n",
    "    train_df = train_df.sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "trainfilepath = os.path.join(repodir, 'train_{}'.format(train_df.shape[0]) )\n",
    "train_df.to_csv(trainfilepath,index = False)\n",
    "\n",
    "testfilepath1 = os.path.join(repodir, 'test_{}'.format(test1_df.shape[0]) )\n",
    "test1_df.to_csv(testfilepath1,index = False)\n",
    "\n",
    "testfilepath2 = os.path.join(repodir, 'test_{}'.format(test2_df.shape[0]) )\n",
    "test2_df.to_csv(testfilepath2,index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_category(freqv): \n",
    "    res = np.zeros((freqv.shape[0],12))\n",
    "    for i in range(freqv.shape[0]):\n",
    "        if freqv[i] == 1:\n",
    "            res[i] = np.array([1,1,1,1,1,1,1,1,1,1,1,1],dtype = 'float')\n",
    "        elif freqv[i] == 2:\n",
    "            res[i] = np.array([0,1,0,1,0,1,0,1,0,1,0,1],dtype = 'float') \n",
    "        elif freqv[i] == 3:\n",
    "            res[i] = np.array([0,0,1,0,0,1,0,0,1,0,0,1],dtype = 'float')\n",
    "        elif freqv[i] == 4:\n",
    "            res[i] = np.array([0,0,0,1,0,0,0,1,0,0,0,1],dtype = 'float')\n",
    "        elif freqv[i] == 6:\n",
    "            res[i] = np.array([0,0,0,0,0,1,0,0,0,0,0,1],dtype = 'float')\n",
    "        elif freqv[i] == 12:\n",
    "            res[i] = np.array([0,0,0,0,0,0,0,0,0,0,0,1],dtype = 'float')\n",
    "    return res\n",
    "\n",
    "def convertor(df):\n",
    "    df.columns = ['n','id','bmode','tb1','tb2','tb3','tb4','tb5','tb6','tb7','tb8','tb9','tb10','tb11','tb12','tb13','tb14','tb15','tb16','tb17','tb18','tb19','tb20','tb21',\n",
    "           'ts1','ts2','ts3','ts4','ts5','ts6','ts7','ts8','ts9','ts10','ts11','ts12','ts13','ts14','ts15','ts16','ts17','ts18','ts19','ts20','ts21',\n",
    "           't1','t2','t3','t4','t5','t6','t7','t8','t9','t10','t11','t12','t13','t14','t15','t16','t17','t18','t19','t20','t21',\n",
    "           'c1','c2','c3','c4','c5','c6','c7','c8','c9','c10','c11','c12','smode','freq']\n",
    "    act_columns = ['tb1','tb2','tb3','tb4','tb5','tb6','tb7','tb8','tb9','tb10','tb11','tb12','tb13','tb14','tb15','tb16','tb17','tb18','tb19','tb20','tb21',\n",
    "               'ts1','ts2','ts3','ts4','ts5','ts6','ts7','ts8','ts9','ts10','ts11','ts12','ts13','ts14','ts15','ts16','ts17','ts18','ts19','ts20','ts21',\n",
    "               'c1','c2','c3','c4','c5','c6','c7','c8','c9','c10','c11','c12']\n",
    "    coup_columns = ['c1','c2','c3','c4','c5','c6','c7','c8','c9','c10','c11','c12'] \n",
    "    target = df[coup_columns].sum(axis=1)\n",
    "    data = df[act_columns].copy()\n",
    "    data.loc[:,coup_columns] = to_category(df['freq'])\n",
    "    return data,target\n",
    "\n",
    "def VaR(ar):\n",
    "    sar = np.sort(ar)\n",
    "    sz = sar.shape[0]\n",
    "    rsk = np.rint(sz * (1 - np.array([0.99,0.98,0.97,0.96,0.95,0.94,0.93,0.92,0.91,0.9]))).astype('int')\n",
    "    return sar[rsk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(trainfilepath)\n",
    "test1_df = pd.read_csv(testfilepath1)\n",
    "test2_df = pd.read_csv(testfilepath2)\n",
    "train_data, train_target = convertor(train_df)\n",
    "test1_data, test1_target = convertor(test1_df)\n",
    "test2_data, test2_target = convertor(test2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b9081beec8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.distplot(test1_target,label = 'Test1 chashflow')\n",
    "sn.distplot(test2_target,label = 'Test2 chashflow')\n",
    "sn.distplot(train_target,label = 'Train chashflow')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               7040      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 122,753\n",
      "Trainable params: 122,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                    tf.keras.layers.Dense(128, activation='relu',input_shape = [len(train_data.keys())]),\n",
    "                    tf.keras.layers.Dense(128, activation='relu'),\n",
    "                    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l1(0.0001)),\n",
    "                    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l1(0.0001)), \n",
    "                    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l1(0.0001)), \n",
    "                    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l1(0.0001)), \n",
    "                    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l1(0.0001)), \n",
    "                    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l1(0.0001)), \n",
    "                    #tf.keras.layers.Dense(64, activation='relu'),\n",
    "                    #tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=tf.keras.regularizers.l1(l=0.00001)),                 \n",
    "                    #tf.keras.layers.Dense(64, activation='relu',kernel_regularizer=tf.keras.regularizers.l1(l=0.0001)),\n",
    "                    tf.keras.layers.Dense(1)       \n",
    "])\n",
    "model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.Adagrad(0.001),\n",
    "              metrics = ['mae','mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.9367 - mae: 0.2282 - mse: 0.1875 - val_loss: 0.7618 - val_mae: 0.1004 - val_mse: 0.0175\n",
      "Epoch 2/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.7802 - mae: 0.1288 - mse: 0.0406 - val_loss: 0.7509 - val_mae: 0.0954 - val_mse: 0.0159\n",
      "Epoch 3/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.7591 - mae: 0.1081 - mse: 0.0287 - val_loss: 0.7409 - val_mae: 0.0950 - val_mse: 0.0151\n",
      "Epoch 4/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.7443 - mae: 0.0960 - mse: 0.0230 - val_loss: 0.7309 - val_mae: 0.0911 - val_mse: 0.0141\n",
      "Epoch 5/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.7316 - mae: 0.0873 - mse: 0.0192 - val_loss: 0.7225 - val_mae: 0.0907 - val_mse: 0.0146\n",
      "Epoch 6/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.7203 - mae: 0.0809 - mse: 0.0167 - val_loss: 0.7130 - val_mae: 0.0896 - val_mse: 0.0138\n",
      "Epoch 7/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.7098 - mae: 0.0760 - mse: 0.0148 - val_loss: 0.7042 - val_mae: 0.0881 - val_mse: 0.0135\n",
      "Epoch 8/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.6998 - mae: 0.0720 - mse: 0.0134 - val_loss: 0.6960 - val_mae: 0.0890 - val_mse: 0.0139\n",
      "Epoch 9/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.6903 - mae: 0.0687 - mse: 0.0123 - val_loss: 0.6884 - val_mae: 0.0911 - val_mse: 0.0146\n",
      "Epoch 10/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.6811 - mae: 0.0660 - mse: 0.0114 - val_loss: 0.6822 - val_mae: 0.0933 - val_mse: 0.0165\n",
      "Epoch 11/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.6723 - mae: 0.0638 - mse: 0.0107 - val_loss: 0.6723 - val_mae: 0.0890 - val_mse: 0.0148\n",
      "Epoch 12/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.6636 - mae: 0.0618 - mse: 0.0101 - val_loss: 0.6665 - val_mae: 0.0929 - val_mse: 0.0170\n",
      "Epoch 13/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.6550 - mae: 0.0600 - mse: 0.0095 - val_loss: 0.6585 - val_mae: 0.0921 - val_mse: 0.0170\n",
      "Epoch 14/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.6467 - mae: 0.0585 - mse: 0.0090 - val_loss: 0.6483 - val_mae: 0.0875 - val_mse: 0.0145\n",
      "Epoch 15/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.6385 - mae: 0.0570 - mse: 0.0086 - val_loss: 0.6419 - val_mae: 0.0893 - val_mse: 0.0158\n",
      "Epoch 16/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.6305 - mae: 0.0557 - mse: 0.0083 - val_loss: 0.6352 - val_mae: 0.0902 - val_mse: 0.0168\n",
      "Epoch 17/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.6226 - mae: 0.0545 - mse: 0.0079 - val_loss: 0.6282 - val_mae: 0.0910 - val_mse: 0.0172\n",
      "Epoch 18/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.6149 - mae: 0.0536 - mse: 0.0077 - val_loss: 0.6208 - val_mae: 0.0910 - val_mse: 0.0172\n",
      "Epoch 19/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.6073 - mae: 0.0527 - mse: 0.0074 - val_loss: 0.6133 - val_mae: 0.0902 - val_mse: 0.0170\n",
      "Epoch 20/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.5998 - mae: 0.0518 - mse: 0.0072 - val_loss: 0.6075 - val_mae: 0.0926 - val_mse: 0.0184\n",
      "Epoch 21/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.5924 - mae: 0.0510 - mse: 0.0070 - val_loss: 0.6005 - val_mae: 0.0928 - val_mse: 0.0186\n",
      "Epoch 22/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.5852 - mae: 0.0502 - mse: 0.0068 - val_loss: 0.5917 - val_mae: 0.0886 - val_mse: 0.0168\n",
      "Epoch 23/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.5780 - mae: 0.0495 - mse: 0.0066 - val_loss: 0.5852 - val_mae: 0.0897 - val_mse: 0.0172\n",
      "Epoch 24/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.5709 - mae: 0.0489 - mse: 0.0064 - val_loss: 0.5792 - val_mae: 0.0911 - val_mse: 0.0182\n",
      "Epoch 25/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.5639 - mae: 0.0482 - mse: 0.0062 - val_loss: 0.5706 - val_mae: 0.0866 - val_mse: 0.0163\n",
      "Epoch 26/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.5571 - mae: 0.0476 - mse: 0.0061 - val_loss: 0.5634 - val_mae: 0.0855 - val_mse: 0.0157\n",
      "Epoch 27/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.5503 - mae: 0.0471 - mse: 0.0060 - val_loss: 0.5586 - val_mae: 0.0887 - val_mse: 0.0175\n",
      "Epoch 28/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.5436 - mae: 0.0465 - mse: 0.0058 - val_loss: 0.5525 - val_mae: 0.0893 - val_mse: 0.0179\n",
      "Epoch 29/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.5371 - mae: 0.0461 - mse: 0.0057 - val_loss: 0.5445 - val_mae: 0.0855 - val_mse: 0.0163\n",
      "Epoch 30/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.5306 - mae: 0.0456 - mse: 0.0056 - val_loss: 0.5388 - val_mae: 0.0867 - val_mse: 0.0169\n",
      "Epoch 31/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.5243 - mae: 0.0452 - mse: 0.0055 - val_loss: 0.5326 - val_mae: 0.0862 - val_mse: 0.0170\n",
      "Epoch 32/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.5180 - mae: 0.0447 - mse: 0.0054 - val_loss: 0.5264 - val_mae: 0.0861 - val_mse: 0.0169\n",
      "Epoch 33/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.5118 - mae: 0.0443 - mse: 0.0053 - val_loss: 0.5199 - val_mae: 0.0847 - val_mse: 0.0164\n",
      "Epoch 34/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.5057 - mae: 0.0439 - mse: 0.0052 - val_loss: 0.5142 - val_mae: 0.0849 - val_mse: 0.0167\n",
      "Epoch 35/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4996 - mae: 0.0435 - mse: 0.0051 - val_loss: 0.5054 - val_mae: 0.0804 - val_mse: 0.0138\n",
      "Epoch 36/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4937 - mae: 0.0432 - mse: 0.0050 - val_loss: 0.5019 - val_mae: 0.0835 - val_mse: 0.0161\n",
      "Epoch 37/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4879 - mae: 0.0428 - mse: 0.0050 - val_loss: 0.4962 - val_mae: 0.0835 - val_mse: 0.0161\n",
      "Epoch 38/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4822 - mae: 0.0425 - mse: 0.0049 - val_loss: 0.4904 - val_mae: 0.0827 - val_mse: 0.0159\n",
      "Epoch 39/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4765 - mae: 0.0421 - mse: 0.0048 - val_loss: 0.4847 - val_mae: 0.0824 - val_mse: 0.0157\n",
      "Epoch 40/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4710 - mae: 0.0419 - mse: 0.0048 - val_loss: 0.4797 - val_mae: 0.0829 - val_mse: 0.0162\n",
      "Epoch 41/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4655 - mae: 0.0416 - mse: 0.0047 - val_loss: 0.4738 - val_mae: 0.0818 - val_mse: 0.0157\n",
      "Epoch 42/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.4601 - mae: 0.0413 - mse: 0.0046 - val_loss: 0.4681 - val_mae: 0.0807 - val_mse: 0.0152\n",
      "Epoch 43/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4548 - mae: 0.0410 - mse: 0.0046 - val_loss: 0.4628 - val_mae: 0.0804 - val_mse: 0.0152\n",
      "Epoch 44/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4495 - mae: 0.0407 - mse: 0.0045 - val_loss: 0.4571 - val_mae: 0.0793 - val_mse: 0.0146\n",
      "Epoch 45/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4444 - mae: 0.0404 - mse: 0.0044 - val_loss: 0.4523 - val_mae: 0.0794 - val_mse: 0.0149\n",
      "Epoch 46/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4393 - mae: 0.0402 - mse: 0.0044 - val_loss: 0.4478 - val_mae: 0.0804 - val_mse: 0.0154\n",
      "Epoch 47/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.4343 - mae: 0.0399 - mse: 0.0043 - val_loss: 0.4419 - val_mae: 0.0780 - val_mse: 0.0143\n",
      "Epoch 48/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.4294 - mae: 0.0396 - mse: 0.0043 - val_loss: 0.4362 - val_mae: 0.0761 - val_mse: 0.0134\n",
      "Epoch 49/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4246 - mae: 0.0394 - mse: 0.0042 - val_loss: 0.4317 - val_mae: 0.0764 - val_mse: 0.0137\n",
      "Epoch 50/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4198 - mae: 0.0392 - mse: 0.0042 - val_loss: 0.4260 - val_mae: 0.0747 - val_mse: 0.0127\n",
      "Epoch 51/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4152 - mae: 0.0390 - mse: 0.0041 - val_loss: 0.4226 - val_mae: 0.0761 - val_mse: 0.0138\n",
      "Epoch 52/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4106 - mae: 0.0388 - mse: 0.0041 - val_loss: 0.4179 - val_mae: 0.0755 - val_mse: 0.0136\n",
      "Epoch 53/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4061 - mae: 0.0385 - mse: 0.0040 - val_loss: 0.4143 - val_mae: 0.0775 - val_mse: 0.0145\n",
      "Epoch 54/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.4016 - mae: 0.0384 - mse: 0.0040 - val_loss: 0.4101 - val_mae: 0.0774 - val_mse: 0.0146\n",
      "Epoch 55/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3973 - mae: 0.0381 - mse: 0.0040 - val_loss: 0.4058 - val_mae: 0.0774 - val_mse: 0.0146\n",
      "Epoch 56/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3930 - mae: 0.0379 - mse: 0.0039 - val_loss: 0.4013 - val_mae: 0.0764 - val_mse: 0.0142\n",
      "Epoch 57/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3889 - mae: 0.0378 - mse: 0.0039 - val_loss: 0.3969 - val_mae: 0.0757 - val_mse: 0.0139\n",
      "Epoch 58/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3848 - mae: 0.0376 - mse: 0.0038 - val_loss: 0.3920 - val_mae: 0.0740 - val_mse: 0.0131\n",
      "Epoch 59/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3807 - mae: 0.0374 - mse: 0.0038 - val_loss: 0.3898 - val_mae: 0.0778 - val_mse: 0.0149\n",
      "Epoch 60/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3768 - mae: 0.0372 - mse: 0.0038 - val_loss: 0.3844 - val_mae: 0.0741 - val_mse: 0.0133\n",
      "Epoch 61/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3729 - mae: 0.0370 - mse: 0.0037 - val_loss: 0.3804 - val_mae: 0.0736 - val_mse: 0.0132\n",
      "Epoch 62/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3691 - mae: 0.0368 - mse: 0.0037 - val_loss: 0.3774 - val_mae: 0.0753 - val_mse: 0.0138\n",
      "Epoch 63/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3654 - mae: 0.0367 - mse: 0.0036 - val_loss: 0.3739 - val_mae: 0.0754 - val_mse: 0.0140\n",
      "Epoch 64/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3618 - mae: 0.0365 - mse: 0.0036 - val_loss: 0.3694 - val_mae: 0.0735 - val_mse: 0.0131\n",
      "Epoch 65/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3582 - mae: 0.0364 - mse: 0.0036 - val_loss: 0.3663 - val_mae: 0.0743 - val_mse: 0.0134\n",
      "Epoch 66/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3547 - mae: 0.0362 - mse: 0.0036 - val_loss: 0.3627 - val_mae: 0.0739 - val_mse: 0.0132\n",
      "Epoch 67/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3513 - mae: 0.0361 - mse: 0.0035 - val_loss: 0.3589 - val_mae: 0.0727 - val_mse: 0.0127\n",
      "Epoch 68/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3480 - mae: 0.0359 - mse: 0.0035 - val_loss: 0.3557 - val_mae: 0.0727 - val_mse: 0.0128\n",
      "Epoch 69/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3448 - mae: 0.0358 - mse: 0.0035 - val_loss: 0.3529 - val_mae: 0.0738 - val_mse: 0.0132\n",
      "Epoch 70/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3416 - mae: 0.0356 - mse: 0.0034 - val_loss: 0.3498 - val_mae: 0.0734 - val_mse: 0.0131\n",
      "Epoch 71/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3386 - mae: 0.0355 - mse: 0.0034 - val_loss: 0.3469 - val_mae: 0.0738 - val_mse: 0.0132\n",
      "Epoch 72/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3356 - mae: 0.0353 - mse: 0.0034 - val_loss: 0.3437 - val_mae: 0.0733 - val_mse: 0.0130\n",
      "Epoch 73/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3327 - mae: 0.0352 - mse: 0.0034 - val_loss: 0.3409 - val_mae: 0.0732 - val_mse: 0.0130\n",
      "Epoch 74/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3298 - mae: 0.0351 - mse: 0.0033 - val_loss: 0.3375 - val_mae: 0.0718 - val_mse: 0.0124\n",
      "Epoch 75/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3270 - mae: 0.0349 - mse: 0.0033 - val_loss: 0.3351 - val_mae: 0.0724 - val_mse: 0.0127\n",
      "Epoch 76/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3243 - mae: 0.0348 - mse: 0.0033 - val_loss: 0.3321 - val_mae: 0.0719 - val_mse: 0.0124\n",
      "Epoch 77/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3217 - mae: 0.0347 - mse: 0.0033 - val_loss: 0.3294 - val_mae: 0.0711 - val_mse: 0.0123\n",
      "Epoch 78/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3192 - mae: 0.0346 - mse: 0.0033 - val_loss: 0.3271 - val_mae: 0.0718 - val_mse: 0.0124\n",
      "Epoch 79/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3167 - mae: 0.0344 - mse: 0.0032 - val_loss: 0.3249 - val_mae: 0.0722 - val_mse: 0.0126\n",
      "Epoch 80/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3143 - mae: 0.0343 - mse: 0.0032 - val_loss: 0.3223 - val_mae: 0.0715 - val_mse: 0.0124\n",
      "Epoch 81/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3120 - mae: 0.0342 - mse: 0.0032 - val_loss: 0.3201 - val_mae: 0.0715 - val_mse: 0.0124\n",
      "Epoch 82/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3097 - mae: 0.0341 - mse: 0.0032 - val_loss: 0.3164 - val_mae: 0.0682 - val_mse: 0.0110\n",
      "Epoch 83/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3075 - mae: 0.0340 - mse: 0.0032 - val_loss: 0.3154 - val_mae: 0.0710 - val_mse: 0.0121\n",
      "Epoch 84/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3054 - mae: 0.0338 - mse: 0.0031 - val_loss: 0.3122 - val_mae: 0.0681 - val_mse: 0.0109\n",
      "Epoch 85/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.3034 - mae: 0.0337 - mse: 0.0031 - val_loss: 0.3115 - val_mae: 0.0710 - val_mse: 0.0122\n",
      "Epoch 86/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.3014 - mae: 0.0336 - mse: 0.0031 - val_loss: 0.3090 - val_mae: 0.0695 - val_mse: 0.0116\n",
      "Epoch 87/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2995 - mae: 0.0335 - mse: 0.0031 - val_loss: 0.3076 - val_mae: 0.0707 - val_mse: 0.0121\n",
      "Epoch 88/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2977 - mae: 0.0334 - mse: 0.0031 - val_loss: 0.3052 - val_mae: 0.0690 - val_mse: 0.0114\n",
      "Epoch 89/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2960 - mae: 0.0333 - mse: 0.0030 - val_loss: 0.3035 - val_mae: 0.0694 - val_mse: 0.0115\n",
      "Epoch 90/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2943 - mae: 0.0332 - mse: 0.0030 - val_loss: 0.3026 - val_mae: 0.0708 - val_mse: 0.0121\n",
      "Epoch 91/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2927 - mae: 0.0331 - mse: 0.0030 - val_loss: 0.3005 - val_mae: 0.0696 - val_mse: 0.0116\n",
      "Epoch 92/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2912 - mae: 0.0331 - mse: 0.0030 - val_loss: 0.2990 - val_mae: 0.0692 - val_mse: 0.0115\n",
      "Epoch 93/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2897 - mae: 0.0330 - mse: 0.0030 - val_loss: 0.2976 - val_mae: 0.0695 - val_mse: 0.0116\n",
      "Epoch 94/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2883 - mae: 0.0329 - mse: 0.0030 - val_loss: 0.2961 - val_mae: 0.0692 - val_mse: 0.0114\n",
      "Epoch 95/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2870 - mae: 0.0328 - mse: 0.0030 - val_loss: 0.2950 - val_mae: 0.0696 - val_mse: 0.0116\n",
      "Epoch 96/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2858 - mae: 0.0327 - mse: 0.0029 - val_loss: 0.2941 - val_mae: 0.0705 - val_mse: 0.0119\n",
      "Epoch 97/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2846 - mae: 0.0326 - mse: 0.0029 - val_loss: 0.2928 - val_mae: 0.0698 - val_mse: 0.0117\n",
      "Epoch 98/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2835 - mae: 0.0325 - mse: 0.0029 - val_loss: 0.2918 - val_mae: 0.0699 - val_mse: 0.0117\n",
      "Epoch 99/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2824 - mae: 0.0325 - mse: 0.0029 - val_loss: 0.2907 - val_mae: 0.0699 - val_mse: 0.0117\n",
      "Epoch 100/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2814 - mae: 0.0324 - mse: 0.0029 - val_loss: 0.2890 - val_mae: 0.0681 - val_mse: 0.0110\n",
      "Epoch 101/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2804 - mae: 0.0323 - mse: 0.0029 - val_loss: 0.2888 - val_mae: 0.0705 - val_mse: 0.0118\n",
      "Epoch 102/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2793 - mae: 0.0322 - mse: 0.0029 - val_loss: 0.2871 - val_mae: 0.0684 - val_mse: 0.0111\n",
      "Epoch 103/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2783 - mae: 0.0321 - mse: 0.0028 - val_loss: 0.2866 - val_mae: 0.0698 - val_mse: 0.0116\n",
      "Epoch 104/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2774 - mae: 0.0321 - mse: 0.0028 - val_loss: 0.2849 - val_mae: 0.0680 - val_mse: 0.0109\n",
      "Epoch 105/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2764 - mae: 0.0320 - mse: 0.0028 - val_loss: 0.2840 - val_mae: 0.0678 - val_mse: 0.0109\n",
      "Epoch 106/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2755 - mae: 0.0319 - mse: 0.0028 - val_loss: 0.2835 - val_mae: 0.0694 - val_mse: 0.0114\n",
      "Epoch 107/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2745 - mae: 0.0318 - mse: 0.0028 - val_loss: 0.2824 - val_mae: 0.0689 - val_mse: 0.0112\n",
      "Epoch 108/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2736 - mae: 0.0317 - mse: 0.0028 - val_loss: 0.2819 - val_mae: 0.0699 - val_mse: 0.0115\n",
      "Epoch 109/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2727 - mae: 0.0317 - mse: 0.0028 - val_loss: 0.2789 - val_mae: 0.0642 - val_mse: 0.0094\n",
      "Epoch 110/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2718 - mae: 0.0316 - mse: 0.0028 - val_loss: 0.2802 - val_mae: 0.0706 - val_mse: 0.0117\n",
      "Epoch 111/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2709 - mae: 0.0315 - mse: 0.0027 - val_loss: 0.2775 - val_mae: 0.0654 - val_mse: 0.0098\n",
      "Epoch 112/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2700 - mae: 0.0315 - mse: 0.0027 - val_loss: 0.2773 - val_mae: 0.0671 - val_mse: 0.0105\n",
      "Epoch 113/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2691 - mae: 0.0314 - mse: 0.0027 - val_loss: 0.2764 - val_mae: 0.0669 - val_mse: 0.0104\n",
      "Epoch 114/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2683 - mae: 0.0313 - mse: 0.0027 - val_loss: 0.2756 - val_mae: 0.0671 - val_mse: 0.0104\n",
      "Epoch 115/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2674 - mae: 0.0313 - mse: 0.0027 - val_loss: 0.2746 - val_mae: 0.0667 - val_mse: 0.0103\n",
      "Epoch 116/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2666 - mae: 0.0312 - mse: 0.0027 - val_loss: 0.2744 - val_mae: 0.0683 - val_mse: 0.0109\n",
      "Epoch 117/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2657 - mae: 0.0311 - mse: 0.0027 - val_loss: 0.2731 - val_mae: 0.0671 - val_mse: 0.0104\n",
      "Epoch 118/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2649 - mae: 0.0311 - mse: 0.0027 - val_loss: 0.2724 - val_mae: 0.0675 - val_mse: 0.0106\n",
      "Epoch 119/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2641 - mae: 0.0310 - mse: 0.0027 - val_loss: 0.2714 - val_mae: 0.0668 - val_mse: 0.0103\n",
      "Epoch 120/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2633 - mae: 0.0310 - mse: 0.0027 - val_loss: 0.2709 - val_mae: 0.0678 - val_mse: 0.0106\n",
      "Epoch 121/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2625 - mae: 0.0309 - mse: 0.0026 - val_loss: 0.2695 - val_mae: 0.0662 - val_mse: 0.0100\n",
      "Epoch 122/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2617 - mae: 0.0308 - mse: 0.0026 - val_loss: 0.2687 - val_mae: 0.0661 - val_mse: 0.0100\n",
      "Epoch 123/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2610 - mae: 0.0307 - mse: 0.0026 - val_loss: 0.2679 - val_mae: 0.0659 - val_mse: 0.0099\n",
      "Epoch 124/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2602 - mae: 0.0307 - mse: 0.0026 - val_loss: 0.2676 - val_mae: 0.0670 - val_mse: 0.0104\n",
      "Epoch 125/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2594 - mae: 0.0307 - mse: 0.0026 - val_loss: 0.2669 - val_mae: 0.0673 - val_mse: 0.0104\n",
      "Epoch 126/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2587 - mae: 0.0306 - mse: 0.0026 - val_loss: 0.2659 - val_mae: 0.0666 - val_mse: 0.0102\n",
      "Epoch 127/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2579 - mae: 0.0305 - mse: 0.0026 - val_loss: 0.2656 - val_mae: 0.0681 - val_mse: 0.0106\n",
      "Epoch 128/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2572 - mae: 0.0305 - mse: 0.0026 - val_loss: 0.2647 - val_mae: 0.0675 - val_mse: 0.0104\n",
      "Epoch 129/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2565 - mae: 0.0304 - mse: 0.0026 - val_loss: 0.2639 - val_mae: 0.0672 - val_mse: 0.0103\n",
      "Epoch 130/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2557 - mae: 0.0303 - mse: 0.0026 - val_loss: 0.2635 - val_mae: 0.0684 - val_mse: 0.0107\n",
      "Epoch 131/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2550 - mae: 0.0303 - mse: 0.0026 - val_loss: 0.2621 - val_mae: 0.0663 - val_mse: 0.0100\n",
      "Epoch 132/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2543 - mae: 0.0302 - mse: 0.0025 - val_loss: 0.2620 - val_mae: 0.0677 - val_mse: 0.0106\n",
      "Epoch 133/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2536 - mae: 0.0302 - mse: 0.0025 - val_loss: 0.2606 - val_mae: 0.0657 - val_mse: 0.0099\n",
      "Epoch 134/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2529 - mae: 0.0301 - mse: 0.0025 - val_loss: 0.2605 - val_mae: 0.0675 - val_mse: 0.0105\n",
      "Epoch 135/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2522 - mae: 0.0301 - mse: 0.0025 - val_loss: 0.2595 - val_mae: 0.0665 - val_mse: 0.0101\n",
      "Epoch 136/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2515 - mae: 0.0300 - mse: 0.0025 - val_loss: 0.2569 - val_mae: 0.0611 - val_mse: 0.0083\n",
      "Epoch 137/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2508 - mae: 0.0300 - mse: 0.0025 - val_loss: 0.2578 - val_mae: 0.0656 - val_mse: 0.0098\n",
      "Epoch 138/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2501 - mae: 0.0299 - mse: 0.0025 - val_loss: 0.2575 - val_mae: 0.0672 - val_mse: 0.0102\n",
      "Epoch 139/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2495 - mae: 0.0299 - mse: 0.0025 - val_loss: 0.2569 - val_mae: 0.0675 - val_mse: 0.0102\n",
      "Epoch 140/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2488 - mae: 0.0298 - mse: 0.0025 - val_loss: 0.2560 - val_mae: 0.0659 - val_mse: 0.0100\n",
      "Epoch 141/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2481 - mae: 0.0297 - mse: 0.0025 - val_loss: 0.2551 - val_mae: 0.0654 - val_mse: 0.0098\n",
      "Epoch 142/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2475 - mae: 0.0297 - mse: 0.0025 - val_loss: 0.2547 - val_mae: 0.0661 - val_mse: 0.0100\n",
      "Epoch 143/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2468 - mae: 0.0296 - mse: 0.0025 - val_loss: 0.2543 - val_mae: 0.0671 - val_mse: 0.0102\n",
      "Epoch 144/256\n",
      "5058/5058 [==============================] - 17s 3ms/step - loss: 0.2462 - mae: 0.0296 - mse: 0.0024 - val_loss: 0.2531 - val_mae: 0.0652 - val_mse: 0.0097\n",
      "Epoch 145/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2455 - mae: 0.0296 - mse: 0.0024 - val_loss: 0.2527 - val_mae: 0.0659 - val_mse: 0.0099\n",
      "Epoch 146/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2449 - mae: 0.0295 - mse: 0.0024 - val_loss: 0.2522 - val_mae: 0.0669 - val_mse: 0.0101\n",
      "Epoch 147/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2442 - mae: 0.0294 - mse: 0.0024 - val_loss: 0.2516 - val_mae: 0.0667 - val_mse: 0.0101\n",
      "Epoch 148/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2436 - mae: 0.0294 - mse: 0.0024 - val_loss: 0.2507 - val_mae: 0.0658 - val_mse: 0.0098\n",
      "Epoch 149/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2430 - mae: 0.0293 - mse: 0.0024 - val_loss: 0.2501 - val_mae: 0.0657 - val_mse: 0.0098\n",
      "Epoch 150/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2424 - mae: 0.0293 - mse: 0.0024 - val_loss: 0.2496 - val_mae: 0.0660 - val_mse: 0.0099\n",
      "Epoch 151/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2418 - mae: 0.0292 - mse: 0.0024 - val_loss: 0.2496 - val_mae: 0.0684 - val_mse: 0.0106\n",
      "Epoch 152/256\n",
      "5058/5058 [==============================] - 17s 3ms/step - loss: 0.2412 - mae: 0.0292 - mse: 0.0024 - val_loss: 0.2482 - val_mae: 0.0655 - val_mse: 0.0097\n",
      "Epoch 153/256\n",
      "5058/5058 [==============================] - 22s 4ms/step - loss: 0.2405 - mae: 0.0292 - mse: 0.0024 - val_loss: 0.2477 - val_mae: 0.0659 - val_mse: 0.0098\n",
      "Epoch 154/256\n",
      "5058/5058 [==============================] - 17s 3ms/step - loss: 0.2399 - mae: 0.0291 - mse: 0.0024 - val_loss: 0.2471 - val_mae: 0.0659 - val_mse: 0.0098\n",
      "Epoch 155/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2393 - mae: 0.0291 - mse: 0.0024 - val_loss: 0.2464 - val_mae: 0.0655 - val_mse: 0.0097\n",
      "Epoch 156/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2388 - mae: 0.0291 - mse: 0.0024 - val_loss: 0.2462 - val_mae: 0.0672 - val_mse: 0.0101\n",
      "Epoch 157/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2382 - mae: 0.0290 - mse: 0.0024 - val_loss: 0.2451 - val_mae: 0.0653 - val_mse: 0.0096\n",
      "Epoch 158/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2376 - mae: 0.0289 - mse: 0.0023 - val_loss: 0.2446 - val_mae: 0.0656 - val_mse: 0.0097\n",
      "Epoch 159/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2370 - mae: 0.0289 - mse: 0.0023 - val_loss: 0.2438 - val_mae: 0.0648 - val_mse: 0.0094\n",
      "Epoch 160/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2364 - mae: 0.0289 - mse: 0.0023 - val_loss: 0.2434 - val_mae: 0.0650 - val_mse: 0.0096\n",
      "Epoch 161/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2358 - mae: 0.0288 - mse: 0.0023 - val_loss: 0.2427 - val_mae: 0.0646 - val_mse: 0.0095\n",
      "Epoch 162/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2353 - mae: 0.0288 - mse: 0.0023 - val_loss: 0.2426 - val_mae: 0.0665 - val_mse: 0.0099\n",
      "Epoch 163/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2347 - mae: 0.0287 - mse: 0.0023 - val_loss: 0.2415 - val_mae: 0.0648 - val_mse: 0.0094\n",
      "Epoch 164/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2341 - mae: 0.0287 - mse: 0.0023 - val_loss: 0.2408 - val_mae: 0.0639 - val_mse: 0.0092\n",
      "Epoch 165/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2336 - mae: 0.0286 - mse: 0.0023 - val_loss: 0.2408 - val_mae: 0.0660 - val_mse: 0.0098\n",
      "Epoch 166/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2330 - mae: 0.0286 - mse: 0.0023 - val_loss: 0.2404 - val_mae: 0.0676 - val_mse: 0.0099\n",
      "Epoch 167/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2325 - mae: 0.0286 - mse: 0.0023 - val_loss: 0.2393 - val_mae: 0.0644 - val_mse: 0.0094\n",
      "Epoch 168/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2319 - mae: 0.0285 - mse: 0.0023 - val_loss: 0.2392 - val_mae: 0.0660 - val_mse: 0.0098\n",
      "Epoch 169/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2314 - mae: 0.0285 - mse: 0.0023 - val_loss: 0.2381 - val_mae: 0.0642 - val_mse: 0.0093\n",
      "Epoch 170/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2309 - mae: 0.0284 - mse: 0.0023 - val_loss: 0.2374 - val_mae: 0.0632 - val_mse: 0.0091\n",
      "Epoch 171/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2303 - mae: 0.0284 - mse: 0.0023 - val_loss: 0.2368 - val_mae: 0.0634 - val_mse: 0.0090\n",
      "Epoch 172/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2298 - mae: 0.0283 - mse: 0.0023 - val_loss: 0.2365 - val_mae: 0.0640 - val_mse: 0.0092\n",
      "Epoch 173/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2292 - mae: 0.0283 - mse: 0.0022 - val_loss: 0.2358 - val_mae: 0.0635 - val_mse: 0.0091\n",
      "Epoch 174/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2287 - mae: 0.0283 - mse: 0.0022 - val_loss: 0.2354 - val_mae: 0.0642 - val_mse: 0.0092\n",
      "Epoch 175/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2282 - mae: 0.0282 - mse: 0.0022 - val_loss: 0.2350 - val_mae: 0.0643 - val_mse: 0.0093\n",
      "Epoch 176/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2277 - mae: 0.0282 - mse: 0.0022 - val_loss: 0.2340 - val_mae: 0.0628 - val_mse: 0.0088\n",
      "Epoch 177/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2271 - mae: 0.0281 - mse: 0.0022 - val_loss: 0.2339 - val_mae: 0.0642 - val_mse: 0.0093\n",
      "Epoch 178/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2266 - mae: 0.0281 - mse: 0.0022 - val_loss: 0.2338 - val_mae: 0.0655 - val_mse: 0.0096\n",
      "Epoch 179/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2261 - mae: 0.0280 - mse: 0.0022 - val_loss: 0.2325 - val_mae: 0.0630 - val_mse: 0.0089\n",
      "Epoch 180/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2256 - mae: 0.0280 - mse: 0.0022 - val_loss: 0.2324 - val_mae: 0.0641 - val_mse: 0.0092\n",
      "Epoch 181/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2251 - mae: 0.0280 - mse: 0.0022 - val_loss: 0.2323 - val_mae: 0.0659 - val_mse: 0.0097\n",
      "Epoch 182/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2246 - mae: 0.0279 - mse: 0.0022 - val_loss: 0.2311 - val_mae: 0.0633 - val_mse: 0.0090\n",
      "Epoch 183/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2241 - mae: 0.0279 - mse: 0.0022 - val_loss: 0.2306 - val_mae: 0.0634 - val_mse: 0.0089\n",
      "Epoch 184/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2236 - mae: 0.0278 - mse: 0.0022 - val_loss: 0.2304 - val_mae: 0.0644 - val_mse: 0.0092\n",
      "Epoch 185/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2231 - mae: 0.0278 - mse: 0.0022 - val_loss: 0.2297 - val_mae: 0.0637 - val_mse: 0.0091\n",
      "Epoch 186/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2226 - mae: 0.0278 - mse: 0.0022 - val_loss: 0.2287 - val_mae: 0.0615 - val_mse: 0.0085\n",
      "Epoch 187/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2221 - mae: 0.0277 - mse: 0.0022 - val_loss: 0.2288 - val_mae: 0.0639 - val_mse: 0.0091\n",
      "Epoch 188/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2216 - mae: 0.0277 - mse: 0.0022 - val_loss: 0.2281 - val_mae: 0.0634 - val_mse: 0.0089\n",
      "Epoch 189/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2211 - mae: 0.0277 - mse: 0.0022 - val_loss: 0.2279 - val_mae: 0.0644 - val_mse: 0.0092\n",
      "Epoch 190/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2207 - mae: 0.0276 - mse: 0.0021 - val_loss: 0.2268 - val_mae: 0.0617 - val_mse: 0.0085\n",
      "Epoch 191/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2202 - mae: 0.0276 - mse: 0.0021 - val_loss: 0.2270 - val_mae: 0.0646 - val_mse: 0.0092\n",
      "Epoch 192/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2197 - mae: 0.0275 - mse: 0.0021 - val_loss: 0.2265 - val_mae: 0.0641 - val_mse: 0.0091\n",
      "Epoch 193/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2192 - mae: 0.0275 - mse: 0.0021 - val_loss: 0.2255 - val_mae: 0.0623 - val_mse: 0.0086\n",
      "Epoch 194/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2188 - mae: 0.0275 - mse: 0.0021 - val_loss: 0.2252 - val_mae: 0.0629 - val_mse: 0.0088\n",
      "Epoch 195/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2183 - mae: 0.0275 - mse: 0.0021 - val_loss: 0.2243 - val_mae: 0.0618 - val_mse: 0.0084\n",
      "Epoch 196/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2178 - mae: 0.0274 - mse: 0.0021 - val_loss: 0.2243 - val_mae: 0.0633 - val_mse: 0.0089\n",
      "Epoch 197/256\n",
      "5058/5058 [==============================] - 14s 3ms/step - loss: 0.2173 - mae: 0.0274 - mse: 0.0021 - val_loss: 0.2238 - val_mae: 0.0629 - val_mse: 0.0088\n",
      "Epoch 198/256\n",
      "5058/5058 [==============================] - 14s 3ms/step - loss: 0.2169 - mae: 0.0273 - mse: 0.0021 - val_loss: 0.2229 - val_mae: 0.0615 - val_mse: 0.0084\n",
      "Epoch 199/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2164 - mae: 0.0273 - mse: 0.0021 - val_loss: 0.2226 - val_mae: 0.0620 - val_mse: 0.0085\n",
      "Epoch 200/256\n",
      "5058/5058 [==============================] - 14s 3ms/step - loss: 0.2159 - mae: 0.0273 - mse: 0.0021 - val_loss: 0.2228 - val_mae: 0.0645 - val_mse: 0.0092\n",
      "Epoch 201/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2155 - mae: 0.0272 - mse: 0.0021 - val_loss: 0.2216 - val_mae: 0.0617 - val_mse: 0.0084\n",
      "Epoch 202/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2150 - mae: 0.0272 - mse: 0.0021 - val_loss: 0.2214 - val_mae: 0.0625 - val_mse: 0.0086\n",
      "Epoch 203/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2146 - mae: 0.0272 - mse: 0.0021 - val_loss: 0.2208 - val_mae: 0.0621 - val_mse: 0.0085\n",
      "Epoch 204/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2141 - mae: 0.0271 - mse: 0.0021 - val_loss: 0.2206 - val_mae: 0.0631 - val_mse: 0.0088\n",
      "Epoch 205/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2137 - mae: 0.0271 - mse: 0.0021 - val_loss: 0.2199 - val_mae: 0.0619 - val_mse: 0.0085\n",
      "Epoch 206/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2132 - mae: 0.0271 - mse: 0.0021 - val_loss: 0.2195 - val_mae: 0.0620 - val_mse: 0.0085\n",
      "Epoch 207/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2128 - mae: 0.0270 - mse: 0.0021 - val_loss: 0.2194 - val_mae: 0.0636 - val_mse: 0.0089\n",
      "Epoch 208/256\n",
      "5058/5058 [==============================] - 14s 3ms/step - loss: 0.2124 - mae: 0.0270 - mse: 0.0021 - val_loss: 0.2190 - val_mae: 0.0637 - val_mse: 0.0089\n",
      "Epoch 209/256\n",
      "5058/5058 [==============================] - 14s 3ms/step - loss: 0.2119 - mae: 0.0270 - mse: 0.0020 - val_loss: 0.2184 - val_mae: 0.0627 - val_mse: 0.0087\n",
      "Epoch 210/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2115 - mae: 0.0269 - mse: 0.0020 - val_loss: 0.2179 - val_mae: 0.0628 - val_mse: 0.0086\n",
      "Epoch 211/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2111 - mae: 0.0269 - mse: 0.0020 - val_loss: 0.2171 - val_mae: 0.0614 - val_mse: 0.0083\n",
      "Epoch 212/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2106 - mae: 0.0269 - mse: 0.0020 - val_loss: 0.2169 - val_mae: 0.0623 - val_mse: 0.0085\n",
      "Epoch 213/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2102 - mae: 0.0269 - mse: 0.0020 - val_loss: 0.2166 - val_mae: 0.0630 - val_mse: 0.0087\n",
      "Epoch 214/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2098 - mae: 0.0268 - mse: 0.0020 - val_loss: 0.2165 - val_mae: 0.0641 - val_mse: 0.0090\n",
      "Epoch 215/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2093 - mae: 0.0268 - mse: 0.0020 - val_loss: 0.2156 - val_mae: 0.0624 - val_mse: 0.0085\n",
      "Epoch 216/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2089 - mae: 0.0268 - mse: 0.0020 - val_loss: 0.2150 - val_mae: 0.0615 - val_mse: 0.0083\n",
      "Epoch 217/256\n",
      "5058/5058 [==============================] - 14s 3ms/step - loss: 0.2085 - mae: 0.0267 - mse: 0.0020 - val_loss: 0.2146 - val_mae: 0.0613 - val_mse: 0.0083\n",
      "Epoch 218/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2081 - mae: 0.0267 - mse: 0.0020 - val_loss: 0.2140 - val_mae: 0.0605 - val_mse: 0.0081\n",
      "Epoch 219/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2077 - mae: 0.0267 - mse: 0.0020 - val_loss: 0.2139 - val_mae: 0.0620 - val_mse: 0.0084\n",
      "Epoch 220/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2072 - mae: 0.0266 - mse: 0.0020 - val_loss: 0.2136 - val_mae: 0.0627 - val_mse: 0.0085\n",
      "Epoch 221/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2068 - mae: 0.0266 - mse: 0.0020 - val_loss: 0.2127 - val_mae: 0.0606 - val_mse: 0.0081\n",
      "Epoch 222/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2064 - mae: 0.0266 - mse: 0.0020 - val_loss: 0.2128 - val_mae: 0.0623 - val_mse: 0.0085\n",
      "Epoch 223/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2060 - mae: 0.0265 - mse: 0.0020 - val_loss: 0.2122 - val_mae: 0.0619 - val_mse: 0.0084\n",
      "Epoch 224/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2056 - mae: 0.0265 - mse: 0.0020 - val_loss: 0.2120 - val_mae: 0.0629 - val_mse: 0.0086\n",
      "Epoch 225/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2052 - mae: 0.0265 - mse: 0.0020 - val_loss: 0.2114 - val_mae: 0.0621 - val_mse: 0.0084\n",
      "Epoch 226/256\n",
      "5058/5058 [==============================] - 17s 3ms/step - loss: 0.2048 - mae: 0.0265 - mse: 0.0020 - val_loss: 0.2110 - val_mae: 0.0619 - val_mse: 0.0084\n",
      "Epoch 227/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2044 - mae: 0.0264 - mse: 0.0020 - val_loss: 0.2106 - val_mae: 0.0618 - val_mse: 0.0084\n",
      "Epoch 228/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2040 - mae: 0.0264 - mse: 0.0020 - val_loss: 0.2102 - val_mae: 0.0615 - val_mse: 0.0084\n",
      "Epoch 229/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2036 - mae: 0.0264 - mse: 0.0020 - val_loss: 0.2098 - val_mae: 0.0620 - val_mse: 0.0084\n",
      "Epoch 230/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2032 - mae: 0.0263 - mse: 0.0020 - val_loss: 0.2093 - val_mae: 0.0616 - val_mse: 0.0083\n",
      "Epoch 231/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2028 - mae: 0.0263 - mse: 0.0020 - val_loss: 0.2089 - val_mae: 0.0615 - val_mse: 0.0082\n",
      "Epoch 232/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2024 - mae: 0.0263 - mse: 0.0019 - val_loss: 0.2090 - val_mae: 0.0633 - val_mse: 0.0087\n",
      "Epoch 233/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2020 - mae: 0.0263 - mse: 0.0020 - val_loss: 0.2083 - val_mae: 0.0621 - val_mse: 0.0084\n",
      "Epoch 234/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.2016 - mae: 0.0262 - mse: 0.0019 - val_loss: 0.2077 - val_mae: 0.0613 - val_mse: 0.0082\n",
      "Epoch 235/256\n",
      "5058/5058 [==============================] - 17s 3ms/step - loss: 0.2012 - mae: 0.0262 - mse: 0.0019 - val_loss: 0.2073 - val_mae: 0.0612 - val_mse: 0.0082\n",
      "Epoch 236/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2008 - mae: 0.0262 - mse: 0.0019 - val_loss: 0.2067 - val_mae: 0.0603 - val_mse: 0.0080\n",
      "Epoch 237/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2004 - mae: 0.0262 - mse: 0.0019 - val_loss: 0.2063 - val_mae: 0.0603 - val_mse: 0.0079\n",
      "Epoch 238/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.2001 - mae: 0.0262 - mse: 0.0019 - val_loss: 0.2061 - val_mae: 0.0612 - val_mse: 0.0082\n",
      "Epoch 239/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1997 - mae: 0.0261 - mse: 0.0019 - val_loss: 0.2058 - val_mae: 0.0611 - val_mse: 0.0082\n",
      "Epoch 240/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1993 - mae: 0.0261 - mse: 0.0019 - val_loss: 0.2053 - val_mae: 0.0608 - val_mse: 0.0081\n",
      "Epoch 241/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1989 - mae: 0.0261 - mse: 0.0019 - val_loss: 0.2049 - val_mae: 0.0607 - val_mse: 0.0080\n",
      "Epoch 242/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1986 - mae: 0.0261 - mse: 0.0019 - val_loss: 0.2045 - val_mae: 0.0604 - val_mse: 0.0080\n",
      "Epoch 243/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1982 - mae: 0.0260 - mse: 0.0019 - val_loss: 0.2045 - val_mae: 0.0620 - val_mse: 0.0084\n",
      "Epoch 244/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1978 - mae: 0.0260 - mse: 0.0019 - val_loss: 0.2036 - val_mae: 0.0602 - val_mse: 0.0079\n",
      "Epoch 245/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1974 - mae: 0.0260 - mse: 0.0019 - val_loss: 0.2036 - val_mae: 0.0612 - val_mse: 0.0082\n",
      "Epoch 246/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1971 - mae: 0.0259 - mse: 0.0019 - val_loss: 0.2033 - val_mae: 0.0624 - val_mse: 0.0084\n",
      "Epoch 247/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1967 - mae: 0.0259 - mse: 0.0019 - val_loss: 0.2026 - val_mae: 0.0603 - val_mse: 0.0080\n",
      "Epoch 248/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1963 - mae: 0.0259 - mse: 0.0019 - val_loss: 0.2027 - val_mae: 0.0627 - val_mse: 0.0085\n",
      "Epoch 249/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1960 - mae: 0.0259 - mse: 0.0019 - val_loss: 0.2022 - val_mae: 0.0615 - val_mse: 0.0083\n",
      "Epoch 250/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1956 - mae: 0.0258 - mse: 0.0019 - val_loss: 0.2015 - val_mae: 0.0607 - val_mse: 0.0080\n",
      "Epoch 251/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1952 - mae: 0.0258 - mse: 0.0019 - val_loss: 0.2010 - val_mae: 0.0598 - val_mse: 0.0078\n",
      "Epoch 252/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1949 - mae: 0.0258 - mse: 0.0019 - val_loss: 0.2011 - val_mae: 0.0619 - val_mse: 0.0083\n",
      "Epoch 253/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1945 - mae: 0.0258 - mse: 0.0019 - val_loss: 0.2004 - val_mae: 0.0603 - val_mse: 0.0079\n",
      "Epoch 254/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1942 - mae: 0.0257 - mse: 0.0019 - val_loss: 0.2005 - val_mae: 0.0623 - val_mse: 0.0084\n",
      "Epoch 255/256\n",
      "5058/5058 [==============================] - 15s 3ms/step - loss: 0.1938 - mae: 0.0257 - mse: 0.0019 - val_loss: 0.1996 - val_mae: 0.0600 - val_mse: 0.0078\n",
      "Epoch 256/256\n",
      "5058/5058 [==============================] - 16s 3ms/step - loss: 0.1935 - mae: 0.0257 - mse: 0.0019 - val_loss: 0.1997 - val_mae: 0.0621 - val_mse: 0.0083\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 256\n",
    "history = model.fit(\n",
    "  train_data, train_target,\n",
    "  batch_size = 64,\n",
    "  epochs=EPOCHS, validation_data=(test1_data,test1_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_path = C:\\Users\\PLDD\\Practice\\GitHub\\Python\\MHS\\models\\2\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\PLDD\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\PLDD\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\PLDD\\Practice\\GitHub\\Python\\MHS\\models\\2\\assets\n",
      "\n",
      "Saved model:\n"
     ]
    }
   ],
   "source": [
    "version = 2\n",
    "export_path = os.path.join(modeldir, str(version))\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")\n",
    "\n",
    "print('\\nSaved model:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>102229.000000</td>\n",
       "      <td>102229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.119526</td>\n",
       "      <td>2.072973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.353206</td>\n",
       "      <td>1.314965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.322815</td>\n",
       "      <td>0.316071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.168864</td>\n",
       "      <td>1.136051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.603277</td>\n",
       "      <td>1.590016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.647212</td>\n",
       "      <td>2.600953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.725821</td>\n",
       "      <td>8.152223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Act           Pred\n",
       "count  102229.000000  102229.000000\n",
       "mean        2.119526       2.072973\n",
       "std         1.353206       1.314965\n",
       "min         0.322815       0.316071\n",
       "25%         1.168864       1.136051\n",
       "50%         1.603277       1.590016\n",
       "75%         2.647212       2.600953\n",
       "max         8.725821       8.152223"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_act1 = test1_target.to_numpy()\n",
    "y_pred1 = model.predict(test1_data).reshape(-1)\n",
    "dff = pd.DataFrame({'Act': test1_target, 'Pred' : y_pred1})\n",
    "dff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>77252.000000</td>\n",
       "      <td>77252.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.552110</td>\n",
       "      <td>1.568512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.072593</td>\n",
       "      <td>1.115968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.236809</td>\n",
       "      <td>0.299229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.766257</td>\n",
       "      <td>0.755042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.168075</td>\n",
       "      <td>1.158127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.960509</td>\n",
       "      <td>2.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.360890</td>\n",
       "      <td>4.400702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Act          Pred\n",
       "count  77252.000000  77252.000000\n",
       "mean       1.552110      1.568512\n",
       "std        1.072593      1.115968\n",
       "min        0.236809      0.299229\n",
       "25%        0.766257      0.755042\n",
       "50%        1.168075      1.158127\n",
       "75%        1.960509      2.036500\n",
       "max        4.360890      4.400702"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_act2 = test2_target.to_numpy()\n",
    "y_pred2 = model.predict(test2_data).reshape(-1)\n",
    "dff = pd.DataFrame({'Act': test2_target, 'Pred' : y_pred2})\n",
    "dff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b90e1c5ac8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.distplot(y_act1,fit = stats.norm, color = 'red', label = 'Determenistic',fit_kws={\"color\":\"red\"},kde = False)\n",
    "sn.distplot(y_pred1, fit = stats.norm, color = 'blue', label = 'Approximated',fit_kws={\"color\":\"blue\"},kde=False)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b9102334c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.distplot(y_act2,fit = stats.norm, color = 'red', label = 'Determenistic',fit_kws={\"color\":\"red\"},kde = False)\n",
    "sn.distplot(y_pred2, fit = stats.norm, color = 'blue', label = 'Approximated',fit_kws={\"color\":\"blue\"},kde=False)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_path = C:\\Users\\PLDD\\Practice\\GitHub\\Python\\MHS\\models\\1\n",
      "\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\PLDD\\Practice\\GitHub\\Python\\MHS\\models\\1\\assets\n",
      "\n",
      "Saved model:\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
